{"Robot & Agent": {"2508.14358": "|**2025-08-20**|**Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation**|Zhujun Li et.al.|[2508.14358](https://arxiv.org/abs/2508.14358)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14160": "|**2025-08-19**|**RynnEC: Bringing MLLMs into Embodied World**|Ronghao Dang et.al.|[2508.14160](https://arxiv.org/abs/2508.14160)|**[link](https://huggingface.co/spaces/Alibaba-DAMO-Academy/RynnEC)**|\n", "2508.14926": "|**2025-08-28**|**Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving**|Dianzhao Li et.al.|[2508.14926](https://arxiv.org/abs/2508.14926)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2508.13530": "|**2025-08-19**|**CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter**|Junyeong Park et.al.|[2508.13530](https://arxiv.org/abs/2508.13530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12349": "|**2025-08-17**|**EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos**|Junyi Ma et.al.|[2508.12349](https://arxiv.org/abs/2508.12349)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12252": "|**2025-08-27**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Kaizhe Hu et.al.|[2508.12252](https://arxiv.org/abs/2508.12252)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2508.12211": "|**2025-08-17**|**Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search**|Cyrus Neary et.al.|[2508.12211](https://arxiv.org/abs/2508.12211)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12189": "|**2025-08-17**|**Self-Guided Action Diffusion**|Rhea Malhotra et.al.|[2508.12189](https://arxiv.org/abs/2508.12189)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12166": "|**2025-08-27**|**Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing**|Gokul Puthumanaillam et.al.|[2508.12166](https://arxiv.org/abs/2508.12166)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2508.11479": "|**2025-08-15**|**OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation**|Tatiana Zemskova et.al.|[2508.11479](https://arxiv.org/abs/2508.11479)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11286": "|**2025-08-15**|**Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent**|Che Rin Yu et.al.|[2508.11286](https://arxiv.org/abs/2508.11286)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11275": "|**2025-08-15**|**Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation**|Masaki Murooka et.al.|[2508.11275](https://arxiv.org/abs/2508.11275)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11117": "|**2025-08-14**|**Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective**|Xuning Yang et.al.|[2508.11117](https://arxiv.org/abs/2508.11117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11049": "|**2025-08-14**|**GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning**|Kelin Yu et.al.|[2508.11049](https://arxiv.org/abs/2508.11049)|**[link](https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning)**|\n", "2508.10511": "|**2025-11-11**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Andrea Rosasco et.al.|[2508.10511](https://arxiv.org/abs/2508.10511)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2508.10399": "|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09976": "|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Marion Lepert et.al.|[2508.09976](https://arxiv.org/abs/2508.09976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.08982": "|**2025-08-12**|**Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion**|Seungeun Rho et.al.|[2508.08982](https://arxiv.org/abs/2508.08982)|**[link](https://github.com/curieuxjy/Awesome_Quadrupedal_Robots)**|\n", "2508.07770": "|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.07033": "|**2025-08-09**|**$\\mathcal{P}^3$: Toward Versatile Embodied Agents**|Shengli Zhou et.al.|[2508.07033](https://arxiv.org/abs/2508.07033)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06990": "|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06980": "|**2025-08-09**|**Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model**|Aswin Paul et.al.|[2508.06980](https://arxiv.org/abs/2508.06980)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06779": "|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Minku Kim et.al.|[2508.06779](https://arxiv.org/abs/2508.06779)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06426": "|**2025-08-08**|**Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation**|Youguang Xing et.al.|[2508.06426](https://arxiv.org/abs/2508.06426)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2508.05634": "|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05614": "|**2025-08-07**|**OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks**|Zixuan Wang et.al.|[2508.05614](https://arxiv.org/abs/2508.05614)|**[link](https://huggingface.co/datasets/wangzx1210/OmniEAR)**|\n", "2508.05543": "|**2025-08-07**|**CleanUpBench: Embodied Sweeping and Grasping Benchmark**|Wenbo Li et.al.|[2508.05543](https://arxiv.org/abs/2508.05543)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.05294": "|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2508.03645": "|**2025-08-05**|**DiWA: Diffusion Policy Adaptation with World Models**|Akshay L Chandra et.al.|[2508.03645](https://arxiv.org/abs/2508.03645)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.03068": "|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|Sirui Chen et.al.|[2508.03068](https://arxiv.org/abs/2508.03068)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2508.02870": "|**2025-08-04**|**Learning User Interaction Forces using Vision for a Soft Finger Exosuit**|Mohamed Irfan Refai et.al.|[2508.02870](https://arxiv.org/abs/2508.02870)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02629": "|**2025-08-06**|**HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents**|Yibin Liu et.al.|[2508.02629](https://arxiv.org/abs/2508.02629)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2508.06326": "|**2025-08-21**|**A \"good regulator theorem\" for embodied agents**|Nathaniel Virgo et.al.|[2508.06326](https://arxiv.org/abs/2508.06326)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02376": "|**2025-08-04**|**Talking Surveys: How Photorealistic Embodied Conversational Agents Shape Response Quality, Engagement, and Satisfaction**|Matus Krajcovic et.al.|[2508.02376](https://arxiv.org/abs/2508.02376)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02146": "|**2025-08-22**|**ScrewSplat: An End-to-End Method for Articulated Object Recognition**|Seungyeon Kim et.al.|[2508.02146](https://arxiv.org/abs/2508.02146)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02062": "|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|\n", "2508.01808": "|**2025-08-03**|**Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by Recurrent Action-Confidence Chunking with Transformer**|Yu Tian et.al.|[2508.01808](https://arxiv.org/abs/2508.01808)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01766": "|**2025-08-25**|**VPN: Visual Prompt Navigation**|Shuo Feng et.al.|[2508.01766](https://arxiv.org/abs/2508.01766)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01723": "|**2025-08-03**|**OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping**|Danyang Li et.al.|[2508.01723](https://arxiv.org/abs/2508.01723)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01651": "|**2025-08-03**|**DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding**|Hanqing Wang et.al.|[2508.01651](https://arxiv.org/abs/2508.01651)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01600": "|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01131": "|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00795": "|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.00500": "|**2025-08-01**|**Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking**|Haoyu Wang et.al.|[2508.00500](https://arxiv.org/abs/2508.00500)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2508.00400": "|**2025-08-01**|**Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents**|Janika Deborah Gajo et.al.|[2508.00400](https://arxiv.org/abs/2508.00400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00354": "|**2025-08-01**|**Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging**|Tianshuang Qiu et.al.|[2508.00354](https://arxiv.org/abs/2508.00354)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|\n", "2507.23772": "|**2025-07-31**|**SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting**|Di Li et.al.|[2507.23772](https://arxiv.org/abs/2507.23772)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|\n", "2507.23523": "|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.23391": "|**2025-07-31**|**Policy Learning from Large Vision-Language Model Feedback without Reward Modeling**|Tung M. Luu et.al.|[2507.23391](https://arxiv.org/abs/2507.23391)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.22028": "|**2025-07-29**|**From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning**|Honglin He et.al.|[2507.22028](https://arxiv.org/abs/2507.22028)|**[link](https://github.com/ai4ce/CityWalker)**|\n", "2508.15972": "|**2025-08-21**|**UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation**|Zhaodong Jiang et.al.|[2508.15972](https://arxiv.org/abs/2508.15972)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17643": "|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Krishna Vinod et.al.|[2508.17643](https://arxiv.org/abs/2508.17643)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17600": "|**2025-08-25**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Guanxing Lu et.al.|[2508.17600](https://arxiv.org/abs/2508.17600)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.17230": "|**2025-09-06**|**4D Visual Pre-training for Robot Learning**|Chengkai Hou et.al.|[2508.17230](https://arxiv.org/abs/2508.17230)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2508.17198": "|**2025-08-24**|**From reactive to cognitive: brain-inspired spatial intelligence for embodied agents**|Shouwei Ruan et.al.|[2508.17198](https://arxiv.org/abs/2508.17198)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2508.19204": "|**2025-08-26**|**LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding**|Julian Ost et.al.|[2508.19204](https://arxiv.org/abs/2508.19204)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.19172": "|**2025-08-28**|**From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity**|Luca Grillotti et.al.|[2508.19172](https://arxiv.org/abs/2508.19172)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18691": "|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Himanshu Gaurav Singh et.al.|[2508.18691](https://arxiv.org/abs/2508.18691)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20085": "|**2025-08-31**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Zhecheng Yuan et.al.|[2508.20085](https://arxiv.org/abs/2508.20085)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2508.19958": "|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Yiguo Fan et.al.|[2508.19958](https://arxiv.org/abs/2508.19958)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.19562": "|**2025-08-27**|**Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities**|Trisanth Srinivasan et.al.|[2508.19562](https://arxiv.org/abs/2508.19562)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19527": "|**2025-08-27**|**MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment**|Zhiting Gao et.al.|[2508.19527](https://arxiv.org/abs/2508.19527)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2508.21065": "|**2025-08-28**|**Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation**|Jiahe Pan et.al.|[2508.21065](https://arxiv.org/abs/2508.21065)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21007": "|**2025-08-28**|**Rapid Mismatch Estimation via Neural Network Informed Variational Inference**|Mateusz Jaszczuk et.al.|[2508.21007](https://arxiv.org/abs/2508.21007)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20840": "|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qiao Sun et.al.|[2508.20840](https://arxiv.org/abs/2508.20840)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.20561": "|**2025-08-28**|**SimShear: Sim-to-Real Shear-based Tactile Servoing**|Kipp McAdam Freud et.al.|[2508.20561](https://arxiv.org/abs/2508.20561)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2508.21690": "|**2025-08-29**|**Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?**|Olger Siebinga et.al.|[2508.21690](https://arxiv.org/abs/2508.21690)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21592": "|**2025-08-29**|**Learning Agile Gate Traversal via Analytical Optimal Policy Gradient**|Tianchen Sun et.al.|[2508.21592](https://arxiv.org/abs/2508.21592)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21375": "|**2025-08-29**|**Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation**|Anuj Pasricha et.al.|[2508.21375](https://arxiv.org/abs/2508.21375)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.02530": "|**2025-09-02**|**Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots**|Minghuan Liu et.al.|[2509.02530](https://arxiv.org/abs/2509.02530)|**[link](https://huggingface.co/models/depth-anything/camera-depth-model-d405)**|\n", "2509.03399": "|**2025-09-12**|**Tangential Action Spaces: Geometry, Memory and Cost in Holonomic and Nonholonomic Agents**|Marcel Blattner et.al.|[2509.03399](https://arxiv.org/abs/2509.03399)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02322": "|**2025-09-02**|**OmniActor: A Generalist GUI and Embodied Agent for 2D&3D Worlds**|Longrong Yang et.al.|[2509.02322](https://arxiv.org/abs/2509.02322)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.01765": "|**2025-09-01**|**Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control**|Skand Peri et.al.|[2509.01765](https://arxiv.org/abs/2509.01765)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01746": "|**2025-09-01**|**Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference**|Yixuan Huang et.al.|[2509.01746](https://arxiv.org/abs/2509.01746)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01708": "|**2025-09-01**|**Articulated Object Estimation in the Wild**|Abdelrhman Werby et.al.|[2509.01708](https://arxiv.org/abs/2509.01708)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01657": "|**2025-09-01**|**Data Retrieval with Importance Weights for Few-Shot Imitation Learning**|Amber Xie et.al.|[2509.01657](https://arxiv.org/abs/2509.01657)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01297": "|**2025-09-01**|**Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning**|Seonsoo Kim et.al.|[2509.01297](https://arxiv.org/abs/2509.01297)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00570": "|**2025-08-30**|**ConceptBot: Enhancing Robot's Autonomy through Task Decomposition with Large Language Models and Knowledge Graph**|Alessandro Leanza et.al.|[2509.00570](https://arxiv.org/abs/2509.00570)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00361": "|**2025-08-30**|**Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation**|Chuye Zhang et.al.|[2509.00361](https://arxiv.org/abs/2509.00361)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00328": "|**2025-08-30**|**Mechanistic interpretability for steering vision-language-action models**|Bear H\u00e4on et.al.|[2509.00328](https://arxiv.org/abs/2509.00328)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.00271": "|**2025-08-29**|**Learn from What We HAVE: History-Aware VErifier that Reasons about Past Interactions Online**|Yishu Li et.al.|[2509.00271](https://arxiv.org/abs/2509.00271)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00178": "|**2025-08-29**|**Poke and Strike: Learning Task-Informed Exploration Policies**|Marina Y. Aoyama et.al.|[2509.00178](https://arxiv.org/abs/2509.00178)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04443": "|**2025-09-04**|**EMMA: Scaling Mobile Manipulation via Egocentric Human Data**|Lawrence Y. Zhu et.al.|[2509.04443](https://arxiv.org/abs/2509.04443)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03956": "|**2025-09-04**|**World Model Implanting for Test-time Adaptation of Embodied Agents**|Minjong Yoo et.al.|[2509.03956](https://arxiv.org/abs/2509.03956)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.03859": "|**2025-09-08**|**Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator**|Haichao Zhang et.al.|[2509.03859](https://arxiv.org/abs/2509.03859)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04996": "|**2025-09-05**|**FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies**|Moritz Reuss et.al.|[2509.04996](https://arxiv.org/abs/2509.04996)|**[link](https://github.com/mees/calvin)**|\n", "2509.04737": "|**2025-09-05**|**Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics**|Ryoga Oishi et.al.|[2509.04737](https://arxiv.org/abs/2509.04737)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04645": "|**2025-09-04**|**Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement**|Kallol Saha et.al.|[2509.04645](https://arxiv.org/abs/2509.04645)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06932": "|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Yuqing Wen et.al.|[2509.06932](https://arxiv.org/abs/2509.06932)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.06233": "|**2025-09-07**|**O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation**|Tongxuan Tian et.al.|[2509.06233](https://arxiv.org/abs/2509.06233)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07953": "|**2025-09-09**|**RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction**|Zheyuan Hu et.al.|[2509.07953](https://arxiv.org/abs/2509.07953)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07445": "|**2025-09-09**|**Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**|Harrison Field et.al.|[2509.07445](https://arxiv.org/abs/2509.07445)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2509.08757": "|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Michael J. Munje et.al.|[2509.08757](https://arxiv.org/abs/2509.08757)|**[link](https://huggingface.co/datasets/michaelmunje/SocialNav-SUB)**|\n", "2509.08500": "|**2025-09-10**|**TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making**|Kechen Jiao et.al.|[2509.08500](https://arxiv.org/abs/2509.08500)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08222": "|**2025-09-10**|**Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following**|Minjong Yoo et.al.|[2509.08222](https://arxiv.org/abs/2509.08222)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.07997": "|**2025-09-05**|**Learning-Based Planning for Improving Science Return of Earth Observation Satellites**|Abigail Breitfeld et.al.|[2509.07997](https://arxiv.org/abs/2509.07997)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09560": "|**2025-09-11**|**Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution**|Shulai Zhang et.al.|[2509.09560](https://arxiv.org/abs/2509.09560)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09356": "|**2025-09-11**|**Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning**|Abdel Hakim Drid et.al.|[2509.09356](https://arxiv.org/abs/2509.09356)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.09074": "|**2025-09-11**|**KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning**|Alice Kate Li et.al.|[2509.09074](https://arxiv.org/abs/2509.09074)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09863": "|**2025-09-11**|**Off Policy Lyapunov Stability in Reinforcement Learning**|Sarvan Gill et.al.|[2509.09863](https://arxiv.org/abs/2509.09863)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11959": "|**2025-09-15**|**Learning to Generate 4D LiDAR Sequences**|Ao Liang et.al.|[2509.11959](https://arxiv.org/abs/2509.11959)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.11663": "|**2025-09-15**|**ParaEQsA: Parallel and Asynchronous Embodied Questions Scheduling and Answering**|Haisheng Wang et.al.|[2509.11663](https://arxiv.org/abs/2509.11663)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11514": "|**2025-09-15**|**LVLMs are Bad at Overhearing Human Referential Communication**|Zhengxiang Wang et.al.|[2509.11514](https://arxiv.org/abs/2509.11514)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11109": "|**2025-09-16**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Jiaxin Huang et.al.|[2509.11109](https://arxiv.org/abs/2509.11109)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10952": "|**2025-09-13**|**ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation**|Yangcen Liu et.al.|[2509.10952](https://arxiv.org/abs/2509.10952)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12531": "|**2025-09-16**|**Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning**|Scott Jones et.al.|[2509.12531](https://arxiv.org/abs/2509.12531)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12507": "|**2025-09-15**|**Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents**|Anna Deichler et.al.|[2509.12507](https://arxiv.org/abs/2509.12507)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12379": "|**2025-09-15**|**Geometric Red-Teaming for Robotic Manipulation**|Divyam Goel et.al.|[2509.12379](https://arxiv.org/abs/2509.12379)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.13733": "|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou et.al.|[2509.13733](https://arxiv.org/abs/2509.13733)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13574": "|**2025-09-16**|**Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation**|Zidong Chen et.al.|[2509.13574](https://arxiv.org/abs/2509.13574)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15061": "|**2025-09-19**|**Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue**|Xingyao Lin et.al.|[2509.15061](https://arxiv.org/abs/2509.15061)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.14967": "|**2025-09-19**|**Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery**|Ana Davila et.al.|[2509.14967](https://arxiv.org/abs/2509.14967)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Tobias J\u00fclg et.al.|[2509.14932](https://arxiv.org/abs/2509.14932)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.14688": "|**2025-09-18**|**exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation**|Yue Xu et.al.|[2509.14688](https://arxiv.org/abs/2509.14688)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2509.14530": "|**2025-09-18**|**Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking**|Zhenghao Fei et.al.|[2509.14530](https://arxiv.org/abs/2509.14530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14460": "|**2025-09-17**|**Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring**|Abhiroop Ajith et.al.|[2509.14460](https://arxiv.org/abs/2509.14460)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16037": "|**2025-09-19**|**Learning Safety for Obstacle Avoidance via Control Barrier Functions**|Shuo Liu et.al.|[2509.16037](https://arxiv.org/abs/2509.16037)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15717": "|**2025-09-19**|**Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference**|Haoran Ding et.al.|[2509.15717](https://arxiv.org/abs/2509.15717)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15293": "|**2025-09-22**|**How Good are Foundation Models in Step-by-Step Embodied Reasoning?**|Dinura Dissanayake et.al.|[2509.15293](https://arxiv.org/abs/2509.15293)|**[link](https://huggingface.co/datasets/Dinura/FoMER)**|\n", "2509.17941": "|**2025-09-22**|**ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion**|Zichao Hu et.al.|[2509.17941](https://arxiv.org/abs/2509.17941)|**[link](https://github.com/wendell0218/Awesome-RL-for-Video-Generation)**|\n", "2509.17783": "|**2025-09-23**|**RoboSeek: You Need to Interact with Your Objects**|Yibo Peng et.al.|[2509.17783](https://arxiv.org/abs/2509.17783)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17759": "|**2025-09-22**|**MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies**|Chengbo Yuan et.al.|[2509.17759](https://arxiv.org/abs/2509.17759)|**[link](https://huggingface.co/datasets/michaelyuanqwq/motiontrans)**|\n", "2509.17750": "|**2025-09-22**|**EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering**|Inkyu Jang et.al.|[2509.17750](https://arxiv.org/abs/2509.17750)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17450": "|**2025-09-22**|**Learning Dexterous Manipulation with Quantized Hand State**|Ying Feng et.al.|[2509.17450](https://arxiv.org/abs/2509.17450)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17425": "|**2025-09-22**|**Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments**|Zhenliang Zhang et.al.|[2509.17425](https://arxiv.org/abs/2509.17425)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17116": "|**2025-09-21**|**MCTS-EP: Empowering Embodied Planning with Online Preference Optimization**|Hang Xu et.al.|[2509.17116](https://arxiv.org/abs/2509.17116)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16924": "|**2025-09-21**|**Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation**|Jia Li et.al.|[2509.16924](https://arxiv.org/abs/2509.16924)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16834": "|**2025-09-20**|**Robot Learning with Sparsity and Scarcity**|Jingxi Xu et.al.|[2509.16834](https://arxiv.org/abs/2509.16834)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16645": "|**2025-09-20**|**ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents**|Yichen Wang et.al.|[2509.16645](https://arxiv.org/abs/2509.16645)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.19292": "|**2025-09-23**|**SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration**|Yang Jin et.al.|[2509.19292](https://arxiv.org/abs/2509.19292)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19041": "|**2025-09-23**|**Position: Human-Robot Interaction in Embodied Intelligence Demands a Shift From Static Privacy Controls to Dynamic Learning**|Shuning Zhang et.al.|[2509.19041](https://arxiv.org/abs/2509.19041)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18734": "|**2025-09-23**|**Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation**|Nishant Doshi et.al.|[2509.18734](https://arxiv.org/abs/2509.18734)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang et.al.|[2509.18610](https://arxiv.org/abs/2509.18610)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2509.18597": "|**2025-09-25**|**Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills**|Yuan Meng et.al.|[2509.18597](https://arxiv.org/abs/2509.18597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18455": "|**2025-09-22**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Yunshuang Li et.al.|[2509.18455](https://arxiv.org/abs/2509.18455)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18447": "|**2025-09-22**|**PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction**|Rishabh Madan et.al.|[2509.18447](https://arxiv.org/abs/2509.18447)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18311": "|**2025-09-22**|**Fine-Tuning Robot Policies While Maintaining User Privacy**|Benjamin A. Christie et.al.|[2509.18311](https://arxiv.org/abs/2509.18311)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06775": "|**2025-09-22**|**Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks**|Po-Heng Chou et.al.|[2509.06775](https://arxiv.org/abs/2509.06775)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.20297": "|**2025-09-26**|**mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies**|Remo Steiner et.al.|[2509.20297](https://arxiv.org/abs/2509.20297)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19958": "|**2025-09-25**|**Generalist Robot Manipulation beyond Action Labeled Data**|Alexander Spiridonov et.al.|[2509.19958](https://arxiv.org/abs/2509.19958)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.19843": "|**2025-09-24**|**PersONAL: Towards a Comprehensive Benchmark for Personalized Embodied Agents**|Filippo Ziliotto et.al.|[2509.19843](https://arxiv.org/abs/2509.19843)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19626": "|**2025-09-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Ryan Punamiya et.al.|[2509.19626](https://arxiv.org/abs/2509.19626)|**[link](https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence)**|\n", "2509.19597": "|**2025-09-23**|**From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting**|Sander Tonkens et.al.|[2509.19597](https://arxiv.org/abs/2509.19597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin et.al.|[2509.19571](https://arxiv.org/abs/2509.19571)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.19524": "|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Ramy ElMallah et.al.|[2509.19524](https://arxiv.org/abs/2509.19524)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20841": "|**2025-09-25**|**ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation**|Dekun Lu et.al.|[2509.20841](https://arxiv.org/abs/2509.20841)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20623": "|**2025-09-24**|**Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation**|Satyajeet Das et.al.|[2509.20623](https://arxiv.org/abs/2509.20623)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20612": "|**2025-09-24**|**Policy Compatible Skill Incremental Learning via Lazy Learning Interface**|Daehee Lee et.al.|[2509.20612](https://arxiv.org/abs/2509.20612)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20541": "|**2025-09-24**|**Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning**|Anujith Muraleedharan et.al.|[2509.20541](https://arxiv.org/abs/2509.20541)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20499": "|**2025-09-24**|**Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting**|Boqi Li et.al.|[2509.20499](https://arxiv.org/abs/2509.20499)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22652": "|**2025-09-26**|**Pixel Motion Diffusion is What We Need for Robot Control**|E-Ro Nguyen et.al.|[2509.22652](https://arxiv.org/abs/2509.22652)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22548": "|**2025-09-26**|**JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation**|Shuang Zeng et.al.|[2509.22548](https://arxiv.org/abs/2509.22548)|**[link](https://github.com/MIV-XJTU/JanusVLN)**|\n", "2509.22442": "|**2025-09-26**|**Learning to Ball: Composing Policies for Long-Horizon Basketball Moves**|Pei Xu et.al.|[2509.22442](https://arxiv.org/abs/2509.22442)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.22434": "|**2025-09-26**|**An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics**|Margherita Martorana et.al.|[2509.22434](https://arxiv.org/abs/2509.22434)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22356": "|**2025-09-26**|**RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation**|Enguang Liu et.al.|[2509.22356](https://arxiv.org/abs/2509.22356)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei et.al.|[2509.22093](https://arxiv.org/abs/2509.22093)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.21986": "|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Tomoya Yoshida et.al.|[2509.21986](https://arxiv.org/abs/2509.21986)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.21810": "|**2025-09-26**|**Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors**|Ning Huang et.al.|[2509.21810](https://arxiv.org/abs/2509.21810)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21576": "|**2025-09-25**|**Vision Language Models Cannot Plan, but Can They Formalize?**|Muyu He et.al.|[2509.21576](https://arxiv.org/abs/2509.21576)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22421": "|**2025-09-24**|**Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping**|Leonel Giacobbe et.al.|[2509.22421](https://arxiv.org/abs/2509.22421)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25097": "|**2025-10-01**|**Curriculum Imitation Learning of Distributed Multi-Robot Policies**|Jes\u00fas Roche et.al.|[2509.25097](https://arxiv.org/abs/2509.25097)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24956": "|**2025-09-29**|**MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation**|Jan Ole von Hartz et.al.|[2509.24956](https://arxiv.org/abs/2509.24956)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24797": "|**2025-09-29**|**Fidelity-Aware Data Composition for Robust Robot Generalization**|Zizhao Tong et.al.|[2509.24797](https://arxiv.org/abs/2509.24797)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang et.al.|[2509.24524](https://arxiv.org/abs/2509.24524)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.24313": "|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Korbinian Moller et.al.|[2509.24313](https://arxiv.org/abs/2509.24313)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Tomoyuki Kagaya et.al.|[2509.24219](https://arxiv.org/abs/2509.24219)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian et.al.|[2509.23823](https://arxiv.org/abs/2509.23823)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.23698": "|**2025-09-28**|**VIVA+: Human-Centered Situational Decision-Making**|Zhe Hu et.al.|[2509.23698](https://arxiv.org/abs/2509.23698)|**[link](https://huggingface.co/datasets/zhehuderek/VIVA_Plus_Benchmark)**|\n", "2509.23690": "|**2025-09-28**|**HomeSafeBench: A Benchmark for Embodied Vision-Language Models in Free-Exploration Home Safety Inspection**|Siyuan Gao et.al.|[2509.23690](https://arxiv.org/abs/2509.23690)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas et.al.|[2509.23655](https://arxiv.org/abs/2509.23655)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.23328": "|**2025-09-27**|**Space Robotics Bench: Robot Learning Beyond Earth**|Andrej Orsula et.al.|[2509.23328](https://arxiv.org/abs/2509.23328)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.23155": "|**2025-09-27**|**LAGEA: Language Guided Embodied Agents for Robotic Manipulation**|Abdul Monaf Chowdhury et.al.|[2509.23155](https://arxiv.org/abs/2509.23155)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23021": "|**2025-09-27**|**UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes**|Xiao Hu et.al.|[2509.23021](https://arxiv.org/abs/2509.23021)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22970": "|**2025-10-08**|**Robot Learning from Any Images**|Siheng Zhao et.al.|[2509.22970](https://arxiv.org/abs/2509.22970)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.22914": "|**2025-09-26**|**ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality**|Rohan Walia et.al.|[2509.22914](https://arxiv.org/abs/2509.22914)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26536": "|**2025-09-30**|**OceanGym: A Benchmark Environment for Underwater Embodied Agents**|Yida Xue et.al.|[2509.26536](https://arxiv.org/abs/2509.26536)|**[link](https://huggingface.co/datasets/zjunlp/OceanGym)**|\n", "2509.26513": "|**2025-09-30**|**Learning from Hallucinating Critical Points for Navigation in Dynamic Environments**|Saad Abdul Ghani et.al.|[2509.26513](https://arxiv.org/abs/2509.26513)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25885": "|**2025-09-30**|**SafeMind: Benchmarking and Mitigating Safety Risks in Embodied LLM Agents**|Ruolin Chen et.al.|[2509.25885](https://arxiv.org/abs/2509.25885)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25466": "|**2025-09-29**|**Data-Efficient Multitask DAgger**|Haotian Fu et.al.|[2509.25466](https://arxiv.org/abs/2509.25466)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25402": "|**2025-09-29**|**Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models**|Hanlan Yang et.al.|[2509.25402](https://arxiv.org/abs/2509.25402)|**[link](https://github.com/p-achs/p-achs.github.io)**|\n", "2509.25358": "|**2025-10-02**|**SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation**|Qianzhong Chen et.al.|[2509.25358](https://arxiv.org/abs/2509.25358)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25352": "|**2025-09-29**|**SRMP: Search-Based Robot Motion Planning Library**|Itamar Mishani et.al.|[2509.25352](https://arxiv.org/abs/2509.25352)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.01607": "|**2025-10-02**|**ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations**|Qiyuan Zeng et.al.|[2510.01607](https://arxiv.org/abs/2510.01607)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2510.01433": "|**2025-10-01**|**AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation**|Anukriti Singh et.al.|[2510.01433](https://arxiv.org/abs/2510.01433)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01068": "|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Jiahang Cao et.al.|[2510.01068](https://arxiv.org/abs/2510.01068)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.01023": "|**2025-10-01**|**Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|S. Satsevich et.al.|[2510.01023](https://arxiv.org/abs/2510.01023)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00573": "|**2025-10-01**|**GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks**|Yen-Ling Tai et.al.|[2510.00573](https://arxiv.org/abs/2510.00573)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00491": "|**2025-10-01**|**From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment**|Han Zhou et.al.|[2510.00491](https://arxiv.org/abs/2510.00491)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.00329": "|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Sarmad Mehrdad et.al.|[2510.00329](https://arxiv.org/abs/2510.00329)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03153": "|**2025-10-03**|**Improving Cooperation in Collaborative Embodied AI**|Hima Jacob Leven Suprabha et.al.|[2510.03153](https://arxiv.org/abs/2510.03153)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.03135": "|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Gen Li et.al.|[2510.03135](https://arxiv.org/abs/2510.03135)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.03123": "|**2025-10-03**|**Learning Stability Certificate for Robotics in Real-World Environments**|Zhe Shen et.al.|[2510.03123](https://arxiv.org/abs/2510.03123)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03104": "|**2025-10-03**|**Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields**|Zhiting Mei et.al.|[2510.03104](https://arxiv.org/abs/2510.03104)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2510.02356": "|**2025-09-27**|**Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark**|Xinjie Shen et.al.|[2510.02356](https://arxiv.org/abs/2510.02356)|**[link](https://huggingface.co/datasets/Graph-COM/EAPrivacy)**|\n", "2510.05013": "|**2025-10-23**|**Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration**|Theodore Jerome Tinker et.al.|[2510.05013](https://arxiv.org/abs/2510.05013)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04898": "|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Zheng Xiong et.al.|[2510.04898](https://arxiv.org/abs/2510.04898)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.04354": "|**2025-10-05**|**Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators**|Apurva Badithela et.al.|[2510.04354](https://arxiv.org/abs/2510.04354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03599": "|**2025-10-04**|**Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning**|Shafeef Omar et.al.|[2510.03599](https://arxiv.org/abs/2510.03599)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05957": "|**2025-10-07**|**Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion**|Vaughn Gzenda et.al.|[2510.05957](https://arxiv.org/abs/2510.05957)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05865": "|**2025-10-07**|**The Safety Challenge of World Models for Embodied AI Agents: A Review**|Lorenzo Baraldi et.al.|[2510.05865](https://arxiv.org/abs/2510.05865)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2510.05580": "|**2025-10-07**|**MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption**|Chen Li et.al.|[2510.05580](https://arxiv.org/abs/2510.05580)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.05213": "|**2025-10-06**|**VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing**|Yixiao Wang et.al.|[2510.05213](https://arxiv.org/abs/2510.05213)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.07117": "|**2025-10-11**|**The Contingencies of Physical Embodiment Allow for Open-Endedness and Care**|Leonardo Christov-Moore et.al.|[2510.07117](https://arxiv.org/abs/2510.07117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06492": "|**2025-10-07**|**What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?**|Matthew Kim et.al.|[2510.06492](https://arxiv.org/abs/2510.06492)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.09459": "|**2025-10-13**|**Failure Prediction at Runtime for Generative Robot Policies**|Ralf R\u00f6mer et.al.|[2510.09459](https://arxiv.org/abs/2510.09459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09096": "|**2025-10-10**|**When a Robot is More Capable than a Human: Learning from Constrained Demonstrators**|Xinhu Li et.al.|[2510.09096](https://arxiv.org/abs/2510.09096)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08807": "|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Zhenyu Zhao et.al.|[2510.08807](https://arxiv.org/abs/2510.08807)|**[link](https://huggingface.co/datasets/USC-GVL/humanoid-everyday)**|\n", "2510.08759": "|**2025-10-09**|**BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities**|Yu Qi et.al.|[2510.08759](https://arxiv.org/abs/2510.08759)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08713": "|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Yifei Dong et.al.|[2510.08713](https://arxiv.org/abs/2510.08713)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang et.al.|[2510.11027](https://arxiv.org/abs/2510.11027)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.10642": "|**2025-10-12**|**UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning**|Jianke Zhang et.al.|[2510.10642](https://arxiv.org/abs/2510.10642)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10637": "|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Haoyu Zhao et.al.|[2510.10637](https://arxiv.org/abs/2510.10637)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Jinliang Zheng et.al.|[2510.10274](https://arxiv.org/abs/2510.10274)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.10221": "|**2025-10-11**|**A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots**|Hyogo Hiruma et.al.|[2510.10221](https://arxiv.org/abs/2510.10221)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10181": "|**2025-10-11**|**Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback**|Shaokai Wu et.al.|[2510.10181](https://arxiv.org/abs/2510.10181)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10125": "|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Yanjiang Guo et.al.|[2510.10125](https://arxiv.org/abs/2510.10125)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.12693": "|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Hanyang Chen et.al.|[2510.12693](https://arxiv.org/abs/2510.12693)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12483": "|**2025-10-14**|**Fast Visuomotor Policy for Robotic Manipulation**|Jingkai Jia et.al.|[2510.12483](https://arxiv.org/abs/2510.12483)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12403": "|**2025-10-14**|**Robot Learning: A Tutorial**|Francesco Capuano et.al.|[2510.12403](https://arxiv.org/abs/2510.12403)|**[link](https://huggingface.co/spaces/lerobot/robot-learning-tutorial)**|\n", "2510.12392": "|**2025-10-14**|**Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking**|Junhyuk So et.al.|[2510.12392](https://arxiv.org/abs/2510.12392)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12215": "|**2025-10-14**|**Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications**|Chanwoo Kim et.al.|[2510.12215](https://arxiv.org/abs/2510.12215)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12095": "|**2025-10-14**|**IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation**|Wenxu Zhou et.al.|[2510.12095](https://arxiv.org/abs/2510.12095)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.12072": "|**2025-10-14**|**EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making**|Zixing Lei et.al.|[2510.12072](https://arxiv.org/abs/2510.12072)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.13778": "|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Xinyi Chen et.al.|[2510.13778](https://arxiv.org/abs/2510.13778)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Haochuan Xu et.al.|[2510.13237](https://arxiv.org/abs/2510.13237)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2510.13016": "|**2025-10-16**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Tanveer Hannan et.al.|[2510.13016](https://arxiv.org/abs/2510.13016)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.12985": "|**2025-10-14**|**SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents**|Simon Sinong Zhan et.al.|[2510.12985](https://arxiv.org/abs/2510.12985)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.14930": "|**2025-10-18**|**VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning**|Binghao Huang et.al.|[2510.14930](https://arxiv.org/abs/2510.14930)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2510.14828": "|**2025-10-22**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Jinrui Liu et.al.|[2510.14828](https://arxiv.org/abs/2510.14828)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15786": "|**2025-10-23**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Xinyue Xu et.al.|[2510.15786](https://arxiv.org/abs/2510.15786)|**[link](https://huggingface.co/datasets/DEXROBOT/DexCanvas)**|\n", "2510.15352": "|**2025-10-17**|**GaussGym: An open-source real-to-sim framework for learning locomotion from pixels**|Alejandro Escontrela et.al.|[2510.15352](https://arxiv.org/abs/2510.15352)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|\n", "2510.15041": "|**2025-10-16**|**Generalized Dynamics Generation towards Scannable Physical World Model**|Yichen Li et.al.|[2510.15041](https://arxiv.org/abs/2510.15041)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17604": "|**2025-10-20**|**Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm**|Hao Qiao et.al.|[2510.17604](https://arxiv.org/abs/2510.17604)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17129": "|**2025-10-20**|**Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents**|Wenbing Tang et.al.|[2510.17129](https://arxiv.org/abs/2510.17129)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17086": "|**2025-10-20**|**Learning to Design Soft Hands using Reward Models**|Xueqian Bai et.al.|[2510.17086](https://arxiv.org/abs/2510.17086)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17059": "|**2025-10-20**|**Consistent Zero-Shot Imitation with Contrastive Goal Inference**|Kathryn Wantlin et.al.|[2510.17059](https://arxiv.org/abs/2510.17059)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16424": "|**2025-10-18**|**Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach**|Dan Guo et.al.|[2510.16424](https://arxiv.org/abs/2510.16424)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16263": "|**2025-10-21**|**NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?**|Jierui Peng et.al.|[2510.16263](https://arxiv.org/abs/2510.16263)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.16240": "|**2025-11-03**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden et.al.|[2510.16240](https://arxiv.org/abs/2510.16240)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2510.15963": "|**2025-10-27**|**ESCA: Contextualizing Embodied Agents via Scene-Graph Generation**|Jiani Huang et.al.|[2510.15963](https://arxiv.org/abs/2510.15963)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18546": "|**2025-10-21**|**EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval**|Zebin Yang et.al.|[2510.18546](https://arxiv.org/abs/2510.18546)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18518": "|**2025-10-21**|**Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning**|Fang Nan et.al.|[2510.18518](https://arxiv.org/abs/2510.18518)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang et.al.|[2510.18337](https://arxiv.org/abs/2510.18337)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18137": "|**2025-10-20**|**Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning**|Hrishikesh Sathyanarayan et.al.|[2510.18137](https://arxiv.org/abs/2510.18137)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18135": "|**2025-10-20**|**World-in-World: World Models in a Closed-Loop World**|Jiahan Zhang et.al.|[2510.18135](https://arxiv.org/abs/2510.18135)|**[link](https://huggingface.co/datasets/zonszer/WIW_datasets)**|\n", "2510.19732": "|**2025-10-22**|**Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning**|Gunshi Gupta et.al.|[2510.19732](https://arxiv.org/abs/2510.19732)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19373": "|**2025-10-22**|**Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets**|Basavasagar Patil et.al.|[2510.19373](https://arxiv.org/abs/2510.19373)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20685": "|**2025-10-30**|**C-NAV: Towards Self-Evolving Continual Object Navigation in Open World**|Ming-Ming Yu et.al.|[2510.20685](https://arxiv.org/abs/2510.20685)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20578": "|**2025-10-23**|**EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence**|Ding Zou et.al.|[2510.20578](https://arxiv.org/abs/2510.20578)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20333": "|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Chiyu Chen et.al.|[2510.20333](https://arxiv.org/abs/2510.20333)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Ajay Sridhar et.al.|[2510.20328](https://arxiv.org/abs/2510.20328)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|\n", "2510.21560": "|**2025-10-24**|**Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning**|Yuxuan Yang et.al.|[2510.21560](https://arxiv.org/abs/2510.21560)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21302": "|**2025-10-24**|**Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning**|Sanghyun Ahn et.al.|[2510.21302](https://arxiv.org/abs/2510.21302)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Yash Jangir et.al.|[2510.23571](https://arxiv.org/abs/2510.23571)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23190": "|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Pascal Benschop et.al.|[2510.23190](https://arxiv.org/abs/2510.23190)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.23121": "|**2025-10-27**|**Reliable Robotic Task Execution in the Face of Anomalies**|Bharath Santhanam et.al.|[2510.23121](https://arxiv.org/abs/2510.23121)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22789": "|**2025-10-26**|**Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning**|Abhijeet M. Kulkarni et.al.|[2510.22789](https://arxiv.org/abs/2510.22789)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22672": "|**2025-10-28**|**Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views**|Anna Deichler et.al.|[2510.22672](https://arxiv.org/abs/2510.22672)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Minho Park et.al.|[2510.22201](https://arxiv.org/abs/2510.22201)|**[link](https://huggingface.co/models/DAVIAN-Robotics/GR00T-N1-2B-tuned-RoboCasa-MG100-FrankaPandaGripper)**|\n", "2510.21817": "|**2025-10-21**|**VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting**|Xiaoyu Liu et.al.|[2510.21817](https://arxiv.org/abs/2510.21817)|**[link](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)**|\n", "2510.21771": "|**2025-10-17**|**Improving the performance of AI-powered Affordable Robotics for Assistive Tasks**|Dharunish Yugeswardeenoo et.al.|[2510.21771](https://arxiv.org/abs/2510.21771)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24161": "|**2025-10-28**|**BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Wentao Tan et.al.|[2510.24161](https://arxiv.org/abs/2510.24161)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Wenbin Ding et.al.|[2510.24109](https://arxiv.org/abs/2510.24109)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.24095": "|**2025-10-28**|**Learning Parameterized Skills from Demonstrations**|Vedant Gupta et.al.|[2510.24095](https://arxiv.org/abs/2510.24095)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23928": "|**2025-10-27**|**Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments**|Raman Jha et.al.|[2510.23928](https://arxiv.org/abs/2510.23928)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25138": "|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Yuxiang Yan et.al.|[2510.25138](https://arxiv.org/abs/2510.25138)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jiahong Chen et.al.|[2510.25122](https://arxiv.org/abs/2510.25122)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25725": "|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Eunju Kwon et.al.|[2510.25725](https://arxiv.org/abs/2510.25725)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2510.26782": "|**2025-10-30**|**Clone Deterministic 3D Worlds with Geometrically-Regularized World Models**|Zaishuo Xia et.al.|[2510.26782](https://arxiv.org/abs/2510.26782)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.26670": "|**2025-10-30**|**Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation**|Qianyou Zhao et.al.|[2510.26670](https://arxiv.org/abs/2510.26670)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27623": "|**2025-10-31**|**Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning**|Qiusi Zhan et.al.|[2510.27623](https://arxiv.org/abs/2510.27623)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|John Won et.al.|[2510.27607](https://arxiv.org/abs/2510.27607)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.27114": "|**2025-10-31**|**Learning Generalizable Visuomotor Policy through Dynamics-Alignment**|Dohyeok Lee et.al.|[2510.27114](https://arxiv.org/abs/2510.27114)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01755": "|**2025-11-03**|**3EED: Ground Everything Everywhere in 3D**|Rong Li et.al.|[2511.01755](https://arxiv.org/abs/2511.01755)|**[link](https://github.com/worldbench/3EED)**|\n", "2511.01718": "|**2025-11-03**|**Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process**|Jiayi Chen et.al.|[2511.01718](https://arxiv.org/abs/2511.01718)|**[link](https://huggingface.co/models/chenpyyy/UD-VLA_CALVIN_ABCD_D)**|\n", "2511.01224": "|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Chengmeng Li et.al.|[2511.01224](https://arxiv.org/abs/2511.01224)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03400": "|**2025-11-05**|**GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement**|Minquan Gao et.al.|[2511.03400](https://arxiv.org/abs/2511.03400)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.03167": "|**2025-11-05**|**Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning**|Xin Liu et.al.|[2511.03167](https://arxiv.org/abs/2511.03167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03001": "|**2025-11-04**|**LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation**|Gyeom Hwangbo et.al.|[2511.03001](https://arxiv.org/abs/2511.03001)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.04671": "|**2025-11-06**|**X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations**|Maximus A. Pace et.al.|[2511.04671](https://arxiv.org/abs/2511.04671)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04665": "|**2025-11-10**|**Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions**|Kaifeng Zhang et.al.|[2511.04665](https://arxiv.org/abs/2511.04665)|**[link](https://github.com/Jianghanxiao/PhysTwin)**|\n", "2511.03996": "|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Yushi Wang et.al.|[2511.03996](https://arxiv.org/abs/2511.03996)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.05203": "|**2025-11-07**|**Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space**|Linus Nwankwo et.al.|[2511.05203](https://arxiv.org/abs/2511.05203)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05199": "|**2025-11-07**|**Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation**|Yichen Zhu et.al.|[2511.05199](https://arxiv.org/abs/2511.05199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04831": "|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|NVIDIA et.al.|[2511.04831](https://arxiv.org/abs/2511.04831)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04769": "|**2025-11-06**|**ReGen: Generative Robot Simulation via Inverse Design**|Phat Nguyen et.al.|[2511.04769](https://arxiv.org/abs/2511.04769)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2511.07416": "|**2025-11-10**|**Robot Learning from a Physical World Model**|Jiageng Mao et.al.|[2511.07416](https://arxiv.org/abs/2511.07416)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.07412": "|**2025-11-10**|**TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research**|Han Zhang et.al.|[2511.07412](https://arxiv.org/abs/2511.07412)|**[link](https://github.com/wonderNefelibata/Awesome-LRM-Safety)**|\n", "2511.06667": "|**2025-11-10**|**Rapidly Learning Soft Robot Control via Implicit Time-Stepping**|Andrew Choi et.al.|[2511.06667](https://arxiv.org/abs/2511.06667)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2511.05622": "|**2025-11-06**|**Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition**|Nicholas Babey et.al.|[2511.05622](https://arxiv.org/abs/2511.05622)|**[link](https://github.com/Lionelsy/RSS)**|\n", "2211.07028": "|**2022-11-15**|**Learning Visualization Policies of Augmented Reality for Human-Robot Collaboration**|Kishan Chandan et.al.|[2211.07028](https://arxiv.org/abs/2211.07028)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2303.06582": "|**2023-03-14**|**Certifiably-correct Control Policies for Safe Learning and Adaptation in Assistive Robotics**|Keyvan Majd et.al.|[2303.06582](https://arxiv.org/abs/2303.06582)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1907.03423": "|**2020-05-19**|**On-Policy Robot Imitation Learning from a Converging Supervisor**|Ashwin Balakrishna et.al.|[1907.03423](https://arxiv.org/abs/1907.03423)|**[link](https://github.com/kristery/Awesome-Imitation-Learning)**|\n", "2505.05753": "|**2025-09-01**|**Towards Embodiment Scaling Laws in Robot Locomotion**|Bo Ai et.al.|[2505.05753](https://arxiv.org/abs/2505.05753)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2212.04573": "|**2022-12-12**|**Modularity through Attention: Efficient Training and Transfer of Language-Conditioned Policies for Robot Manipulation**|Yifan Zhou et.al.|[2212.04573](https://arxiv.org/abs/2212.04573)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1806.09351": "|**2020-03-05**|**Multi-objective Model-based Policy Search for Data-efficient Learning with Sparse Rewards**|Rituraj Kaushik et.al.|[1806.09351](https://arxiv.org/abs/1806.09351)|**[link](https://github.com/sferes2/sferes2)**|\n", "2309.01267": "|**2023-11-03**|**Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy**|Haimin Hu et.al.|[2309.01267](https://arxiv.org/abs/2309.01267)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1810.07167": "|**2018-10-17**|**Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation**|Gregory Kahn et.al.|[1810.07167](https://arxiv.org/abs/1810.07167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1907.07202": "|**2021-11-30**|**Understanding Teacher Gaze Patterns for Robot Learning**|Akanksha Saran et.al.|[1907.07202](https://arxiv.org/abs/1907.07202)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1405.6341": "|**2017-06-15**|**Efficient Model Learning for Human-Robot Collaborative Tasks**|Stefanos Nikolaidis et.al.|[1405.6341](https://arxiv.org/abs/1405.6341)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2406.19464": "|**2024-11-05**|**ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data**|Zeyi Liu et.al.|[2406.19464](https://arxiv.org/abs/2406.19464)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2010.00824": "|**2021-09-15**|**Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds**|Lirui Wang et.al.|[2010.00824](https://arxiv.org/abs/2010.00824)|**[link](https://github.com/GeorgeDu/vision-based-robotic-grasping)**|\n", "2410.13816": "|**2025-02-26**|**Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance**|Mitsuhiko Nakamoto et.al.|[2410.13816](https://arxiv.org/abs/2410.13816)|**[link](https://github.com/OpenHelix-Team/Awesome-VLA-RL)**|\n", "2310.14196": "|**2025-05-07**|**Learning to Discern: Imitating Heterogeneous Human Demonstrations with Preference and Representation Learning**|Sachit Kuhar et.al.|[2310.14196](https://arxiv.org/abs/2310.14196)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2407.05425": "|**2024-10-08**|**ClutterGen: A Cluttered Scene Generator for Robot Learning**|Yinsen Jia et.al.|[2407.05425](https://arxiv.org/abs/2407.05425)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2010.09170": "|**2021-10-22**|**Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability**|Hai Nguyen et.al.|[2010.09170](https://arxiv.org/abs/2010.09170)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1911.11744": "|**2019-11-27**|**Imitation Learning of Robot Policies by Combining Language, Vision and Demonstration**|Simon Stepputtis et.al.|[1911.11744](https://arxiv.org/abs/1911.11744)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2407.20635": "|**2025-02-26**|**Autonomous Improvement of Instruction Following Skills via Foundation Models**|Zhiyuan Zhou et.al.|[2407.20635](https://arxiv.org/abs/2407.20635)|**[link](https://github.com/showlab/Awesome-Robotics-Diffusion)**|\n", "2507.02864": "|**2025-09-23**|**The Sound of Simulation: Learning Multimodal Sim-to-Real Robot Policies with Generative Audio**|Renhao Wang et.al.|[2507.02864](https://arxiv.org/abs/2507.02864)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2203.12601": "|**2022-11-21**|**R3M: A Universal Visual Representation for Robot Manipulation**|Suraj Nair et.al.|[2203.12601](https://arxiv.org/abs/2203.12601)|**[link](https://github.com/GT-RIPL/Awesome-LLM-Robotics)**|\n", "2401.13127": "|**2024-01-25**|**Generalization of Heterogeneous Multi-Robot Policies via Awareness and Communication of Capabilities**|Pierce Howell et.al.|[2401.13127](https://arxiv.org/abs/2401.13127)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2405.10315": "|**2024-10-15**|**TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction**|Yunfan Jiang et.al.|[2405.10315](https://arxiv.org/abs/2405.10315)|**[link](https://huggingface.co/models/transic-robot/models-moved)**|\n", "2007.04959": "|**2020-07-23**|**Assistive VR Gym: Interactions with Real People to Improve Virtual Assistive Robots**|Zackory Erickson et.al.|[2007.04959](https://arxiv.org/abs/2007.04959)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2211.02231": "|**2022-11-07**|**Residual Skill Policies: Learning an Adaptable Skill-based Action Space for Reinforcement Learning for Robotics**|Krishan Rana et.al.|[2211.02231](https://arxiv.org/abs/2211.02231)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1701.07790": "|**2017-06-15**|**Game-Theoretic Modeling of Human Adaptation in Human-Robot Collaboration**|Stefanos Nikolaidis et.al.|[1701.07790](https://arxiv.org/abs/1701.07790)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2203.17138": "|**2022-04-01**|**Imitate and Repurpose: Learning Reusable Robot Movement Skills From Human and Animal Behaviors**|Steven Bohez et.al.|[2203.17138](https://arxiv.org/abs/2203.17138)|**[link](https://github.com/curieuxjy/Awesome_Quadrupedal_Robots)**|\n", "2007.14290": "|**2020-07-29**|**Learning Stable Manoeuvres in Quadruped Robots from Expert Demonstrations**|Sashank Tirumala et.al.|[2007.14290](https://arxiv.org/abs/2007.14290)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2011.04999": "|**2020-11-11**|**Untangling Dense Knots by Learning Task-Relevant Keypoints**|Jennifer Grannen et.al.|[2011.04999](https://arxiv.org/abs/2011.04999)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2410.08504": "|**2024-10-14**|**CoHRT: A Collaboration System for Human-Robot Teamwork**|Sujan Sarker et.al.|[2410.08504](https://arxiv.org/abs/2410.08504)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1909.06415": "|**2019-09-17**|**Enabling Intuitive Human-Robot Teaming Using Augmented Reality and Gesture Control**|Jason M. Gregory et.al.|[1909.06415](https://arxiv.org/abs/1909.06415)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2110.00438": "|**2021-11-10**|**Guiding Evolutionary Strategies by Differentiable Robot Simulators**|Vladislav Kurenkov et.al.|[2110.00438](https://arxiv.org/abs/2110.00438)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2312.07214": "|**2024-03-22**|**Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming**|Younes Lakhnati et.al.|[2312.07214](https://arxiv.org/abs/2312.07214)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2303.01497": "|**2023-03-03**|**Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations**|Siddhant Haldar et.al.|[2303.01497](https://arxiv.org/abs/2303.01497)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2411.01813": "|**2024-11-05**|**So You Think You Can Scale Up Autonomous Robot Data Collection?**|Suvir Mirchandani et.al.|[2411.01813](https://arxiv.org/abs/2411.01813)|**[link](https://github.com/YanjieZe/Paper-List)**|\n", "2510.22740": "|**2025-10-28**|**Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM**|Sai Krishna Ghanta et.al.|[2510.22740](https://arxiv.org/abs/2510.22740)|**[link](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO)**|\n", "2008.04460": "|**2020-11-10**|**Hardware as Policy: Mechanical and Computational Co-Optimization using Deep Reinforcement Learning**|Tianjian Chen et.al.|[2008.04460](https://arxiv.org/abs/2008.04460)|**[link](https://github.com/Yuxing-Wang-THU/SurveyBrainBody)**|\n", "2305.12171": "|**2023-11-14**|**Diffusion Co-Policy for Synergistic Human-Robot Collaborative Tasks**|Eley Ng et.al.|[2305.12171](https://arxiv.org/abs/2305.12171)|**[link](https://github.com/opendilab/awesome-diffusion-model-in-rl)**|\n", "2012.12291": "|**2022-08-02**|**Learning a Group-Aware Policy for Robot Navigation**|Kapil Katyal et.al.|[2012.12291](https://arxiv.org/abs/2012.12291)|**[link](https://github.com/PaoPaoRobot/IROS2022-paper-list)**|\n", "2301.02555": "|**2023-01-09**|**\"No, to the Right\" -- Online Language Corrections for Robotic Manipulation via Shared Autonomy**|Yuchen Cui et.al.|[2301.02555](https://arxiv.org/abs/2301.02555)|**[link](https://github.com/GT-RIPL/Awesome-LLM-Robotics)**|\n", "2207.06572": "|**2022-11-23**|**i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight Human-Robot Interaction Loops**|Saminda Abeyruwan et.al.|[2207.06572](https://arxiv.org/abs/2207.06572)|**[link](https://github.com/luweiagi/machine-learning-notes)**|\n", "1909.11639": "|**2019-12-17**|**ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots**|Michael Ahn et.al.|[1909.11639](https://arxiv.org/abs/1909.11639)|**[link](https://github.com/GeorgeDu/vision-based-robotic-grasping)**|\n", "1810.01217": "|**2018-10-03**|**Sparse Gaussian Process Temporal Difference Learning for Marine Robot Navigation**|John Martin et.al.|[1810.01217](https://arxiv.org/abs/1810.01217)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2503.05652": "|**2025-08-26**|**BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities**|Yunfan Jiang et.al.|[2503.05652](https://arxiv.org/abs/2503.05652)|**[link](https://huggingface.co/datasets/behavior-robot-suite/data)**|\n", "2211.09006": "|**2022-11-17**|**ToolFlowNet: Robotic Manipulation with Tools via Predicting Tool Flow from Point Clouds**|Daniel Seita et.al.|[2211.09006](https://arxiv.org/abs/2211.09006)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2409.16451": "|**2025-09-09**|**ARCH: Hierarchical Hybrid Learning for Long-Horizon Contact-Rich Robotic Assembly**|Jiankai Sun et.al.|[2409.16451](https://arxiv.org/abs/2409.16451)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2506.22028": "|**2025-06-30**|**LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies**|Ossi Parikka et.al.|[2506.22028](https://arxiv.org/abs/2506.22028)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|\n", "2505.06771": "|**2025-11-12**|**JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes**|Shalin Anand Jain et.al.|[2505.06771](https://arxiv.org/abs/2505.06771)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10635": "|**2025-11-13**|**Robot Crash Course: Learning Soft and Stylized Falling**|Pascal Strauch et.al.|[2511.10635](https://arxiv.org/abs/2511.10635)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.10560": "|**2025-11-14**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer**|Haosong Peng et.al.|[2511.10560](https://arxiv.org/abs/2511.10560)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10448": "|**2025-11-13**|**Improving dependability in robotized bolting operations**|Lorenzo Pagliara et.al.|[2511.10448](https://arxiv.org/abs/2511.10448)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10376": "|**2025-11-14**|**MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation**|Xun Huang et.al.|[2511.10376](https://arxiv.org/abs/2511.10376)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10110": "|**2025-11-13**|**Learning a Thousand Tasks in a Day**|Kamil Dreczkowski et.al.|[2511.10110](https://arxiv.org/abs/2511.10110)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10087": "|**2025-11-13**|**Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning**|Haidong Huang et.al.|[2511.10087](https://arxiv.org/abs/2511.10087)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2511.10079": "|**2025-11-13**|**Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks**|Yizheng Wang et.al.|[2511.10079](https://arxiv.org/abs/2511.10079)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10017": "|**2025-11-13**|**AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models**|Xinyi Wang et.al.|[2511.10017](https://arxiv.org/abs/2511.10017)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09964": "|**2025-11-13**|**EnvTrace: Simulation-Based Semantic Evaluation of LLM Code via Execution Trace Alignment -- Demonstrated at Synchrotron Beamlines**|Noah van der Vleuten et.al.|[2511.09964](https://arxiv.org/abs/2511.09964)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.09958": "|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Xiangyi Wei et.al.|[2511.09958](https://arxiv.org/abs/2511.09958)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09923": "|**2025-11-14**|**Harnessing Bounded-Support Evolution Strategies for Policy Refinement**|Ethan Hirschowitz et.al.|[2511.09923](https://arxiv.org/abs/2511.09923)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09836": "|**2025-11-13**|**Provably Safe Stein Variational Clarity-Aware Informative Planning**|Kaleb Ben Naveed et.al.|[2511.09836](https://arxiv.org/abs/2511.09836)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09790": "|**2025-11-12**|**A Robust Task-Level Control Architecture for Learned Dynamical Systems**|Eshika Pathak et.al.|[2511.09790](https://arxiv.org/abs/2511.09790)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09737": "|**2025-11-12**|**Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy**|Bram Grooten et.al.|[2511.09737](https://arxiv.org/abs/2511.09737)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09727": "|**2025-11-12**|**Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard**|Stelios Zarifis et.al.|[2511.09727](https://arxiv.org/abs/2511.09727)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09681": "|**2025-11-12**|**SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning**|Tairan Huang et.al.|[2511.09681](https://arxiv.org/abs/2511.09681)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09558": "|**2025-11-12**|**IFG: Internet-Scale Guidance for Functional Grasping Generation**|Ray Muxin Liu et.al.|[2511.09558](https://arxiv.org/abs/2511.09558)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09515": "|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Fangqi Zhu et.al.|[2511.09515](https://arxiv.org/abs/2511.09515)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2511.09497": "|**2025-11-12**|**Fundamentals of Physical AI**|Vahid Salehi et.al.|[2511.09497](https://arxiv.org/abs/2511.09497)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09484": "|**2025-11-12**|**SPIDER: Scalable Physics-Informed Dexterous Retargeting**|Chaoyi Pan et.al.|[2511.09484](https://arxiv.org/abs/2511.09484)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.09602": "|**2025-11-12**|**ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset**|Sizhe Wang et.al.|[2511.09602](https://arxiv.org/abs/2511.09602)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09331": "|**2025-11-12**|**CoRL-MPPI: Enhancing MPPI With Learnable Behaviours For Efficient And Provably-Safe Multi-Robot Collision Avoidance**|Stepan Dergachev et.al.|[2511.09331](https://arxiv.org/abs/2511.09331)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09302": "|**2025-11-12**|**UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning**|Yan Huang et.al.|[2511.09302](https://arxiv.org/abs/2511.09302)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.09241": "|**2025-11-12**|**Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots**|Yuxi Wei et.al.|[2511.09241](https://arxiv.org/abs/2511.09241)|null|\n", "2511.09141": "|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Xuetao Li et.al.|[2511.09141](https://arxiv.org/abs/2511.09141)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.09104": "|**2025-11-13**|**Decoupling Torque and Stiffness: A Unified Modeling and Control Framework for Antagonistic Artificial Muscles**|Amirhossein Kazemipour et.al.|[2511.09104](https://arxiv.org/abs/2511.09104)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09091": "|**2025-11-12**|**APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots**|Shivam Sood et.al.|[2511.09091](https://arxiv.org/abs/2511.09091)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09020": "|**2025-11-12**|**A Quantum Tunneling and Bio-Phototactic Driven Enhanced Dwarf Mongoose Optimizer for UAV Trajectory Planning and Engineering Problem**|Mingyang Yu et.al.|[2511.09020](https://arxiv.org/abs/2511.09020)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.08942": "|**2025-11-12**|**Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning**|Mobin Habibpour et.al.|[2511.08942](https://arxiv.org/abs/2511.08942)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08935": "|**2025-11-12**|**Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation**|Ningnan Wang et.al.|[2511.08935](https://arxiv.org/abs/2511.08935)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08926": "|**2025-11-12**|**Achieving Equilibrium under Utility Heterogeneity: An Agent-Attention Framework for Multi-Agent Multi-Objective Reinforcement Learning**|Zhuhui Li et.al.|[2511.08926](https://arxiv.org/abs/2511.08926)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08912": "|**2025-11-12**|**A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction**|Jinyu Zhang et.al.|[2511.08912](https://arxiv.org/abs/2511.08912)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08778": "|**2025-11-11**|**Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains**|Richard Cheng et.al.|[2511.08778](https://arxiv.org/abs/2511.08778)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08741": "|**2025-11-13**|**ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements**|Kai S. Yun et.al.|[2511.08741](https://arxiv.org/abs/2511.08741)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08732": "|**2025-11-11**|**Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration**|Marta Lagomarsino et.al.|[2511.08732](https://arxiv.org/abs/2511.08732)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08585": "|**2025-11-11**|**Simulating the Visual World with Artificial Intelligence: A Roadmap**|Jingtong Yue et.al.|[2511.08585](https://arxiv.org/abs/2511.08585)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.08583": "|**2025-11-11**|**SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment**|Rong Xue et.al.|[2511.08583](https://arxiv.org/abs/2511.08583)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08545": "|**2025-11-11**|**RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses**|Sriram Srinivasan et.al.|[2511.08545](https://arxiv.org/abs/2511.08545)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08502": "|**2025-11-11**|**Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1**|Ruya Karagulle et.al.|[2511.08502](https://arxiv.org/abs/2511.08502)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08490": "|**2025-11-11**|**A Supervised Autonomous Resection and Retraction Framework for Transurethral Enucleation of the Prostatic Median Lobe**|Mariana Smith et.al.|[2511.08490](https://arxiv.org/abs/2511.08490)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08454": "|**2025-11-11**|**Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface**|Tianyu Jia et.al.|[2511.08454](https://arxiv.org/abs/2511.08454)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08425": "|**2025-11-11**|**HardFlow: Hard-Constrained Sampling for Flow-Matching Models via Trajectory Optimization**|Zeyang Li et.al.|[2511.08425](https://arxiv.org/abs/2511.08425)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.08377": "|**2025-11-11**|**Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm**|Michael Bowman et.al.|[2511.08377](https://arxiv.org/abs/2511.08377)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08299": "|**2025-11-11**|**Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot**|Zhiang Liu et.al.|[2511.08299](https://arxiv.org/abs/2511.08299)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08297": "|**2025-11-11**|**Work-in-Progress: Function-as-Subtask API Replacing Publish/Subscribe for OS-Native DAG Scheduling**|Takahiro Ishikawa-Aso et.al.|[2511.08297](https://arxiv.org/abs/2511.08297)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08294": "|**2025-11-11**|**SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering**|Laura Bragagnolo et.al.|[2511.08294](https://arxiv.org/abs/2511.08294)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.08277": "|**2025-11-11**|**X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention**|Dehan Shen et.al.|[2511.08277](https://arxiv.org/abs/2511.08277)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08231": "|**2025-11-11**|**Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems**|Devin Hunter et.al.|[2511.08231](https://arxiv.org/abs/2511.08231)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08133": "|**2025-11-11**|**OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition**|Lixu Sun et.al.|[2511.08133](https://arxiv.org/abs/2511.08133)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08086": "|**2025-11-11**|**Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks**|Muthukumar Pandaram et.al.|[2511.08086](https://arxiv.org/abs/2511.08086)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.11529": "|**2025-11-14**|**Terrain Costmap Generation via Scaled Preference Conditioning**|Luisa Mao et.al.|[2511.11529](https://arxiv.org/abs/2511.11529)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11520": "|**2025-11-17**|**Scalable Policy Evaluation with Video World Models**|Wei-Cheng Tseng et.al.|[2511.11520](https://arxiv.org/abs/2511.11520)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.11512": "|**2025-11-14**|**Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities**|Yiyun Zhou et.al.|[2511.11512](https://arxiv.org/abs/2511.11512)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11478": "|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Nhat Chung et.al.|[2511.11478](https://arxiv.org/abs/2511.11478)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11456": "|**2025-11-14**|**SimTac: A Physics-Based Simulator for Vision-Based Tactile Sensing with Biomorphic Structures**|Xuyang Zhang et.al.|[2511.11456](https://arxiv.org/abs/2511.11456)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11310": "|**2025-11-14**|**Simulating an Autonomous System in CARLA using ROS 2**|Joseph Abdo et.al.|[2511.11310](https://arxiv.org/abs/2511.11310)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11223": "|**2025-11-14**|**Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects**|Sverre Herland et.al.|[2511.11223](https://arxiv.org/abs/2511.11223)|null|\n", "2511.11218": "|**2025-11-14**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Chenhao Liu et.al.|[2511.11218](https://arxiv.org/abs/2511.11218)|null|\n", "2511.11210": "|**2025-11-14**|**One-to-N Backdoor Attack in 3D Point Cloud via Spherical Trigger**|Dongmei Shan et.al.|[2511.11210](https://arxiv.org/abs/2511.11210)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.11052": "|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Jinxuan Zhu et.al.|[2511.11052](https://arxiv.org/abs/2511.11052)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11025": "|**2025-11-14**|**AirCopBench: A Benchmark for Multi-drone Collaborative Embodied Perception and Reasoning**|Jirong Zha et.al.|[2511.11025](https://arxiv.org/abs/2511.11025)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10987": "|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Wenbin Bai et.al.|[2511.10987](https://arxiv.org/abs/2511.10987)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10946": "|**2025-11-14**|**Abstract 3D Perception for Spatial Intelligence in Vision-Language Models**|Yifan Liu et.al.|[2511.10946](https://arxiv.org/abs/2511.10946)|**[link](https://github.com/mll-lab-nu/Awesome-Spatial-Intelligence-in-VLM)**|\n", "2511.10874": "|**2025-11-14**|**Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation**|Yorai Shaoul et.al.|[2511.10874](https://arxiv.org/abs/2511.10874)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10864": "|**2025-11-14**|**WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot**|Jose Vasquez et.al.|[2511.10864](https://arxiv.org/abs/2511.10864)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10833": "|**2025-11-13**|**SURFACEBENCH: Can Self-Evolving LLMs Find the Equations of 3D Scientific Surfaces?**|Sanchit Kabra et.al.|[2511.10833](https://arxiv.org/abs/2511.10833)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10766": "|**2025-11-13**|**Expert Consensus-based Video-Based Assessment Tool for Workflow Analysis in Minimally Invasive Colorectal Surgery: Development and Validation of ColoWorkflow**|Pooja P Jain et.al.|[2511.10766](https://arxiv.org/abs/2511.10766)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10762": "|**2025-11-13**|**Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues**|Nikolaos Tsagkas et.al.|[2511.10762](https://arxiv.org/abs/2511.10762)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.13710": "|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Jianglong Ye et.al.|[2511.13710](https://arxiv.org/abs/2511.13710)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13707": "|**2025-11-17**|**OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving**|Xiaoyu Liang et.al.|[2511.13707](https://arxiv.org/abs/2511.13707)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13648": "|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziang Cao et.al.|[2511.13648](https://arxiv.org/abs/2511.13648)|**[link](https://huggingface.co/models/Caoza/PhysX-Anything)**|\n", "2511.13530": "|**2025-11-17**|**Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety**|Vesna Poprcova et.al.|[2511.13530](https://arxiv.org/abs/2511.13530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13524": "|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Yuhang Peng et.al.|[2511.13524](https://arxiv.org/abs/2511.13524)|**[link](https://huggingface.co/datasets/Astronaut-PENG/FreeAskWorld)**|\n", "2511.13488": "|**2025-11-17**|**InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE**|Lipeng Wang et.al.|[2511.13488](https://arxiv.org/abs/2511.13488)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13459": "|**2025-11-17**|**Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness**|Bingkun Huang et.al.|[2511.13459](https://arxiv.org/abs/2511.13459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13411": "|**2025-11-17**|**An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence**|Przemyslaw Chojecki et.al.|[2511.13411](https://arxiv.org/abs/2511.13411)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13327": "|**2025-11-17**|**ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning**|Juntao Jian et.al.|[2511.13327](https://arxiv.org/abs/2511.13327)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13312": "|**2025-11-17**|**EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation**|Jonas Bode et.al.|[2511.13312](https://arxiv.org/abs/2511.13312)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13195": "|**2025-11-17**|**Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection**|Soyul Lee et.al.|[2511.13195](https://arxiv.org/abs/2511.13195)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13071": "|**2025-11-17**|**Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers**|Michal Levin et.al.|[2511.13071](https://arxiv.org/abs/2511.13071)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13042": "|**2025-11-17**|**APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation**|Yong Li et.al.|[2511.13042](https://arxiv.org/abs/2511.13042)|**[link](https://github.com/ryanbgriffiths/ICRA2024PaperList)**|\n", "2511.12977": "|**2025-11-18**|**ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes**|Yixuan Yang et.al.|[2511.12977](https://arxiv.org/abs/2511.12977)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12972": "|**2025-11-17**|**SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models**|Siddarth Narasimhan et.al.|[2511.12972](https://arxiv.org/abs/2511.12972)|**[link](https://github.com/3D-Vision-World/awesome-NeRF-and-3DGS-SLAM)**|\n", "2511.12937": "|**2025-11-17**|**Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models**|Guoyan Wang et.al.|[2511.12937](https://arxiv.org/abs/2511.12937)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12912": "|**2025-11-17**|**DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping**|Yingting Zhou et.al.|[2511.12912](https://arxiv.org/abs/2511.12912)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12896": "|**2025-11-17**|**Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction**|Jun Huo et.al.|[2511.12896](https://arxiv.org/abs/2511.12896)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12878": "|**2025-11-18**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Junyi Ma et.al.|[2511.12878](https://arxiv.org/abs/2511.12878)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12848": "|**2025-11-17**|**Structured Imitation Learning of Interactive Policies through Inverse Games**|Max M. Sun et.al.|[2511.12848](https://arxiv.org/abs/2511.12848)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12844": "|**2025-11-17**|**Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback**|Julia Santaniello et.al.|[2511.12844](https://arxiv.org/abs/2511.12844)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12779": "|**2025-11-16**|**Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation**|Zhenshuo Zhang et.al.|[2511.12779](https://arxiv.org/abs/2511.12779)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12676": "|**2025-11-16**|**BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections**|Subin Varghese et.al.|[2511.12676](https://arxiv.org/abs/2511.12676)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12650": "|**2025-11-16**|**Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning**|Arvind Kumar Mishra et.al.|[2511.12650](https://arxiv.org/abs/2511.12650)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12526": "|**2025-11-16**|**Botany Meets Robotics in Alpine Scree Monitoring**|Davide De Benedittis et.al.|[2511.12526](https://arxiv.org/abs/2511.12526)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12436": "|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Xiaoshuai Hao et.al.|[2511.12436](https://arxiv.org/abs/2511.12436)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12405": "|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|Hyunki Seong et.al.|[2511.12405](https://arxiv.org/abs/2511.12405)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12390": "|**2025-11-15**|**Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control**|Sanjar Atamuradov et.al.|[2511.12390](https://arxiv.org/abs/2511.12390)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12383": "|**2025-11-15**|**Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks**|Sanjar Atamuradov et.al.|[2511.12383](https://arxiv.org/abs/2511.12383)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12368": "|**2025-11-15**|**Fast Reasoning Segmentation for Images and Videos**|Yiqing Shen et.al.|[2511.12368](https://arxiv.org/abs/2511.12368)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12361": "|**2025-11-15**|**SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty**|Leroy D'Souza et.al.|[2511.12361](https://arxiv.org/abs/2511.12361)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12319": "|**2025-11-15**|**Decision and Gender Biases in Large Language Models: A Behavioral Economic Perspective**|Luca Corazzini et.al.|[2511.12319](https://arxiv.org/abs/2511.12319)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12237": "|**2025-11-15**|**Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration**|Alysson Ribeiro da Silva et.al.|[2511.12237](https://arxiv.org/abs/2511.12237)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12232": "|**2025-11-18**|**SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation**|Lingfeng Zhang et.al.|[2511.12232](https://arxiv.org/abs/2511.12232)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.12184": "|**2025-11-15**|**Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance**|Jun Huo et.al.|[2511.12184](https://arxiv.org/abs/2511.12184)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12101": "|**2025-11-15**|**Decoupled Action Head: Confining Task Knowledge to Conditioning Layers**|Jian Zhou et.al.|[2511.12101](https://arxiv.org/abs/2511.12101)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12040": "|**2025-11-15**|**SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images**|Xinyuan Hu et.al.|[2511.12040](https://arxiv.org/abs/2511.12040)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12022": "|**2025-11-15**|**SBAMP: Sampling Based Adaptive Motion Planning**|Anh-Quan Pham et.al.|[2511.12022](https://arxiv.org/abs/2511.12022)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11967": "|**2025-11-15**|**Bootstrapped LLM Semantics for Context-Aware Path Planning**|Mani Amani et.al.|[2511.11967](https://arxiv.org/abs/2511.11967)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11899": "|**2025-11-14**|**End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction**|Xi Li et.al.|[2511.11899](https://arxiv.org/abs/2511.11899)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11847": "|**2025-11-14**|**A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches**|Ryan Singh et.al.|[2511.11847](https://arxiv.org/abs/2511.11847)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14759": "|**2025-11-19**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Physical Intelligence et.al.|[2511.14759](https://arxiv.org/abs/2511.14759)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14756": "|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Lai Wei et.al.|[2511.14756](https://arxiv.org/abs/2511.14756)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al.|[2511.14659](https://arxiv.org/abs/2511.14659)|**[link](https://huggingface.co/models/declare-lab/nora-1.5)**|\n", "2511.14565": "|**2025-11-18**|**Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language**|Minyoung Hwang et.al.|[2511.14565](https://arxiv.org/abs/2511.14565)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14434": "|**2025-11-18**|**Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies**|Marlow Fawn et.al.|[2511.14434](https://arxiv.org/abs/2511.14434)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14427": "|**2025-11-18**|**Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning**|Rickmer Krohn et.al.|[2511.14427](https://arxiv.org/abs/2511.14427)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14396": "|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi et.al.|[2511.14396](https://arxiv.org/abs/2511.14396)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14341": "|**2025-11-18**|**Going Places: Place Recognition in Artificial and Natural Systems**|Michael Milford et.al.|[2511.14341](https://arxiv.org/abs/2511.14341)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14330": "|**2025-11-18**|**MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning**|Yizhen Yin et.al.|[2511.14330](https://arxiv.org/abs/2511.14330)|**[link](https://github.com/Active-SLAM/Active-SLAM-Paper-List)**|\n", "2511.14327": "|**2025-11-18**|**Dual-Variable Force Characterisation method for Human-Robot Interaction in Wearable Robotics**|Felipe Ballen-Moreno et.al.|[2511.14327](https://arxiv.org/abs/2511.14327)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14286": "|**2025-11-18**|**NeuralBoneReg: A Novel Self-Supervised Method for Robust and Accurate Multi-Modal Bone Surface Registration**|Luohong Wu et.al.|[2511.14286](https://arxiv.org/abs/2511.14286)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14242": "|**2025-11-18**|**TailCue: Exploring Animal-inspired Robotic Tail for Automated Vehicles Interaction**|Yuan Li et.al.|[2511.14242](https://arxiv.org/abs/2511.14242)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14237": "|**2025-11-18**|**Breaking the Passive Learning Trap: An Active Perception Strategy for Human Motion Prediction**|Juncheng Hu et.al.|[2511.14237](https://arxiv.org/abs/2511.14237)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14178": "|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Zhuo Li et.al.|[2511.14178](https://arxiv.org/abs/2511.14178)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15614": "|**2025-11-19**|**Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography**|Sai Puppala et.al.|[2511.15614](https://arxiv.org/abs/2511.15614)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15605": "|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei et.al.|[2511.15605](https://arxiv.org/abs/2511.15605)|**[link](https://github.com/sii-research/siiRL)**|\n", "2511.15597": "|**2025-11-19**|**Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition**|Xufei Wang et.al.|[2511.15597](https://arxiv.org/abs/2511.15597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15565": "|**2025-11-19**|**Scriboora: Rethinking Human Pose Forecasting**|Daniel Bermuth et.al.|[2511.15565](https://arxiv.org/abs/2511.15565)|**[link](https://github.com/halsay/ASR-TTS-paper-daily)**|\n", "2511.15550": "|**2025-11-20**|**UltraDP: Generalizable Carotid Ultrasound Scanning with Force-Aware Diffusion Policy**|Ruoqu Chen et.al.|[2511.15550](https://arxiv.org/abs/2511.15550)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15529": "|**2025-11-19**|**Decentralized Gaussian Process Classification and an Application in Subsea Robotics**|Yifei Gao et.al.|[2511.15529](https://arxiv.org/abs/2511.15529)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15520": "|**2025-11-19**|**Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies**|Gabriel Lauzier et.al.|[2511.15520](https://arxiv.org/abs/2511.15520)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15358": "|**2025-11-19**|**Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention**|Gabriele Calzolari et.al.|[2511.15358](https://arxiv.org/abs/2511.15358)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.15284": "|**2025-11-19**|**Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments**|Jonas De Maeyer et.al.|[2511.15284](https://arxiv.org/abs/2511.15284)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Jiashu Yang et.al.|[2511.15279](https://arxiv.org/abs/2511.15279)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15239": "|**2025-11-19**|**Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy**|Tomoki Nakao et.al.|[2511.15239](https://arxiv.org/abs/2511.15239)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.15218": "|**2025-11-19**|**Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding of Complex Visual Imagery**|Byoung-Hee Kwon et.al.|[2511.15218](https://arxiv.org/abs/2511.15218)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15200": "|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Tairan He et.al.|[2511.15200](https://arxiv.org/abs/2511.15200)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.15194": "|**2025-11-19**|**Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization**|Jian Deng et.al.|[2511.15194](https://arxiv.org/abs/2511.15194)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15167": "|**2025-11-19**|**Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation**|Jing Cao et.al.|[2511.15167](https://arxiv.org/abs/2511.15167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15105": "|**2025-11-19**|**Painted Heart Beats**|Angshu Adhya et.al.|[2511.15105](https://arxiv.org/abs/2511.15105)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14988": "|**2025-11-19**|**An Alignment-Based Approach to Learning Motions from Demonstrations**|Alex Cuellar et.al.|[2511.14988](https://arxiv.org/abs/2511.14988)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14905": "|**2025-11-18**|**Automated laboratory x-ray diffractometer and fluorescence spectrometer for high-throughput materials characterization**|Hyun Sang Park et.al.|[2511.14905](https://arxiv.org/abs/2511.14905)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14884": "|**2025-11-18**|**GeoSceneGraph: Geometric Scene Graph Diffusion Model for Text-guided 3D Indoor Scene Synthesis**|Antonio Ruiz et.al.|[2511.14884](https://arxiv.org/abs/2511.14884)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.16661": "|**2025-11-20**|**Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations**|Irmak Guzey et.al.|[2511.16661](https://arxiv.org/abs/2511.16661)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.16650": "|**2025-11-20**|**Late-decoupled 3D Hierarchical Semantic Segmentation with Semantic Prototype Discrimination based Bi-branch Supervision**|Shuyu Cao et.al.|[2511.16650](https://arxiv.org/abs/2511.16650)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16602": "|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Yi Zhang et.al.|[2511.16602](https://arxiv.org/abs/2511.16602)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16596": "|**2025-11-20**|**Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies**|Zohar Rimon et.al.|[2511.16596](https://arxiv.org/abs/2511.16596)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16593": "|**2025-11-20**|**Green Resilience of Cyber-Physical Systems: Doctoral Dissertation**|Diaeddin Rimawi et.al.|[2511.16593](https://arxiv.org/abs/2511.16593)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16518": "|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Xiaoshuai Hao et.al.|[2511.16518](https://arxiv.org/abs/2511.16518)|**[link](https://huggingface.co/models/XiaomiMiMo/MiMo-Embodied-7B)**|\n", "2511.16430": "|**2025-11-20**|**Graph Neural Networks for Surgical Scene Segmentation**|Yihan Li et.al.|[2511.16430](https://arxiv.org/abs/2511.16430)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.16407": "|**2025-11-20**|**LAOF: Robust Latent Action Learning with Optical Flow Constraints**|Xizhou Bu et.al.|[2511.16407](https://arxiv.org/abs/2511.16407)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16390": "|**2025-11-20**|**Robot Metacognition: Decision Making with Confidence for Tool Invention**|Ajith Anil Meera et.al.|[2511.16390](https://arxiv.org/abs/2511.16390)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16347": "|**2025-11-20**|**The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks**|Chunyang Li et.al.|[2511.16347](https://arxiv.org/abs/2511.16347)|**[link](https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak)**|\n", "2511.16333": "|**2025-11-20**|**Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning**|Mohammad Areeb Qazi et.al.|[2511.16333](https://arxiv.org/abs/2511.16333)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16330": "|**2025-11-20**|**Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning**|Shreyas Kumar et.al.|[2511.16330](https://arxiv.org/abs/2511.16330)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16306": "|**2025-11-20**|**InEKFormer: A Hybrid State Estimator for Humanoid Robots**|Lasse Hohmeyer et.al.|[2511.16306](https://arxiv.org/abs/2511.16306)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.16223": "|**2025-11-20**|**DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks**|Vincenzo Pomponi et.al.|[2511.16223](https://arxiv.org/abs/2511.16223)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.16203": "|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan et.al.|[2511.16203](https://arxiv.org/abs/2511.16203)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Yi Yang et.al.|[2511.16175](https://arxiv.org/abs/2511.16175)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16166": "|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Zeting Liu et.al.|[2511.16166](https://arxiv.org/abs/2511.16166)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16158": "|**2025-11-20**|**MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics**|Lara Bergmann et.al.|[2511.16158](https://arxiv.org/abs/2511.16158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16140": "|**2025-11-20**|**Real-Time 3D Object Detection with Inference-Aligned Learning**|Chenyu Zhao et.al.|[2511.16140](https://arxiv.org/abs/2511.16140)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16050": "|**2025-11-20**|**Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers**|Takeru Tsunoori et.al.|[2511.16050](https://arxiv.org/abs/2511.16050)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15997": "|**2025-11-20**|**Sensorium Arc: AI Agent System for Oceanic Data Exploration and Interactive Eco-Art**|Noah Bissell et.al.|[2511.15997](https://arxiv.org/abs/2511.15997)|null|\n", "2511.15956": "|**2025-11-20**|**The Role of Consequential and Functional Sound in Human-Robot Interaction: Toward Audio Augmented Reality Interfaces**|Aliyah Smith et.al.|[2511.15956](https://arxiv.org/abs/2511.15956)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15914": "|**2025-11-19**|**I've Changed My Mind: Robots Adapting to Changing Human Goals during Collaboration**|Debasmita Ghose et.al.|[2511.15914](https://arxiv.org/abs/2511.15914)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17502": "|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen et.al.|[2511.17502](https://arxiv.org/abs/2511.17502)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.17467": "|**2025-11-21**|**PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM**|Siqi Liang et.al.|[2511.17467](https://arxiv.org/abs/2511.17467)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2511.17441": "|**2025-11-21**|**RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation**|Shihan Wu et.al.|[2511.17441](https://arxiv.org/abs/2511.17441)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2511.17411": "|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Nikolay Nikolov et.al.|[2511.17411](https://arxiv.org/abs/2511.17411)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17401": "|**2025-11-21**|**Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment**|Xiaoshan Zhou et.al.|[2511.17401](https://arxiv.org/abs/2511.17401)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.17384": "|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yifan Li et.al.|[2511.17384](https://arxiv.org/abs/2511.17384)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17373": "|**2025-11-21**|**Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data**|Yixuan Pan et.al.|[2511.17373](https://arxiv.org/abs/2511.17373)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu et.al.|[2511.17366](https://arxiv.org/abs/2511.17366)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17335": "|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Chiori Hori et.al.|[2511.17335](https://arxiv.org/abs/2511.17335)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2511.17265": "|**2025-11-21**|**DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format**|Shady Agwa et.al.|[2511.17265](https://arxiv.org/abs/2511.17265)|**[link](https://github.com/randomrisk/NeuroAI-Daily-Arxiv)**|\n", "2511.17013": "|**2025-11-21**|**MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints**|Yiwen Ying et.al.|[2511.17013](https://arxiv.org/abs/2511.17013)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17001": "|**2025-11-21**|**Stable Offline Hand-Eye Calibration for any Robot with Just One Mark**|Sicheng Xie et.al.|[2511.17001](https://arxiv.org/abs/2511.17001)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.16949": "|**2025-11-21**|**MobileOcc: A Human-Aware Semantic Occupancy Dataset for Mobile Robots**|Junseo Kim et.al.|[2511.16949](https://arxiv.org/abs/2511.16949)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.16898": "|**2025-11-21**|**Single-Pixel Tactile Skin via Compressive Sampling**|Ariel Slepyan et.al.|[2511.16898](https://arxiv.org/abs/2511.16898)|**[link](https://github.com/aslepyan/SPTS)**|\n", "2511.19433": "|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Dong Jing et.al.|[2511.19433](https://arxiv.org/abs/2511.19433)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19432": "|**2025-11-24**|**Robotic chip-scale nanofabrication for superior consistency**|Felix M. Mayor et.al.|[2511.19432](https://arxiv.org/abs/2511.19432)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19430": "|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Dingkang Liang et.al.|[2511.19430](https://arxiv.org/abs/2511.19430)|**[link](https://huggingface.co/models/H-EmbodVis/GRANT)**|\n", "2511.19396": "|**2025-11-24**|**Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments**|Jorge Ortigoso-Narro et.al.|[2511.19396](https://arxiv.org/abs/2511.19396)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.19315": "|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Weiliang Tang et.al.|[2511.19315](https://arxiv.org/abs/2511.19315)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19236": "|**2025-11-24**|**SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control**|Yuxuan Wang et.al.|[2511.19236](https://arxiv.org/abs/2511.19236)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19217": "|**2025-11-24**|**ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment**|Wanjiang Weng et.al.|[2511.19217](https://arxiv.org/abs/2511.19217)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19204": "|**2025-11-24**|**Reference-Free Sampling-Based Model Predictive Control**|Fabian Schramm et.al.|[2511.19204](https://arxiv.org/abs/2511.19204)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.19201": "|**2025-11-24**|**Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap**|Ann-Sophia M\u00fcller et.al.|[2511.19201](https://arxiv.org/abs/2511.19201)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2511.19113": "|**2025-11-24**|**Agent Discovery in Internet of Agents: Challenges and Solutions**|Shaolong Guo et.al.|[2511.19113](https://arxiv.org/abs/2511.19113)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.19094": "|**2025-11-24**|**Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework**|David Bricher et.al.|[2511.19094](https://arxiv.org/abs/2511.19094)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19033": "|**2025-11-24**|**ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay**|Gengyuan Zhang et.al.|[2511.19033](https://arxiv.org/abs/2511.19033)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19031": "|**2025-11-24**|**Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors**|Haihang Wu et.al.|[2511.19031](https://arxiv.org/abs/2511.19031)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18960": "|**2025-11-24**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Lei Xiao et.al.|[2511.18960](https://arxiv.org/abs/2511.18960)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18950": "|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Juntao Gao et.al.|[2511.18950](https://arxiv.org/abs/2511.18950)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18929": "|**2025-11-25**|**Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search**|Zijian Song et.al.|[2511.18929](https://arxiv.org/abs/2511.18929)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18878": "|**2025-11-24**|**Accelerating Reinforcement Learning via Error-Related Human Brain Signals**|Suzie Kim et.al.|[2511.18878](https://arxiv.org/abs/2511.18878)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18857": "|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Changsheng Luo et.al.|[2511.18857](https://arxiv.org/abs/2511.18857)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18810": "|**2025-11-24**|**MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent**|Yuxia Fu et.al.|[2511.18810](https://arxiv.org/abs/2511.18810)|**[link](https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications)**|\n", "2511.18746": "|**2025-11-24**|**Any4D: Open-Prompt 4D Generation from Natural Language and Images**|Hao Li et.al.|[2511.18746](https://arxiv.org/abs/2511.18746)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18685": "|**2025-11-24**|**Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents**|Dayong Liu et.al.|[2511.18685](https://arxiv.org/abs/2511.18685)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18617": "|**2025-11-25**|**AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations**|Litian Gong et.al.|[2511.18617](https://arxiv.org/abs/2511.18617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18563": "|**2025-11-23**|**Object-centric Task Representation and Transfer using Diffused Orientation Fields**|Cem Bilaloglu et.al.|[2511.18563](https://arxiv.org/abs/2511.18563)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18561": "|**2025-11-23**|**The Evaluation for Usability Methods of Unmanned Surface Vehicles: Are Current Usability Methods Viable for Unmanned Surface Vehicles? Insights from a Multiple Case Study Approach to Human-Robot Interaction**|Zitian Peng et.al.|[2511.18561](https://arxiv.org/abs/2511.18561)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18509": "|**2025-11-23**|**SafeFall: Learning Protective Control for Humanoid Robots**|Ziyu Meng et.al.|[2511.18509](https://arxiv.org/abs/2511.18509)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.18450": "|**2025-11-23**|**ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints**|Rui Xu et.al.|[2511.18450](https://arxiv.org/abs/2511.18450)|**[link](https://github.com/mll-lab-nu/Awesome-Spatial-Intelligence-in-VLM)**|\n", "2511.18322": "|**2025-11-23**|**Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video**|Henrik Krauss et.al.|[2511.18322](https://arxiv.org/abs/2511.18322)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18299": "|**2025-11-23**|**MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing**|Steven Oh et.al.|[2511.18299](https://arxiv.org/abs/2511.18299)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18293": "|**2025-11-23**|**AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization**|Shuai Zhang et.al.|[2511.18293](https://arxiv.org/abs/2511.18293)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18243": "|**2025-11-23**|**Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters**|Eashan Vytla et.al.|[2511.18243](https://arxiv.org/abs/2511.18243)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18203": "|**2025-11-22**|**SkillWrapper: Generative Predicate Invention for Skill Abstraction**|Ziyi Yang et.al.|[2511.18203](https://arxiv.org/abs/2511.18203)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.18183": "|**2025-11-22**|**Off-Road Navigation via Implicit Neural Representation of Terrain Traversability**|Yixuan Jia et.al.|[2511.18183](https://arxiv.org/abs/2511.18183)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18173": "|**2025-11-22**|**EgoControl: Controllable Egocentric Video Generation via 3D Full-Body Poses**|Enrico Pallotta et.al.|[2511.18173](https://arxiv.org/abs/2511.18173)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18157": "|**2025-11-22**|**scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python**|Martin Schuck et.al.|[2511.18157](https://arxiv.org/abs/2511.18157)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18140": "|**2025-11-22**|**Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting**|Yilong Wang et.al.|[2511.18140](https://arxiv.org/abs/2511.18140)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.18127": "|**2025-11-22**|**SFHand: A Streaming Framework for Language-guided 3D Hand Forecasting and Embodied Manipulation**|Ruicong Liu et.al.|[2511.18127](https://arxiv.org/abs/2511.18127)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18114": "|**2025-11-22**|**ASTRA: Agentic Steerability and Risk Assessment Framework**|Itay Hazan et.al.|[2511.18114](https://arxiv.org/abs/2511.18114)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.18112": "|**2025-11-22**|**EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation**|Min Lin et.al.|[2511.18112](https://arxiv.org/abs/2511.18112)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18088": "|**2025-11-22**|**A Unified Multi-Dynamics Framework for Perception-Oriented Modeling in Tendon-Driven Continuum Robots**|Ibrahim Alsarraj et.al.|[2511.18088](https://arxiv.org/abs/2511.18088)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18085": "|**2025-11-22**|**Continually Evolving Skill Knowledge in Vision Language Action Model**|Yuxuan Wu et.al.|[2511.18085](https://arxiv.org/abs/2511.18085)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18005": "|**2025-11-22**|**RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World Generation at City-Scale**|Shengyuan Wang et.al.|[2511.18005](https://arxiv.org/abs/2511.18005)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17961": "|**2025-11-22**|**RoboArmGS: High-Quality Robotic Arm Splatting via B\u00e9zier Curve Refinement**|Hao Wang et.al.|[2511.17961](https://arxiv.org/abs/2511.17961)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17925": "|**2025-11-22**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Jeonghwan Kim et.al.|[2511.17925](https://arxiv.org/abs/2511.17925)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17915": "|**2025-11-22**|**DISPATCH -- Decentralized Informed Spatial Planning and Assignment of Tasks for Cooperative Heterogeneous Agents**|Yao Liu et.al.|[2511.17915](https://arxiv.org/abs/2511.17915)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17898": "|**2025-11-22**|**L1 Sample Flow for Efficient Visuomotor Learning**|Weixi Song et.al.|[2511.17898](https://arxiv.org/abs/2511.17898)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17889": "|**2025-11-22**|**MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots**|Ting Huang et.al.|[2511.17889](https://arxiv.org/abs/2511.17889)|**[link](https://huggingface.co/datasets/AIGeeksGroup/MobileVLA-CoT)**|\n", "2511.17869": "|**2025-11-22**|**The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems**|Subramanyam Sahoo et.al.|[2511.17869](https://arxiv.org/abs/2511.17869)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17855": "|**2025-11-22**|**QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents**|Jordan Abi Nader et.al.|[2511.17855](https://arxiv.org/abs/2511.17855)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.17824": "|**2025-11-21**|**QAL: A Loss for Recall Precision Balance in 3D Reconstruction**|Pranay Meshram et.al.|[2511.17824](https://arxiv.org/abs/2511.17824)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17798": "|**2025-11-21**|**SM2ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control**|Francesco D'Orazio et.al.|[2511.17798](https://arxiv.org/abs/2511.17798)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20644": "|**2025-11-25**|**Vision-Language Memory for Spatial Reasoning**|Zuntao Liu et.al.|[2511.20644](https://arxiv.org/abs/2511.20644)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Jiahui Zhang et.al.|[2511.20633](https://arxiv.org/abs/2511.20633)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20593": "|**2025-11-25**|**Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning**|Allen Emmanuel Binny et.al.|[2511.20593](https://arxiv.org/abs/2511.20593)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20570": "|**2025-11-25**|**Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics**|Tasha Kim et.al.|[2511.20570](https://arxiv.org/abs/2511.20570)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20496": "|**2025-11-25**|**Metric, inertially aligned monocular state estimation via kinetodynamic priors**|Jiaxin Liu et.al.|[2511.20496](https://arxiv.org/abs/2511.20496)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.20422": "|**2025-11-25**|**VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning**|Bo Pang et.al.|[2511.20422](https://arxiv.org/abs/2511.20422)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20394": "|**2025-11-25**|**Improved adaptive wind driven optimization algorithm for real-time path planning**|Shiqian Liu et.al.|[2511.20394](https://arxiv.org/abs/2511.20394)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20351": "|**2025-11-26**|**Thinking in 360\u00b0: Humanoid Visual Search in the Wild**|Heyang Yu et.al.|[2511.20351](https://arxiv.org/abs/2511.20351)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20299": "|**2025-11-25**|**How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks**|R\u00f3is\u00edn Keenan et.al.|[2511.20299](https://arxiv.org/abs/2511.20299)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20275": "|**2025-11-25**|**HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments**|Chenhui Dong et.al.|[2511.20275](https://arxiv.org/abs/2511.20275)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.20226": "|**2025-11-25**|**Toward generic control for soft robotic systems**|Yu Sun et.al.|[2511.20226](https://arxiv.org/abs/2511.20226)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20216": "|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Haebin Seong et.al.|[2511.20216](https://arxiv.org/abs/2511.20216)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20180": "|**2025-11-25**|**Hibikino-Musashi@Home 2025 Team Description Paper**|Ryohei Kobayashi et.al.|[2511.20180](https://arxiv.org/abs/2511.20180)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20018": "|**2025-11-25**|**Energy Costs and Neural Complexity Evolution in Changing Environments**|Sian Heesom-Green et.al.|[2511.20018](https://arxiv.org/abs/2511.20018)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19955": "|**2025-11-25**|**ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation**|Jinxuan Zhu et.al.|[2511.19955](https://arxiv.org/abs/2511.19955)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19932": "|**2025-11-25**|**Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine**|Lidi Zhang et.al.|[2511.19932](https://arxiv.org/abs/2511.19932)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19869": "|**2025-11-25**|**Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function**|Eito Sato et.al.|[2511.19869](https://arxiv.org/abs/2511.19869)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19865": "|**2025-11-25**|**Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G**|Mingkai Chen et.al.|[2511.19865](https://arxiv.org/abs/2511.19865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19861": "|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|GigaWorld Team et.al.|[2511.19861](https://arxiv.org/abs/2511.19861)|**[link](https://huggingface.co/models/open-gigaai/GigaWorld-0-Video-GR1-2b)**|\n", "2511.19859": "|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Xiangkai Ma et.al.|[2511.19859](https://arxiv.org/abs/2511.19859)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19836": "|**2025-11-25**|**4DWorldBench: A Comprehensive Evaluation Framework for 3D/4D World Generation Models**|Yiting Lu et.al.|[2511.19836](https://arxiv.org/abs/2511.19836)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.19768": "|**2025-11-24**|**Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering**|Noah Frahm et.al.|[2511.19768](https://arxiv.org/abs/2511.19768)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19647": "|**2025-11-24**|**Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation**|Jennifer Grannen et.al.|[2511.19647](https://arxiv.org/abs/2511.19647)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.19584": "|**2025-11-24**|**Learning Massively Multitask World Models for Continuous Control**|Nicklas Hansen et.al.|[2511.19584](https://arxiv.org/abs/2511.19584)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.19543": "|**2025-11-24**|**A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers**|Omar Faris et.al.|[2511.19543](https://arxiv.org/abs/2511.19543)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21690": "|**2025-11-26**|**TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos**|Seungjae Lee et.al.|[2511.21690](https://arxiv.org/abs/2511.21690)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan et.al.|[2511.21542](https://arxiv.org/abs/2511.21542)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21460": "|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Junjian Wang et.al.|[2511.21460](https://arxiv.org/abs/2511.21460)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.21312": "|**2025-11-26**|**Neural NMPC through Signed Distance Field Encoding for Collision Avoidance**|Martin Jacquet et.al.|[2511.21312](https://arxiv.org/abs/2511.21312)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21264": "|**2025-11-26**|**Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation**|Iryna Hurova et.al.|[2511.21264](https://arxiv.org/abs/2511.21264)|null|\n", "2511.21192": "|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu et.al.|[2511.21192](https://arxiv.org/abs/2511.21192)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.21169": "|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Kaiyan Xiao et.al.|[2511.21169](https://arxiv.org/abs/2511.21169)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.21161": "|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Xu Hu et.al.|[2511.21161](https://arxiv.org/abs/2511.21161)|**[link](https://github.com/hzxie/Awesome-3D-Scene-Generation)**|\n", "2511.21149": "|**2025-11-26**|**Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning**|Guoming Huang et.al.|[2511.21149](https://arxiv.org/abs/2511.21149)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Ziyi Chen et.al.|[2511.21135](https://arxiv.org/abs/2511.21135)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21083": "|**2025-11-26**|**Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry**|Feiyang Pan et.al.|[2511.21083](https://arxiv.org/abs/2511.21083)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.21053": "|**2025-11-26**|**AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios**|Chenglizhao Chen et.al.|[2511.21053](https://arxiv.org/abs/2511.21053)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21025": "|**2025-11-26**|**CaptionQA: Is Your Caption as Useful as the Image Itself?**|Shijia Yang et.al.|[2511.21025](https://arxiv.org/abs/2511.21025)|**[link](https://huggingface.co/datasets/Borise/CaptionQA)**|\n", "2511.21011": "|**2025-11-26**|**Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning**|Sid Bharthulwar et.al.|[2511.21011](https://arxiv.org/abs/2511.21011)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20937": "|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Qineng Wang et.al.|[2511.20937](https://arxiv.org/abs/2511.20937)|**[link](https://huggingface.co/datasets/MLL-Lab/ENACT)**|\n", "2511.20906": "|**2025-11-25**|**Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy**|Inkook Chun et.al.|[2511.20906](https://arxiv.org/abs/2511.20906)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2511.20887": "|**2025-11-25**|**ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation**|Rui Yan et.al.|[2511.20887](https://arxiv.org/abs/2511.20887)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20857": "|**2025-11-25**|**Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory**|Tianxin Wei et.al.|[2511.20857](https://arxiv.org/abs/2511.20857)|**[link](https://github.com/masamasa59/ai-agent-papers)**|\n", "2511.20853": "|**2025-11-25**|**MODEST: Multi-Optics Depth-of-Field Stereo Dataset**|Nisarg K. Trivedi et.al.|[2511.20853](https://arxiv.org/abs/2511.20853)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20848": "|**2025-11-25**|**NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities**|Tasha Kim et.al.|[2511.20848](https://arxiv.org/abs/2511.20848)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20811": "|**2025-11-25**|**Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning**|Aaron O. Feldman et.al.|[2511.20811](https://arxiv.org/abs/2511.20811)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20721": "|**2025-11-25**|**Foundry: Distilling 3D Foundation Models for the Edge**|Guillaume Letellier et.al.|[2511.20721](https://arxiv.org/abs/2511.20721)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20714": "|**2025-11-25**|**Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation**|Inferix Team et.al.|[2511.20714](https://arxiv.org/abs/2511.20714)|**[link](https://huggingface.co/datasets/heyuanyu/LV-Bench)**|\n", "2511.23407": "|**2025-11-28**|**From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products**|Jan Baumg\u00e4rtner et.al.|[2511.23407](https://arxiv.org/abs/2511.23407)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23300": "|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Yara Mahmoud et.al.|[2511.23300](https://arxiv.org/abs/2511.23300)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.23241": "|**2025-11-28**|**Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods**|Jose Moises Araya-Martinez et.al.|[2511.23241](https://arxiv.org/abs/2511.23241)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23215": "|**2025-11-28**|**Field-programmable dynamics in a soft magnetic actuator enabling true random number generation and reservoir computing**|Eduardo Sergio Oliveros-Mata et.al.|[2511.23215](https://arxiv.org/abs/2511.23215)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23186": "|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Runyu Jiao et.al.|[2511.23186](https://arxiv.org/abs/2511.23186)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23143": "|**2025-11-28**|**Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications**|Enrico Saccon et.al.|[2511.23143](https://arxiv.org/abs/2511.23143)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23055": "|**2025-11-28**|**MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents**|Ruoxuan Zhang et.al.|[2511.23055](https://arxiv.org/abs/2511.23055)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23034": "|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Zuolei Li et.al.|[2511.23034](https://arxiv.org/abs/2511.23034)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22963": "|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Zhirui Liu et.al.|[2511.22963](https://arxiv.org/abs/2511.22963)|null|\n", "2511.22950": "|**2025-11-28**|**RobotSeg: A Model and Dataset for Segmenting Robots in Image and Video**|Haiyang Mei et.al.|[2511.22950](https://arxiv.org/abs/2511.22950)|null|\n", "2511.22896": "|**2025-11-28**|**DM$^3$T: Harmonizing Modalities via Diffusion for Multi-Object Tracking**|Weiran Li et.al.|[2511.22896](https://arxiv.org/abs/2511.22896)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22845": "|**2025-11-28**|**Embodied Intelligent Wireless (EIW): Synesthesia of Machines Empowered Wireless Communications**|Xiang Cheng et.al.|[2511.22845](https://arxiv.org/abs/2511.22845)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22780": "|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Amir Rasouli et.al.|[2511.22780](https://arxiv.org/abs/2511.22780)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22777": "|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Sajjad Pakdamansavoji et.al.|[2511.22777](https://arxiv.org/abs/2511.22777)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22773": "|**2025-11-27**|**CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance**|Rui Heng Yang et.al.|[2511.22773](https://arxiv.org/abs/2511.22773)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22744": "|**2025-11-27**|**Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion**|R\u00e9my Rahem et.al.|[2511.22744](https://arxiv.org/abs/2511.22744)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22685": "|**2025-11-27**|**Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation**|Haoyi Wang et.al.|[2511.22685](https://arxiv.org/abs/2511.22685)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22555": "|**2025-11-27**|**Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention**|Yanbo Mao et.al.|[2511.22555](https://arxiv.org/abs/2511.22555)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22505": "|**2025-12-08**|**RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion**|Xiujian Liang et.al.|[2511.22505](https://arxiv.org/abs/2511.22505)|null|\n", "2511.22415": "|**2025-11-27**|**Exposing Vulnerabilities in RL: A Novel Stealthy Backdoor Attack through Reward Poisoning**|Bokang Zhang et.al.|[2511.22415](https://arxiv.org/abs/2511.22415)|null|\n", "2511.22388": "|**2025-11-27**|**Prudent Rationalizability and the Best Rationalization Principle**|Nicodemo De Vito et.al.|[2511.22388](https://arxiv.org/abs/2511.22388)|null|\n", "2511.22354": "|**2025-11-27**|**LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning**|Suraj Borate et.al.|[2511.22354](https://arxiv.org/abs/2511.22354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22338": "|**2025-11-27**|**Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning**|Denghan Xiong et.al.|[2511.22338](https://arxiv.org/abs/2511.22338)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22269": "|**2025-11-27**|**Investigating AI in Peer Support via Multi-Module System-Driven Embodied Conversational Agents**|Ruoyu Wen et.al.|[2511.22269](https://arxiv.org/abs/2511.22269)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22134": "|**2025-11-27**|**DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action**|Zhen Fang et.al.|[2511.22134](https://arxiv.org/abs/2511.22134)|null|\n", "2511.22098": "|**2025-11-27**|**WorldWander: Bridging Egocentric and Exocentric Worlds in Video Generation**|Quanjian Song et.al.|[2511.22098](https://arxiv.org/abs/2511.22098)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.22087": "|**2025-11-27**|**SoftNash: Entropy-Regularized Nash Games for Non-Fighting Virtual Fixtures**|Tai Inui et.al.|[2511.22087](https://arxiv.org/abs/2511.22087)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22025": "|**2025-11-27**|**Layover or Direct Flight: Rethinking Audio-Guided Image Segmentation**|Joel Alberto Santos et.al.|[2511.22025](https://arxiv.org/abs/2511.22025)|null|\n", "2511.21945": "|**2025-11-26**|**AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views**|Junwei Zhou et.al.|[2511.21945](https://arxiv.org/abs/2511.21945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21887": "|**2025-11-26**|**UniArt: Unified 3D Representation for Generating 3D Articulated Objects with Open-Set Articulation**|Bu Jin et.al.|[2511.21887](https://arxiv.org/abs/2511.21887)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02020": "|**2025-12-01**|**EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI**|Jianlei Chang et.al.|[2512.02020](https://arxiv.org/abs/2512.02020)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01996": "|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Younggyo Seo et.al.|[2512.01996](https://arxiv.org/abs/2512.01996)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2512.01924": "|**2025-12-01**|**Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model**|Kentaro Fujii et.al.|[2512.01924](https://arxiv.org/abs/2512.01924)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01908": "|**2025-12-01**|**SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception**|Gurmeher Khurana et.al.|[2512.01908](https://arxiv.org/abs/2512.01908)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01850": "|**2025-12-01**|**Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching**|Yue Pan et.al.|[2512.01850](https://arxiv.org/abs/2512.01850)|null|\n", "2512.01809": "|**2025-12-01**|**Much Ado About Noising: Dispelling the Myths of Generative Robotic Control**|Chaoyi Pan et.al.|[2512.01809](https://arxiv.org/abs/2512.01809)|null|\n", "2512.01801": "|**2025-12-02**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yunfei Li et.al.|[2512.01801](https://arxiv.org/abs/2512.01801)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2512.01773": "|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Chenghao Gu et.al.|[2512.01773](https://arxiv.org/abs/2512.01773)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01754": "|**2025-12-01**|**How to Capture Human Preference: Commissioning of a Robotic Use-Case via Preferential Bayesian Optimisation**|Sander De Witte et.al.|[2512.01754](https://arxiv.org/abs/2512.01754)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01715": "|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Wanpeng Zhang et.al.|[2512.01715](https://arxiv.org/abs/2512.01715)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01598": "|**2025-12-01**|**A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics**|Marek Vagas et.al.|[2512.01598](https://arxiv.org/abs/2512.01598)|null|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Fei Liu et.al.|[2512.01550](https://arxiv.org/abs/2512.01550)|null|\n", "2512.01446": "|**2025-12-01**|**$\\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering**|Jiayi Li et.al.|[2512.01446](https://arxiv.org/abs/2512.01446)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01383": "|**2025-12-01**|**PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**|Yunze Liu et.al.|[2512.01383](https://arxiv.org/abs/2512.01383)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01358": "|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Junsung Park et.al.|[2512.01358](https://arxiv.org/abs/2512.01358)|null|\n", "2512.01336": "|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Diyuan Shi et.al.|[2512.01336](https://arxiv.org/abs/2512.01336)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2512.01280": "|**2025-12-01**|**Visibility-aware Cooperative Aerial Tracking with Decentralized LiDAR-based Swarms**|Longji Yin et.al.|[2512.01280](https://arxiv.org/abs/2512.01280)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01204": "|**2025-12-01**|**TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image**|Ziqian Wang et.al.|[2512.01204](https://arxiv.org/abs/2512.01204)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01188": "|**2025-12-01**|**Real-World Reinforcement Learning of Active Perception Behaviors**|Edward S. Hu et.al.|[2512.01188](https://arxiv.org/abs/2512.01188)|null|\n", "2512.01106": "|**2025-11-30**|**Tactile Robotics: Past and Future**|Nathan F. Lepora et.al.|[2512.01106](https://arxiv.org/abs/2512.01106)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01078": "|**2025-11-30**|**SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds**|Jiawei Ren et.al.|[2512.01078](https://arxiv.org/abs/2512.01078)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.01061": "|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Haoru Xue et.al.|[2512.01061](https://arxiv.org/abs/2512.01061)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2512.01052": "|**2025-11-30**|**Autonomous Grasping On Quadruped Robot With Task Level Interaction**|Muhtadin et.al.|[2512.01052](https://arxiv.org/abs/2512.01052)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|Jiaming Tang et.al.|[2512.01031](https://arxiv.org/abs/2512.01031)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Yi-Lin Wei et.al.|[2512.01022](https://arxiv.org/abs/2512.01022)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01010": "|**2025-11-30**|**Chain of Unit-Physics: A Primitive-Centric Approach to Scientific Code Synthesis**|Vansh Sharma et.al.|[2512.01010](https://arxiv.org/abs/2512.01010)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.00975": "|**2025-12-08**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Haotian Liang et.al.|[2512.00975](https://arxiv.org/abs/2512.00975)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00971": "|**2025-11-30**|**H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**|Yunfeng Lin et.al.|[2512.00971](https://arxiv.org/abs/2512.00971)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2512.00960": "|**2025-11-30**|**Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction**|Boran Wen et.al.|[2512.00960](https://arxiv.org/abs/2512.00960)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00907": "|**2025-11-30**|**Magnetic Tactile-Driven Soft Actuator for Intelligent Grasping and Firmness Evaluation**|Chengjin Du et.al.|[2512.00907](https://arxiv.org/abs/2512.00907)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00797": "|**2025-11-30**|**Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration**|Nan Sun et.al.|[2512.00797](https://arxiv.org/abs/2512.00797)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang et.al.|[2512.00783](https://arxiv.org/abs/2512.00783)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00775": "|**2025-11-30**|**SAGAS: Semantic-Aware Graph-Assisted Stitching for Offline Temporal Logic Planning**|Ruijia Liu et.al.|[2512.00775](https://arxiv.org/abs/2512.00775)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00727": "|**2025-11-30**|**MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion**|Sizhe Wei et.al.|[2512.00727](https://arxiv.org/abs/2512.00727)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.00592": "|**2025-11-29**|**HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks**|Mihir Chauhan et.al.|[2512.00592](https://arxiv.org/abs/2512.00592)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.00532": "|**2025-11-29**|**Image Generation as a Visual Planner for Robotic Manipulation**|Ye Pang et.al.|[2512.00532](https://arxiv.org/abs/2512.00532)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00453": "|**2025-11-29**|**Sample-Efficient Expert Query Control in Active Imitation Learning via Conformal Prediction**|Arad Firouzkouhi et.al.|[2512.00453](https://arxiv.org/abs/2512.00453)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00427": "|**2025-11-29**|**Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control**|Mengting Yu et.al.|[2512.00427](https://arxiv.org/abs/2512.00427)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00355": "|**2025-11-29**|**SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction**|Junqiao Fan et.al.|[2512.00355](https://arxiv.org/abs/2512.00355)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00324": "|**2025-11-29**|**MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation**|Jinda Du et.al.|[2512.00324](https://arxiv.org/abs/2512.00324)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00300": "|**2025-11-29**|**TGSFormer: Scalable Temporal Gaussian Splatting for Embodied Semantic Scene Completion**|Rui Qian et.al.|[2512.00300](https://arxiv.org/abs/2512.00300)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2512.00262": "|**2025-11-29**|**\"Why the face?\": Exploring Robot Error Detection Using Instrumented Bystander Reactions**|Maria Teresa Parreira et.al.|[2512.00262](https://arxiv.org/abs/2512.00262)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03044": "|**2025-12-02**|**Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling**|Yueru Jia et.al.|[2512.03044](https://arxiv.org/abs/2512.03044)|null|\n", "2512.03000": "|**2025-12-03**|**DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling**|Kairun Wen et.al.|[2512.03000](https://arxiv.org/abs/2512.03000)|**[link](https://huggingface.co/datasets/kairunwen/DynamicVerse)**|\n", "2512.02851": "|**2025-12-03**|**SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots**|Iana Zhura et.al.|[2512.02851](https://arxiv.org/abs/2512.02851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02810": "|**2025-12-02**|**Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms**|Shyam prasad reddy Kaitha et.al.|[2512.02810](https://arxiv.org/abs/2512.02810)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02787": "|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng et.al.|[2512.02787](https://arxiv.org/abs/2512.02787)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang et.al.|[2512.02729](https://arxiv.org/abs/2512.02729)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02609": "|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Shengkai Wu et.al.|[2512.02609](https://arxiv.org/abs/2512.02609)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2512.02569": "|**2025-12-02**|**Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models**|Yuchong Zhang et.al.|[2512.02569](https://arxiv.org/abs/2512.02569)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02549": "|**2025-12-02**|**Robotic capabilities framework: A boundary object and intermediate-level knowledge artifact for co-designing robotic processes**|Alessandro Ianniello et.al.|[2512.02549](https://arxiv.org/abs/2512.02549)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02543": "|**2025-12-02**|**In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs**|Vishnu Sarukkai et.al.|[2512.02543](https://arxiv.org/abs/2512.02543)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02458": "|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Zhongyi Cai et.al.|[2512.02458](https://arxiv.org/abs/2512.02458)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02389": "|**2025-12-02**|**Synthetic Error Injection Fails to Elicit Self-Correction In Language Models**|David X. Wu et.al.|[2512.02389](https://arxiv.org/abs/2512.02389)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02329": "|**2025-12-02**|**Towards autonomous normative multi-agent systems for Human-AI software engineering teams**|Hoa Khanh Dam et.al.|[2512.02329](https://arxiv.org/abs/2512.02329)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.04069": "|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Siyi Chen et.al.|[2512.04069](https://arxiv.org/abs/2512.04069)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2512.03991": "|**2025-12-03**|**When to Say \"Hi\" - Learn to Open a Conversation with an in-the-wild Dataset**|Michael Schiffmann et.al.|[2512.03991](https://arxiv.org/abs/2512.03991)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03958": "|**2025-12-03**|**MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation**|Xiaobei Zhao et.al.|[2512.03958](https://arxiv.org/abs/2512.03958)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03945": "|**2025-12-03**|**Classification of User Satisfaction in HRI with Social Signals in the Wild**|Michael Schiffmann et.al.|[2512.03945](https://arxiv.org/abs/2512.03945)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.03911": "|**2025-12-03**|**Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware**|Kenneth Stewart et.al.|[2512.03911](https://arxiv.org/abs/2512.03911)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03871": "|**2025-12-03**|**Adaptive Parameter Control Using AAN for Lower Limb Rehabilitation Exoskeletons**|Zheng Sun et.al.|[2512.03871](https://arxiv.org/abs/2512.03871)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03851": "|**2025-12-03**|**Comparison of neural network training strategies for the simulation of dynamical systems**|Paul Strasser et.al.|[2512.03851](https://arxiv.org/abs/2512.03851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03828": "|**2025-12-03**|**IM HERE: Interaction Model for Human Effort Based Robot Engagement**|Dominykas Strazdas et.al.|[2512.03828](https://arxiv.org/abs/2512.03828)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03743": "|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Kehlani Fay et.al.|[2512.03743](https://arxiv.org/abs/2512.03743)|**[link](https://github.com/Yuxing-Wang-THU/SurveyBrainBody)**|\n", "2512.03736": "|**2025-12-03**|**Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control**|Kenneth Stewart et.al.|[2512.03736](https://arxiv.org/abs/2512.03736)|null|\n", "2512.03729": "|**2025-12-03**|**Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing**|Samantha Chapin et.al.|[2512.03729](https://arxiv.org/abs/2512.03729)|null|\n", "2512.03707": "|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Sundas Rafat Mulkana et.al.|[2512.03707](https://arxiv.org/abs/2512.03707)|null|\n", "2512.03687": "|**2025-12-03**|**Active Visual Perception: Opportunities and Challenges**|Yian Li et.al.|[2512.03687](https://arxiv.org/abs/2512.03687)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03666": "|**2025-12-03**|**ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos**|Qi'ao Xu et.al.|[2512.03666](https://arxiv.org/abs/2512.03666)|null|\n", "2512.03538": "|**2025-12-03**|**AdaPower: Specializing World Foundation Models for Predictive Manipulation**|Yuhang Huang et.al.|[2512.03538](https://arxiv.org/abs/2512.03538)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.03444": "|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Davood Soleymanzadeh et.al.|[2512.03444](https://arxiv.org/abs/2512.03444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03438": "|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Reuben Tan et.al.|[2512.03438](https://arxiv.org/abs/2512.03438)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03429": "|**2025-12-03**|**World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations**|Raul Steinmetz et.al.|[2512.03429](https://arxiv.org/abs/2512.03429)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03256": "|**2025-12-02**|**KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems**|Albert H. Li et.al.|[2512.03256](https://arxiv.org/abs/2512.03256)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03210": "|**2025-12-02**|**Flux4D: Flow-based Unsupervised 4D Reconstruction**|Jingkang Wang et.al.|[2512.03210](https://arxiv.org/abs/2512.03210)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2512.03204": "|**2025-12-02**|**Scaling Internal-State Policy-Gradient Methods for POMDPs**|Douglas Aberdeen et.al.|[2512.03204](https://arxiv.org/abs/2512.03204)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03194": "|**2025-12-02**|**GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding**|Johannes Gaber et.al.|[2512.03194](https://arxiv.org/abs/2512.03194)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.03166": "|**2025-12-02**|**Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments**|Aya Taourirte et.al.|[2512.03166](https://arxiv.org/abs/2512.03166)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu et.al.|[2512.05107](https://arxiv.org/abs/2512.05107)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05094": "|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|James Ni et.al.|[2512.05094](https://arxiv.org/abs/2512.05094)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2512.05079": "|**2025-12-04**|**Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints**|Minghan Zhu et.al.|[2512.05079](https://arxiv.org/abs/2512.05079)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Yicheng Liu et.al.|[2512.04952](https://arxiv.org/abs/2512.04952)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04884": "|**2025-12-04**|**Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation**|Tim Engelbracht et.al.|[2512.04884](https://arxiv.org/abs/2512.04884)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04813": "|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Huanqian Wang et.al.|[2512.04813](https://arxiv.org/abs/2512.04813)|**[link](https://huggingface.co/datasets/BAAI/MOVE)**|\n", "2512.04797": "|**2025-12-04**|**SIMA 2: A Generalist Embodied Agent for Virtual Worlds**|SIMA team et.al.|[2512.04797](https://arxiv.org/abs/2512.04797)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.04770": "|**2025-12-04**|**Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges**|Yuxing Wang et.al.|[2512.04770](https://arxiv.org/abs/2512.04770)|**[link](https://github.com/Yuxing-Wang-THU/SurveyBrainBody)**|\n", "2512.04731": "|**2025-12-04**|**Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting**|Jian Tang et.al.|[2512.04731](https://arxiv.org/abs/2512.04731)|null|\n", "2512.04716": "|**2025-12-04**|**Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics**|Haodong Feng et.al.|[2512.04716](https://arxiv.org/abs/2512.04716)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang et.al.|[2512.04686](https://arxiv.org/abs/2512.04686)|**[link](https://huggingface.co/models/WangYipu2002/CroPond-3B)**|\n", "2512.04597": "|**2025-12-04**|**When Robots Should Say \"I Don't Know\": Benchmarking Abstention in Embodied Question Answering**|Tao Wu et.al.|[2512.04597](https://arxiv.org/abs/2512.04597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04579": "|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Hannes Homburger et.al.|[2512.04579](https://arxiv.org/abs/2512.04579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang et.al.|[2512.04537](https://arxiv.org/abs/2512.04537)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04535": "|**2025-12-05**|**GTM: Simulating the World of Tools for AI Agents**|Zhenzhen Ren et.al.|[2512.04535](https://arxiv.org/abs/2512.04535)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04528": "|**2025-12-04**|**Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification**|Chentao Shen et.al.|[2512.04528](https://arxiv.org/abs/2512.04528)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04513": "|**2025-12-04**|**BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models**|Yu-Wei Zhan et.al.|[2512.04513](https://arxiv.org/abs/2512.04513)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.04463": "|**2025-12-04**|**MARL Warehouse Robots**|Price Allman et.al.|[2512.04463](https://arxiv.org/abs/2512.04463)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04453": "|**2025-12-04**|**Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration**|Debasmita Ghose et.al.|[2512.04453](https://arxiv.org/abs/2512.04453)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04451": "|**2025-12-04**|**StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios**|Yifei Wang et.al.|[2512.04451](https://arxiv.org/abs/2512.04451)|null|\n", "2512.04399": "|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Haoqi Han et.al.|[2512.04399](https://arxiv.org/abs/2512.04399)|null|\n", "2512.04308": "|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Lei Zhang et.al.|[2512.04308](https://arxiv.org/abs/2512.04308)|null|\n", "2512.04231": "|**2025-12-03**|**CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding**|Zhou Chen et.al.|[2512.04231](https://arxiv.org/abs/2512.04231)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05927": "|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Zhiting Mei et.al.|[2512.05927](https://arxiv.org/abs/2512.05927)|null|\n", "2512.05808": "|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Sushmita Bhattacharya et.al.|[2512.05808](https://arxiv.org/abs/2512.05808)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05803": "|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Blanca Inigo et.al.|[2512.05803](https://arxiv.org/abs/2512.05803)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05783": "|**2025-12-05**|**Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth**|Maryam Yousefi et.al.|[2512.05783](https://arxiv.org/abs/2512.05783)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05693": "|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Zhiying Du et.al.|[2512.05693](https://arxiv.org/abs/2512.05693)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05579": "|**2025-12-05**|**A Comprehensive Framework for Automated Quality Control in the Automotive Industry**|Panagiota Moraiti et.al.|[2512.05579](https://arxiv.org/abs/2512.05579)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05578": "|**2025-12-05**|**A Hyperspectral Imaging Guided Robotic Grasping System**|Zheng Sun et.al.|[2512.05578](https://arxiv.org/abs/2512.05578)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05447": "|**2025-12-05**|**Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning**|Pengcheng Dai et.al.|[2512.05447](https://arxiv.org/abs/2512.05447)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05389": "|**2025-12-05**|**CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement**|Yuxuan Chen et.al.|[2512.05389](https://arxiv.org/abs/2512.05389)|null|\n", "2512.05270": "|**2025-12-04**|**XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots**|Tianyi Wang et.al.|[2512.05270](https://arxiv.org/abs/2512.05270)|null|\n", "2512.05267": "|**2025-12-04**|**Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective**|Osvaldo Simeone et.al.|[2512.05267](https://arxiv.org/abs/2512.05267)|null|\n", "2512.05259": "|**2025-12-04**|**Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization**|Georgios Chatzichristodoulou et.al.|[2512.05259](https://arxiv.org/abs/2512.05259)|null|\n", "2512.05240": "|**2025-12-04**|**IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction**|Dmitrii Torbunov et.al.|[2512.05240](https://arxiv.org/abs/2512.05240)|null|\n", "2512.05230": "|**2025-12-04**|**Invariance Co-training for Robot Visual Generalization**|Jonathan Yang et.al.|[2512.05230](https://arxiv.org/abs/2512.05230)|null|\n", "2512.07599": "|**2025-12-08**|**Online Segment Any 3D Thing as Instance Tracking**|Hanshi Wang et.al.|[2512.07599](https://arxiv.org/abs/2512.07599)|**[link](https://github.com/Mondrian-He/awesome-nips-2025-artist)**|\n", "2512.07582": "|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Guangyan Chen et.al.|[2512.07582](https://arxiv.org/abs/2512.07582)|null|\n", "2512.07266": "|**2025-12-08**|**SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks**|Florian Tretter et.al.|[2512.07266](https://arxiv.org/abs/2512.07266)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.07177": "|**2025-12-08**|**Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction**|Fanjun Bu et.al.|[2512.07177](https://arxiv.org/abs/2512.07177)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.07041": "|**2025-12-07**|**CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation**|Hiroki Sawada et.al.|[2512.07041](https://arxiv.org/abs/2512.07041)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Yichao Shen et.al.|[2512.06963](https://arxiv.org/abs/2512.06963)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2512.06558": "|**2025-12-06**|**Embodied Referring Expression Comprehension in Human-Robot Interaction**|Md Mofijul Islam et.al.|[2512.06558](https://arxiv.org/abs/2512.06558)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.06017": "|**2025-12-03**|**Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models**|Laurence Liang et.al.|[2512.06017](https://arxiv.org/abs/2512.06017)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.06013": "|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Wenhao Li et.al.|[2512.06013](https://arxiv.org/abs/2512.06013)|null|\n", "2512.06002": "|**2025-12-02**|**POrTAL: Plan-Orchestrated Tree Assembly for Lookahead**|Evan Conway et.al.|[2512.06002](https://arxiv.org/abs/2512.06002)|null|\n"}, "Robotic Manipulation": {"2508.15669": "|**2025-08-21**|**Exploiting Policy Idling for Dexterous Manipulation**|Annie S. Chen et.al.|[2508.15669](https://arxiv.org/abs/2508.15669)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15633": "|**2025-08-21**|**GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)**|Wei Herng Choong et.al.|[2508.15633](https://arxiv.org/abs/2508.15633)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15432": "|**2025-08-21**|**GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO**|Bidyapati Pradhan et.al.|[2508.15432](https://arxiv.org/abs/2508.15432)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15327": "|**2025-08-21**|**Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning**|Xiancheng Gao et.al.|[2508.15327](https://arxiv.org/abs/2508.15327)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15274": "|**2025-08-21**|**TComQA: Extracting Temporal Commonsense from Text**|Lekshmi R Nair et.al.|[2508.15274](https://arxiv.org/abs/2508.15274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15157": "|**2025-08-21**|**Big-Stop Semantics: A Simple Way to Get the Benefits of Small-Step Semantics in a Big-Step Judgment**|David M Kahn et.al.|[2508.15157](https://arxiv.org/abs/2508.15157)|**[link](https://github.com/jaalonso/Lecturas_GLC)**|\n", "2508.15013": "|**2025-08-20**|**Goals and the Structure of Experience**|Nadav Amir et.al.|[2508.15013](https://arxiv.org/abs/2508.15013)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15002": "|**2025-08-20**|**GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping**|Ren\u00e9 Zurbr\u00fcgg et.al.|[2508.15002](https://arxiv.org/abs/2508.15002)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14994": "|**2025-08-20**|**A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot**|Murilo Vinicius da Silva et.al.|[2508.14994](https://arxiv.org/abs/2508.14994)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14704": "|**2025-08-20**|**MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers**|Ziyang Luo et.al.|[2508.14704](https://arxiv.org/abs/2508.14704)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2508.13998": "|**2025-08-19**|**Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation**|Yifu Yuan et.al.|[2508.13998](https://arxiv.org/abs/2508.13998)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.13877": "|**2025-08-19**|**Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer**|Rathnam Vidushika Rasanji et.al.|[2508.13877](https://arxiv.org/abs/2508.13877)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.13154": "|**2025-08-18**|**4DNeX: Feed-Forward 4D Generative Modeling Made Easy**|Zhaoxi Chen et.al.|[2508.13154](https://arxiv.org/abs/2508.13154)|**[link](https://huggingface.co/datasets/3DTopia/4DNeX-10M)**|\n", "2508.13104": "|**2025-08-18**|**Precise Action-to-Video Generation Through Visual Action Prompts**|Yuang Wang et.al.|[2508.13104](https://arxiv.org/abs/2508.13104)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2508.13103": "|**2025-08-18**|**Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy**|Tianyi Zhang et.al.|[2508.13103](https://arxiv.org/abs/2508.13103)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.13073": "|**2025-09-04**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Rui Shao et.al.|[2508.13073](https://arxiv.org/abs/2508.13073)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2508.13009": "|**2025-08-18**|**Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model**|Xianglong He et.al.|[2508.13009](https://arxiv.org/abs/2508.13009)|**[link](https://huggingface.co/spaces/jbilcke-hf/NON_WORKING_matrix_game_2)**|\n", "2508.12620": "|**2025-08-18**|**Strengthening Programming Comprehension in Large Language Models through Code Generation**|Xiaoning Ren et.al.|[2508.12620](https://arxiv.org/abs/2508.12620)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12554": "|**2025-08-18**|**PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions**|Hamza El-Kebir et.al.|[2508.12554](https://arxiv.org/abs/2508.12554)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12439": "|**2025-08-17**|**Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation**|Sunyu Wang et.al.|[2508.12439](https://arxiv.org/abs/2508.12439)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12349": "|**2025-08-17**|**EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos**|Junyi Ma et.al.|[2508.12349](https://arxiv.org/abs/2508.12349)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12274": "|**2025-08-17**|**Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments**|Jian Zhao et.al.|[2508.12274](https://arxiv.org/abs/2508.12274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12160": "|**2025-08-16**|**Conditional mutual information: A generalization of causal inference in quantum systems**|Anupam Ghosh et.al.|[2508.12160](https://arxiv.org/abs/2508.12160)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12087": "|**2025-08-16**|**MAPF-World: Action World Model for Multi-Agent Path Finding**|Zhanjiang Yang et.al.|[2508.12087](https://arxiv.org/abs/2508.12087)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12071": "|**2025-08-16**|**OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments**|Amy Phung et.al.|[2508.12071](https://arxiv.org/abs/2508.12071)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12038": "|**2025-08-16**|**Fully Spiking Actor-Critic Neural Network for Robotic Manipulation**|Liwen Zhang et.al.|[2508.12038](https://arxiv.org/abs/2508.12038)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11898": "|**2025-08-16**|**OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation**|Jilei Mao et.al.|[2508.11898](https://arxiv.org/abs/2508.11898)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11836": "|**2025-08-15**|**Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video**|Dave Goel et.al.|[2508.11836](https://arxiv.org/abs/2508.11836)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2508.11620": "|**2025-08-15**|**Grab-n-Go: On-the-Go Microgesture Recognition with Objects in Hand**|Chi-Jung Lee et.al.|[2508.11620](https://arxiv.org/abs/2508.11620)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11588": "|**2025-08-15**|**Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation**|Benjamin Walt et.al.|[2508.11588](https://arxiv.org/abs/2508.11588)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11428": "|**2025-08-15**|**ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving**|Jingyu Li et.al.|[2508.11428](https://arxiv.org/abs/2508.11428)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.11204": "|**2025-08-15**|**Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation**|Hongbin Lin et.al.|[2508.11204](https://arxiv.org/abs/2508.11204)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11200": "|**2025-08-15**|**Visuomotor Grasping with World Models for Surgical Robots**|Hongbin Lin et.al.|[2508.11200](https://arxiv.org/abs/2508.11200)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.11143": "|**2025-08-15**|**Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward**|Jiarui Yang et.al.|[2508.11143](https://arxiv.org/abs/2508.11143)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11117": "|**2025-08-14**|**Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective**|Xuning Yang et.al.|[2508.11117](https://arxiv.org/abs/2508.11117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11002": "|**2025-08-20**|**3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation**|Nikolaos Gkanatsios et.al.|[2508.11002](https://arxiv.org/abs/2508.11002)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.10770": "|**2025-08-14**|**From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models**|Tiancheng Han et.al.|[2508.10770](https://arxiv.org/abs/2508.10770)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.10489": "|**2025-08-14**|**Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures**|Jonas Ulmen et.al.|[2508.10489](https://arxiv.org/abs/2508.10489)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.10399": "|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.10378": "|**2025-08-14**|**A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons**|Yu Chen et.al.|[2508.10378](https://arxiv.org/abs/2508.10378)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09976": "|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Marion Lepert et.al.|[2508.09976](https://arxiv.org/abs/2508.09976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09855": "|**2025-08-13**|**Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes**|Yuekun Wu et.al.|[2508.09855](https://arxiv.org/abs/2508.09855)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2508.09822": "|**2025-08-25**|**Physical Autoregressive Model for Robotic Manipulation without Action Pretraining**|Zijian Song et.al.|[2508.09822](https://arxiv.org/abs/2508.09822)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2508.09820": "|**2025-08-13**|**Provable In-Context Vector Arithmetic via Retrieving Task Concepts**|Dake Bu et.al.|[2508.09820](https://arxiv.org/abs/2508.09820)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09700": "|**2025-08-13**|**Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions**|Mahdi Hejrati et.al.|[2508.09700](https://arxiv.org/abs/2508.09700)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09561": "|**2025-08-13**|**Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges**|Changyuan Zhao et.al.|[2508.09561](https://arxiv.org/abs/2508.09561)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.09558": "|**2025-08-13**|**CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail**|Jiahui Zuo et.al.|[2508.09558](https://arxiv.org/abs/2508.09558)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09502": "|**2025-08-13**|**Reactive Model Predictive Contouring Control for Robot Manipulators**|Junheon Yoon et.al.|[2508.09502](https://arxiv.org/abs/2508.09502)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09448": "|**2025-08-13**|**The watery atmosphere of HD~209458~b revealed by joint $K$- and $L$-band high-resolution spectroscopy**|Luke Finnerty et.al.|[2508.09448](https://arxiv.org/abs/2508.09448)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09346": "|**2025-08-12**|**How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy**|Zhenjiang Mao et.al.|[2508.09346](https://arxiv.org/abs/2508.09346)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.16512": "|**2025-08-22**|**Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation**|Chun-Peng Chang et.al.|[2508.16512](https://arxiv.org/abs/2508.16512)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.15990": "|**2025-08-21**|**GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System**|Hung-Jui Huang et.al.|[2508.15990](https://arxiv.org/abs/2508.15990)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2508.15972": "|**2025-08-21**|**UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation**|Zhaodong Jiang et.al.|[2508.15972](https://arxiv.org/abs/2508.15972)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2508.15949": "|**2025-08-21**|**An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem**|Bruna C. B. Charytitsch et.al.|[2508.15949](https://arxiv.org/abs/2508.15949)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15874": "|**2025-08-21**|**Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning**|Yijun Liu et.al.|[2508.15874](https://arxiv.org/abs/2508.15874)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.15859": "|**2025-08-20**|**Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language**|Tadahiro Taniguchi et.al.|[2508.15859](https://arxiv.org/abs/2508.15859)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18269": "|**2025-08-26**|**FlowVLA: Thinking in Motion with a Visual Chain of Thought**|Zhide Zhong et.al.|[2508.18269](https://arxiv.org/abs/2508.18269)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.17986": "|**2025-08-25**|**No Need to Look! Locating and Grasping Objects by a Robot Arm Covered with Sensitive Skin**|Karel Bartunek et.al.|[2508.17986](https://arxiv.org/abs/2508.17986)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17643": "|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Krishna Vinod et.al.|[2508.17643](https://arxiv.org/abs/2508.17643)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17600": "|**2025-08-25**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Guanxing Lu et.al.|[2508.17600](https://arxiv.org/abs/2508.17600)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.17588": "|**2025-08-25**|**HERO: Hierarchical Extrapolation and Refresh for Efficient World Models**|Quanjian Song et.al.|[2508.17588](https://arxiv.org/abs/2508.17588)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.17482": "|**2025-08-24**|**Variational Shape Inference for Grasp Diffusion on SE(3)**|S. Talha Bukhari et.al.|[2508.17482](https://arxiv.org/abs/2508.17482)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17466": "|**2025-08-24**|**Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation**|Dilermando Almeida et.al.|[2508.17466](https://arxiv.org/abs/2508.17466)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17449": "|**2025-08-24**|**Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges**|Zezeng Li et.al.|[2508.17449](https://arxiv.org/abs/2508.17449)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17298": "|**2025-08-27**|**Explain Before You Answer: A Survey on Compositional Visual Reasoning**|Fucai Ke et.al.|[2508.17298](https://arxiv.org/abs/2508.17298)|**[link](https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling)**|\n", "2508.17260": "|**2025-08-24**|**OVITA: Open-Vocabulary Interpretable Trajectory Adaptations**|Anurag Maurya et.al.|[2508.17260](https://arxiv.org/abs/2508.17260)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17102": "|**2025-08-23**|**GRASP: Geospatial pixel Reasoning viA Structured Policy learning**|Chengjie Jiang et.al.|[2508.17102](https://arxiv.org/abs/2508.17102)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.16876": "|**2025-08-26**|**Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling**|Yue Zhao et.al.|[2508.16876](https://arxiv.org/abs/2508.16876)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.16749": "|**2025-08-22**|**A Dataset and Benchmark for Robotic Cloth Unfolding Grasp Selection: The ICRA 2024 Cloth Competition**|Victor-Louis De Gusseme et.al.|[2508.16749](https://arxiv.org/abs/2508.16749)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17437": "|**2025-08-26**|**Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels**|Long Le et.al.|[2508.17437](https://arxiv.org/abs/2508.17437)|**[link](https://huggingface.co/datasets/vlongle/pixie)**|\n", "2508.19236": "|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Hao Shi et.al.|[2508.19236](https://arxiv.org/abs/2508.19236)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2508.19191": "|**2025-08-27**|**AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot**|Yue Wang et.al.|[2508.19191](https://arxiv.org/abs/2508.19191)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18898": "|**2025-08-26**|**Interpretable Decision-Making for End-to-End Autonomous Driving**|Mona Mirzaie et.al.|[2508.18898](https://arxiv.org/abs/2508.18898)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18820": "|**2025-08-26**|**AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy**|Christian Henkel et.al.|[2508.18820](https://arxiv.org/abs/2508.18820)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18802": "|**2025-08-26**|**HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation**|Li Sun et.al.|[2508.18802](https://arxiv.org/abs/2508.18802)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18627": "|**2025-08-26**|**Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning**|Ziyuan Jiao et.al.|[2508.18627](https://arxiv.org/abs/2508.18627)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18507": "|**2025-08-25**|**Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies**|Dillon Z. Chen et.al.|[2508.18507](https://arxiv.org/abs/2508.18507)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18443": "|**2025-08-25**|**PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing**|Ruohan Zhang et.al.|[2508.18443](https://arxiv.org/abs/2508.18443)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2508.18399": "|**2025-08-25**|**Maintenance automation: methods for robotics manipulation planning and execution**|Christian Friedrich et.al.|[2508.18399](https://arxiv.org/abs/2508.18399)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20085": "|**2025-08-31**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Zhecheng Yuan et.al.|[2508.20085](https://arxiv.org/abs/2508.20085)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2508.19958": "|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Yiguo Fan et.al.|[2508.19958](https://arxiv.org/abs/2508.19958)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.19852": "|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Binjie Zhang et.al.|[2508.19852](https://arxiv.org/abs/2508.19852)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2508.19851": "|**2025-08-27**|**Tracking World States with Language Models: State-Based Evaluation Using Chess**|Romain Harang et.al.|[2508.19851](https://arxiv.org/abs/2508.19851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19790": "|**2025-08-27**|**APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors**|Liding Zhang et.al.|[2508.19790](https://arxiv.org/abs/2508.19790)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19608": "|**2025-08-27**|**Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning**|Dongjae Lee et.al.|[2508.19608](https://arxiv.org/abs/2508.19608)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19607": "|**2025-08-27**|**Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks**|Amin Berjaoui Tahmaz et.al.|[2508.19607](https://arxiv.org/abs/2508.19607)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2508.19391": "|**2025-08-26**|**LaVA-Man: Learning Visual Action Representations for Robot Manipulation**|Chaoran Zhu et.al.|[2508.19391](https://arxiv.org/abs/2508.19391)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19367": "|**2025-08-26**|**Inference of Human-derived Specifications of Object Placement via Demonstration**|Alex Cuellar et.al.|[2508.19367](https://arxiv.org/abs/2508.19367)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19320": "|**2025-08-28**|**MIDAS: Multimodal Interactive Digital-humAn Synthesis via Real-time Autoregressive Video Generation**|Ming Chen et.al.|[2508.19320](https://arxiv.org/abs/2508.19320)|**[link](https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey)**|\n", "2508.20982": "|**2025-08-29**|**UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception**|Junhao Gong et.al.|[2508.20982](https://arxiv.org/abs/2508.20982)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2508.20959": "|**2025-08-28**|**Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing**|Curtis C. Johnson et.al.|[2508.20959](https://arxiv.org/abs/2508.20959)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20884": "|**2025-08-28**|**Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning**|Liding Zhang et.al.|[2508.20884](https://arxiv.org/abs/2508.20884)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20840": "|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qiao Sun et.al.|[2508.20840](https://arxiv.org/abs/2508.20840)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.20547": "|**2025-08-30**|**SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes**|Yunpeng Mei et.al.|[2508.20547](https://arxiv.org/abs/2508.20547)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2508.20294": "|**2025-08-27**|**Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization**|Frank R\u00f6der et.al.|[2508.20294](https://arxiv.org/abs/2508.20294)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.21677": "|**2025-08-29**|**Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators**|Bernhard Wullt et.al.|[2508.21677](https://arxiv.org/abs/2508.21677)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21549": "|**2025-08-29**|**Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler**|Liding Zhang et.al.|[2508.21549](https://arxiv.org/abs/2508.21549)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21378": "|**2025-08-29**|**RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation**|Chenduo Ying et.al.|[2508.21378](https://arxiv.org/abs/2508.21378)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21321": "|**2025-08-29**|**Project-Based Learning in Introductory Quantum Computing Courses: A Case Study on Quantum Algorithms for Medical Imaging**|Nischal Binod Gautam et.al.|[2508.21321](https://arxiv.org/abs/2508.21321)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21272": "|**2025-08-29**|**Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609**|Jaehong Oh et.al.|[2508.21272](https://arxiv.org/abs/2508.21272)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03479": "|**2025-09-03**|**Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games**|Haonan Wang et.al.|[2509.03479](https://arxiv.org/abs/2509.03479)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03345": "|**2025-09-03**|**Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning**|Yunxin Sun et.al.|[2509.03345](https://arxiv.org/abs/2509.03345)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.03342": "|**2025-09-03**|**Quantifying many-body contributions to depletion forces**|Gabriel P\u00e9rez-Angel et.al.|[2509.03342](https://arxiv.org/abs/2509.03342)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03119": "|**2025-09-07**|**Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built from a Five Bar Linkage**|Yash Vyas et.al.|[2509.03119](https://arxiv.org/abs/2509.03119)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03114": "|**2025-09-03**|**Towards Realistic Hand-Object Interaction with Gravity-Field Based Diffusion Bridge**|Miao Xu et.al.|[2509.03114](https://arxiv.org/abs/2509.03114)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02876": "|**2025-09-02**|**Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model**|Hongrui Yu et.al.|[2509.02876](https://arxiv.org/abs/2509.02876)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02807": "|**2025-09-02**|**PixFoundation 2.0: Do Video Multi-Modal LLMs Use Motion in Visual Grounding?**|Mennatullah Siam et.al.|[2509.02807](https://arxiv.org/abs/2509.02807)|**[link](https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation)**|\n", "2509.02722": "|**2025-09-06**|**Planning with Reasoning using Vision Language World Model**|Delong Chen et.al.|[2509.02722](https://arxiv.org/abs/2509.02722)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.02530": "|**2025-09-02**|**Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots**|Minghuan Liu et.al.|[2509.02530](https://arxiv.org/abs/2509.02530)|**[link](https://huggingface.co/models/depth-anything/camera-depth-model-d405)**|\n", "2509.02437": "|**2025-09-02**|**U-ARM : Ultra low-cost general teleoperation interface for robot manipulation**|Yanwen Zou et.al.|[2509.02437](https://arxiv.org/abs/2509.02437)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.02655": "|**2025-09-02**|**BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format**|Roland Pihlakas et.al.|[2509.02655](https://arxiv.org/abs/2509.02655)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.02055": "|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Yang Zhang et.al.|[2509.02055](https://arxiv.org/abs/2509.02055)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.01996": "|**2025-09-02**|**MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation**|Chi Sun et.al.|[2509.01996](https://arxiv.org/abs/2509.01996)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01819": "|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Ge Yan et.al.|[2509.01819](https://arxiv.org/abs/2509.01819)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.01793": "|**2025-09-01**|**Toward a Unified Benchmark and Taxonomy of Stochastic Environments**|Aryan Amit Barsainyan et.al.|[2509.01793](https://arxiv.org/abs/2509.01793)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01236": "|**2025-09-01**|**Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors**|Hao Yang et.al.|[2509.01236](https://arxiv.org/abs/2509.01236)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01113": "|**2025-09-01**|**A novel parameter estimation method for pneumatic soft hand control applying logarithmic decrement for pseudo rigid body modeling**|Haiyun Zhang et.al.|[2509.01113](https://arxiv.org/abs/2509.01113)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01044": "|**2025-09-01**|**A Reactive Grasping Framework for Multi-DoF Grippers via Task Space Velocity Fields and Joint Space QP**|Yonghyeon Lee et.al.|[2509.01044](https://arxiv.org/abs/2509.01044)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00836": "|**2025-08-31**|**One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields**|Yulin Li et.al.|[2509.00836](https://arxiv.org/abs/2509.00836)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00828": "|**2025-09-06**|**An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator**|Takumu Okazaki et.al.|[2509.00828](https://arxiv.org/abs/2509.00828)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.00823": "|**2025-09-06**|**Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gr\u00f6bner Systems**|Takumu Okazaki et.al.|[2509.00823](https://arxiv.org/abs/2509.00823)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00559": "|**2025-08-30**|**Social World Models**|Xuhui Zhou et.al.|[2509.00559](https://arxiv.org/abs/2509.00559)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.00499": "|**2025-08-30**|**NeuralSVCD for Efficient Swept Volume Collision Detection**|Dongwon Son et.al.|[2509.00499](https://arxiv.org/abs/2509.00499)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00361": "|**2025-08-30**|**Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation**|Chuye Zhang et.al.|[2509.00361](https://arxiv.org/abs/2509.00361)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00339": "|**2025-08-30**|**Autonomous Aggregate Sorting in Construction and Mining via Computer Vision-Aided Robotic Arm Systems**|Md. Taherul Islam Shawon et.al.|[2509.00339](https://arxiv.org/abs/2509.00339)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00210": "|**2025-08-29**|**Beyond Pixels: Introducing Geometric-Semantic World Priors for Video-based Embodied Models via Spatio-temporal Alignment**|Jinzhou Tang et.al.|[2509.00210](https://arxiv.org/abs/2509.00210)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00074": "|**2025-08-26**|**Language and Experience: A Computational Model of Social Learning in Complex Tasks**|C\u00e9dric Colas et.al.|[2509.00074](https://arxiv.org/abs/2509.00074)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04400": "|**2025-09-04**|**On $\u03c4$ Spin Use with KKMCee**|J. M. John et.al.|[2509.04400](https://arxiv.org/abs/2509.04400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04324": "|**2025-09-04**|**OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection**|Chen Hu et.al.|[2509.04324](https://arxiv.org/abs/2509.04324)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04266": "|**2025-09-04**|**Foundations of photonic quantum computation**|Martin Bombardelli et.al.|[2509.04266](https://arxiv.org/abs/2509.04266)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04063": "|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Hongyin Zhang et.al.|[2509.04063](https://arxiv.org/abs/2509.04063)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.04018": "|**2025-09-04**|**FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction**|Yifan Yang et.al.|[2509.04018](https://arxiv.org/abs/2509.04018)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.03956": "|**2025-09-04**|**World Model Implanting for Test-time Adaptation of Embodied Agents**|Minjong Yoo et.al.|[2509.03956](https://arxiv.org/abs/2509.03956)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.03893": "|**2025-09-04**|**Weakly-Supervised Learning of Dense Functional Correspondences**|Stefan Stojanov et.al.|[2509.03893](https://arxiv.org/abs/2509.03893)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03889": "|**2025-09-04**|**Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance**|Neha Sunil et.al.|[2509.03889](https://arxiv.org/abs/2509.03889)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2509.03887": "|**2025-09-04**|**OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction**|Bu Jin et.al.|[2509.03887](https://arxiv.org/abs/2509.03887)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.03867": "|**2025-09-10**|**Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth**|Yang Wang et.al.|[2509.03867](https://arxiv.org/abs/2509.03867)|**[link](https://huggingface.co/datasets/extraordinarylab/drivel-hub)**|\n", "2509.03859": "|**2025-09-08**|**Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator**|Haichao Zhang et.al.|[2509.03859](https://arxiv.org/abs/2509.03859)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03771": "|**2025-09-03**|**Learning an Adversarial World Model for Automated Curriculum Generation in MARL**|Brennen Hill et.al.|[2509.03771](https://arxiv.org/abs/2509.03771)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.03638": "|**2025-09-03**|**Cooperative Grasping for Collective Object Transport in Constrained Environments**|David Alvear et.al.|[2509.03638](https://arxiv.org/abs/2509.03638)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03636": "|**2025-09-03**|**CausalARC: Abstract Reasoning with Causal World Models**|Jacqueline Maasch et.al.|[2509.03636](https://arxiv.org/abs/2509.03636)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.05263": "|**2025-09-08**|**LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation**|Yinglin Duan et.al.|[2509.05263](https://arxiv.org/abs/2509.05263)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.04810": "|**2025-09-05**|**Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation**|Yogev Cohen et.al.|[2509.04810](https://arxiv.org/abs/2509.04810)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04731": "|**2025-09-05**|**Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning**|Brennen Hill et.al.|[2509.04731](https://arxiv.org/abs/2509.04731)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.04676": "|**2025-09-04**|**An Approach to Grounding AI Model Evaluations in Human-derived Criteria**|Sasha Mitts et.al.|[2509.04676](https://arxiv.org/abs/2509.04676)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04658": "|**2025-09-04**|**Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision**|Manish Kansana et.al.|[2509.04658](https://arxiv.org/abs/2509.04658)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04645": "|**2025-09-04**|**Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement**|Kallol Saha et.al.|[2509.04645](https://arxiv.org/abs/2509.04645)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04600": "|**2025-09-04**|**WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human**|Qijun Ying et.al.|[2509.04600](https://arxiv.org/abs/2509.04600)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.04599": "|**2025-09-04**|**Exploring the variational method for thermodynamic models**|Oliwier Urba\u0144ski et.al.|[2509.04599](https://arxiv.org/abs/2509.04599)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04535": "|**2025-09-04**|**In-Context Policy Adaptation via Cross-Domain Skill Diffusion**|Minjong Yoo et.al.|[2509.04535](https://arxiv.org/abs/2509.04535)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.06953": "|**2025-09-08**|**Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments**|Jiahui Yang et.al.|[2509.06953](https://arxiv.org/abs/2509.06953)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06932": "|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Yuqing Wen et.al.|[2509.06932](https://arxiv.org/abs/2509.06932)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.06705": "|**2025-09-08**|**Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention**|Mohamed Zayaan S et.al.|[2509.06705](https://arxiv.org/abs/2509.06705)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06579": "|**2025-09-08**|**CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis**|Xin Kong et.al.|[2509.06579](https://arxiv.org/abs/2509.06579)|**[link](https://github.com/ChaoyueSong/Awesome-Auto-Regressive-in-GenerativeAI)**|\n", "2509.06233": "|**2025-09-07**|**O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation**|Tongxuan Tian et.al.|[2509.06233](https://arxiv.org/abs/2509.06233)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06201": "|**2025-09-07**|**Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control**|Jun Yamada et.al.|[2509.06201](https://arxiv.org/abs/2509.06201)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06191": "|**2025-09-07**|**Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)**|Yifei Ren et.al.|[2509.06191](https://arxiv.org/abs/2509.06191)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06048": "|**2025-09-07**|**Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness**|Yi Dong et.al.|[2509.06048](https://arxiv.org/abs/2509.06048)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06025": "|**2025-09-07**|**Unified Interaction Foundational Model (UIFM) for Predicting Complex User and System Behavior**|Vignesh Ethiraj et.al.|[2509.06025](https://arxiv.org/abs/2509.06025)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.05735": "|**2025-09-06**|**Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies**|Jiaqi Chen et.al.|[2509.05735](https://arxiv.org/abs/2509.05735)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.05547": "|**2025-09-06**|**TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs**|Ziling Chen et.al.|[2509.05547](https://arxiv.org/abs/2509.05547)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07978": "|**2025-09-09**|**One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation**|Zheng Geng et.al.|[2509.07978](https://arxiv.org/abs/2509.07978)|**[link](https://github.com/GZWSAMA/OnePoseviaGen)**|\n", "2509.07962": "|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Zongzheng Zhang et.al.|[2509.07962](https://arxiv.org/abs/2509.07962)|**[link](https://github.com/ZZongzheng0918/TA-VLA)**|\n", "2509.07957": "|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Shunlei Li et.al.|[2509.07957](https://arxiv.org/abs/2509.07957)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.07945": "|**2025-09-09**|**One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning**|Yuan Pu et.al.|[2509.07945](https://arxiv.org/abs/2509.07945)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.07916": "|**2025-09-09**|**Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability**|Jianshu Zhou et.al.|[2509.07916](https://arxiv.org/abs/2509.07916)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07496": "|**2025-09-09**|**Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction**|Ayano Miyamichi et.al.|[2509.07496](https://arxiv.org/abs/2509.07496)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07216": "|**2025-09-08**|**Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators**|Hassen Nigatu et.al.|[2509.07216](https://arxiv.org/abs/2509.07216)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07201": "|**2025-09-08**|**Design of Input-Output Observers for a Population of Systems with Bounded Frequency-Domain Variation using $DK$-iteration**|Timothy Everett Adams et.al.|[2509.07201](https://arxiv.org/abs/2509.07201)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07162": "|**2025-09-08**|**First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping**|Martin Matak et.al.|[2509.07162](https://arxiv.org/abs/2509.07162)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08775": "|**2025-09-11**|**Joint Model-based Model-free Diffusion for Planning with Constraints**|Wonsuhk Jung et.al.|[2509.08775](https://arxiv.org/abs/2509.08775)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08404": "|**2025-09-10**|**HyperMOOC: Augmenting MOOC Videos with Concept-based Embedded Visualizations**|Li Ye et.al.|[2509.08404](https://arxiv.org/abs/2509.08404)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08354": "|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Ce Guo et.al.|[2509.08354](https://arxiv.org/abs/2509.08354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08270": "|**2025-09-10**|**Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models**|Pranav Pawar et.al.|[2509.08270](https://arxiv.org/abs/2509.08270)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08218": "|**2025-09-10**|**PolicyStory: Leveraging Large Language Models to Generate Comprehensible Summaries of Policy-News in India**|Aatif Nisar Dar et.al.|[2509.08218](https://arxiv.org/abs/2509.08218)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08126": "|**2025-09-09**|**Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning**|Houjian Yu et.al.|[2509.08126](https://arxiv.org/abs/2509.08126)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07996": "|**2025-09-11**|**3D and 4D World Modeling: A Survey**|Lingdong Kong et.al.|[2509.07996](https://arxiv.org/abs/2509.07996)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.09674": "|**2025-09-11**|**SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning**|Haozhan Li et.al.|[2509.09674](https://arxiv.org/abs/2509.09674)|**[link](https://github.com/PRIME-RL/SimpleVLA-RL)**|\n", "2509.09671": "|**2025-09-11**|**Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration**|Sirui Xu et.al.|[2509.09671](https://arxiv.org/abs/2509.09671)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09546": "|**2025-09-11**|**A Neuromorphic Incipient Slip Detection System using Papillae Morphology**|Yanhui Lu et.al.|[2509.09546](https://arxiv.org/abs/2509.09546)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09093": "|**2025-09-12**|**Kinetostatics and Particle-Swarm Optimization of Vehicle-Mounted Underactuated Metamorphic Loading Manipulators**|Nan Mao et.al.|[2509.09093](https://arxiv.org/abs/2509.09093)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10416": "|**2025-09-12**|**TASC: Task-Aware Shared Control for Teleoperated Manipulation**|Ze Fu et.al.|[2509.10416](https://arxiv.org/abs/2509.10416)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09769": "|**2025-09-11**|**MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos**|Rutav Shah et.al.|[2509.09769](https://arxiv.org/abs/2509.09769)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09737": "|**2025-09-10**|**World Modeling with Probabilistic Structure Integration**|Klemen Kotar et.al.|[2509.09737](https://arxiv.org/abs/2509.09737)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.12201": "|**2025-09-15**|**OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling**|Yang Zhou et.al.|[2509.12201](https://arxiv.org/abs/2509.12201)|**[link](https://huggingface.co/datasets/InternRobotics/OmniWorld)**|\n", "2509.12158": "|**2025-09-20**|**Pun Unintended: LLMs and the Illusion of Humor Understanding**|Alessandro Zangari et.al.|[2509.12158](https://arxiv.org/abs/2509.12158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12008": "|**2025-09-15**|**Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees**|Yuqing Song et.al.|[2509.12008](https://arxiv.org/abs/2509.12008)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11959": "|**2025-09-15**|**Learning to Generate 4D LiDAR Sequences**|Ao Liang et.al.|[2509.11959](https://arxiv.org/abs/2509.11959)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11943": "|**2025-09-15**|**Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics**|Antonin Sulc et.al.|[2509.11943](https://arxiv.org/abs/2509.11943)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.11865": "|**2025-09-15**|**Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer**|Travis Davies et.al.|[2509.11865](https://arxiv.org/abs/2509.11865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11621": "|**2025-09-15**|**Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios**|Xiangtong Yao et.al.|[2509.11621](https://arxiv.org/abs/2509.11621)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11617": "|**2025-09-15**|**AssemMate: Graph-Based LLM for Robotic Assembly Assistance**|Qi Zheng et.al.|[2509.11617](https://arxiv.org/abs/2509.11617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11594": "|**2025-09-16**|**GBPP: Grasp-Aware Base Placement Prediction for Robots via Two-Stage Learning**|Jizhuo Chen et.al.|[2509.11594](https://arxiv.org/abs/2509.11594)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11417": "|**2025-09-17**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Shresth Grover et.al.|[2509.11417](https://arxiv.org/abs/2509.11417)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.11364": "|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Sheng Liu et.al.|[2509.11364](https://arxiv.org/abs/2509.11364)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11225": "|**2025-09-14**|**MEMBOT: Memory-Based Robot in Intermittent POMDP**|Youzhi Liang et.al.|[2509.11225](https://arxiv.org/abs/2509.11225)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11185": "|**2025-09-14**|**SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators**|Kai Chen et.al.|[2509.11185](https://arxiv.org/abs/2509.11185)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11125": "|**2025-09-14**|**ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations**|Zheng Li et.al.|[2509.11125](https://arxiv.org/abs/2509.11125)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10952": "|**2025-09-13**|**ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation**|Yangcen Liu et.al.|[2509.10952](https://arxiv.org/abs/2509.10952)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10929": "|**2025-09-13**|**Clarifying Model Transparency: Interpretability versus Explainability in Deep Learning with MNIST and IMDB Examples**|Mitali Raj et.al.|[2509.10929](https://arxiv.org/abs/2509.10929)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10875": "|**2025-09-13**|**Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?**|Jesse Gardner et.al.|[2509.10875](https://arxiv.org/abs/2509.10875)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.13126": "|**2025-09-16**|**Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation**|Miquel Oller et.al.|[2509.13126](https://arxiv.org/abs/2509.13126)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13095": "|**2025-09-16**|**Empowering Multi-Robot Cooperation via Sequential World Models**|Zijie Zhao et.al.|[2509.13095](https://arxiv.org/abs/2509.13095)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.13077": "|**2025-09-16**|**A Design Co-Pilot for Task-Tailored Manipulators**|Jonathan K\u00fclz et.al.|[2509.13077](https://arxiv.org/abs/2509.13077)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13074": "|**2025-09-16**|**Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five**|Simon Fritsch et.al.|[2509.13074](https://arxiv.org/abs/2509.13074)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12969": "|**2025-09-16**|**Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators**|Jae-Hyun Lee et.al.|[2509.12969](https://arxiv.org/abs/2509.12969)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12739": "|**2025-09-16**|**Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors**|Trung Kien La et.al.|[2509.12739](https://arxiv.org/abs/2509.12739)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12674": "|**2025-09-16**|**Safety filtering of robotic manipulation under environment uncertainty: a computational approach**|Anna Johansson et.al.|[2509.12674](https://arxiv.org/abs/2509.12674)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12437": "|**2025-09-15**|**Enhancing Physical Consistency in Lightweight World Models**|Dingrui Wang et.al.|[2509.12437](https://arxiv.org/abs/2509.12437)|**[link](https://huggingface.co/models/TUM/PIWM_ckpt)**|\n", "2509.12387": "|**2025-09-15**|**Causal-Symbolic Meta-Learning (CSML): Inducing Causal World Models for Few-Shot Generalization**|Mohamed Zayaan S et.al.|[2509.12387](https://arxiv.org/abs/2509.12387)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12379": "|**2025-09-17**|**Geometric Red-Teaming for Robotic Manipulation**|Divyam Goel et.al.|[2509.12379](https://arxiv.org/abs/2509.12379)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.14143": "|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Zijian An et.al.|[2509.14143](https://arxiv.org/abs/2509.14143)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Ran Yang et.al.|[2509.14138](https://arxiv.org/abs/2509.14138)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.13905": "|**2025-09-17**|**Do Large Language Models Understand Word Senses?**|Domenico Meconi et.al.|[2509.13905](https://arxiv.org/abs/2509.13905)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13903": "|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Artem Lykov et.al.|[2509.13903](https://arxiv.org/abs/2509.13903)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.13815": "|**2025-09-17**|**Soft Regrasping Tool Inspired by Jamming Gripper**|Takuya Kiyokawa et.al.|[2509.13815](https://arxiv.org/abs/2509.13815)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13802": "|**2025-09-17**|**Shell-Type Soft Jig for Holding Objects during Disassembly**|Takuya Kiyokawa et.al.|[2509.13802](https://arxiv.org/abs/2509.13802)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13774": "|**2025-09-17**|**Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach**|Piaopiao Jin et.al.|[2509.13774](https://arxiv.org/abs/2509.13774)|**[link](https://github.com/philfung/awesome-reliable-robotics)**|\n", "2509.13731": "|**2025-09-17**|**Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings**|Jeongwoo Park et.al.|[2509.13731](https://arxiv.org/abs/2509.13731)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2509.13692": "|**2025-09-17**|**HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion**|Yadan Zeng et.al.|[2509.13692](https://arxiv.org/abs/2509.13692)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13572": "|**2025-09-16**|**Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference**|Ozan Karaali et.al.|[2509.13572](https://arxiv.org/abs/2509.13572)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13534": "|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Chunxin Zheng et.al.|[2509.13534](https://arxiv.org/abs/2509.13534)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.13389": "|**2025-09-16**|**From Next Token Prediction to (STRIPS) World Models -- Preliminary Results**|Carlos N\u00fa\u00f1ez-Molina et.al.|[2509.13389](https://arxiv.org/abs/2509.13389)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13384": "|**2025-09-16**|**A tree-based Polynomial Chaos expansion for surrogate modeling and sensitivity analysis of complex numerical models**|Faten Ben Said et.al.|[2509.13384](https://arxiv.org/abs/2509.13384)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14178": "|**2025-09-16**|**\\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video**|Kai Ye et.al.|[2509.14178](https://arxiv.org/abs/2509.14178)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13349": "|**2025-09-13**|**Label-Efficient Grasp Joint Prediction with Point-JEPA**|Jed Guzelkabaagac et.al.|[2509.13349](https://arxiv.org/abs/2509.13349)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13341": "|**2025-09-11**|**Imagined Autocurricula**|Ahmet H. G\u00fczel et.al.|[2509.13341](https://arxiv.org/abs/2509.13341)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15212": "|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Yuming Jiang et.al.|[2509.15212](https://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|\n", "2509.15071": "|**2025-09-18**|**A Nonlinear Scaling-based Design of Control Lyapunov-barrier Function for Relative Degree 2 Case and its Application to Safe Feedback Linearization**|Haechan Pyon et.al.|[2509.15071](https://arxiv.org/abs/2509.15071)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14758": "|**2025-09-18**|**Designing Latent Safety Filters using Pre-Trained Vision Models**|Ihab Tabbara et.al.|[2509.14758](https://arxiv.org/abs/2509.14758)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16122": "|**2025-09-19**|**Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors**|Carter Sifferman et.al.|[2509.16122](https://arxiv.org/abs/2509.16122)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16072": "|**2025-09-22**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Clemence Grislain et.al.|[2509.16072](https://arxiv.org/abs/2509.16072)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15915": "|**2025-09-19**|**Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds**|Remo Sasso et.al.|[2509.15915](https://arxiv.org/abs/2509.15915)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15880": "|**2025-09-19**|**Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder**|An Dinh Vuong et.al.|[2509.15880](https://arxiv.org/abs/2509.15880)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15876": "|**2025-09-19**|**High-Bandwidth Tactile-Reactive Control for Grasp Adjustment**|Yonghyeon Lee et.al.|[2509.15876](https://arxiv.org/abs/2509.15876)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15778": "|**2025-09-19**|**All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control**|Mohammad Bahari et.al.|[2509.15778](https://arxiv.org/abs/2509.15778)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15733": "|**2025-09-19**|**GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation**|Quanhao Qian et.al.|[2509.15733](https://arxiv.org/abs/2509.15733)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15717": "|**2025-09-19**|**Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference**|Haoran Ding et.al.|[2509.15717](https://arxiv.org/abs/2509.15717)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15536": "|**2025-09-19**|**SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models**|Sen Wang et.al.|[2509.15536](https://arxiv.org/abs/2509.15536)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15479": "|**2025-09-18**|**OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data**|Bj\u00f6rn M\u00f6ller et.al.|[2509.15479](https://arxiv.org/abs/2509.15479)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18084": "|**2025-09-24**|**ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces**|Jiawen Tian et.al.|[2509.18084](https://arxiv.org/abs/2509.18084)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.18043": "|**2025-09-22**|**Prepare Before You Act: Learning From Humans to Rearrange Initial States**|Yinlong Dai et.al.|[2509.18043](https://arxiv.org/abs/2509.18043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17812": "|**2025-09-23**|**Tac2Motion: Contact-Aware Reinforcement Learning with Tactile Feedback for Robotic Hand Manipulation**|Yitaek Kim et.al.|[2509.17812](https://arxiv.org/abs/2509.17812)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17808": "|**2025-09-22**|**Remote Sensing-Oriented World Model**|Yuxi Lu et.al.|[2509.17808](https://arxiv.org/abs/2509.17808)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.17788": "|**2025-09-22**|**One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts**|Xingyu Fan et.al.|[2509.17788](https://arxiv.org/abs/2509.17788)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17783": "|**2025-09-23**|**RoboSeek: You Need to Interact with Your Objects**|Yibo Peng et.al.|[2509.17783](https://arxiv.org/abs/2509.17783)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17759": "|**2025-09-22**|**MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies**|Chengbo Yuan et.al.|[2509.17759](https://arxiv.org/abs/2509.17759)|**[link](https://huggingface.co/datasets/michaelyuanqwq/motiontrans)**|\n", "2509.17684": "|**2025-09-22**|**DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning**|ThankGod Egbe et.al.|[2509.17684](https://arxiv.org/abs/2509.17684)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17666": "|**2025-09-22**|**Robust and Resilient Soft Robotic Object Insertion with Compliance-Enabled Contact Formation and Failure Recovery**|Mimo Shirasaka et.al.|[2509.17666](https://arxiv.org/abs/2509.17666)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17389": "|**2025-09-22**|**3D Printable Soft Liquid Metal Sensors for Delicate Manipulation Tasks**|Lois Liow et.al.|[2509.17389](https://arxiv.org/abs/2509.17389)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17381": "|**2025-09-22**|**Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators**|Yongliang Wang et.al.|[2509.17381](https://arxiv.org/abs/2509.17381)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2509.17125": "|**2025-09-21**|**Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation**|Liang Heng et.al.|[2509.17125](https://arxiv.org/abs/2509.17125)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17057": "|**2025-09-21**|**RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments**|Masaki Murooka et.al.|[2509.17057](https://arxiv.org/abs/2509.17057)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17010": "|**2025-09-21**|**Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems**|Rajpal Singh et.al.|[2509.17010](https://arxiv.org/abs/2509.17010)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16871": "|**2025-09-21**|**HOGraspFlow: Exploring Vision-based Generative Grasp Synthesis with Hand-Object Priors and Taxonomy Awareness**|Yitian Shi et.al.|[2509.16871](https://arxiv.org/abs/2509.16871)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16645": "|**2025-09-20**|**ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents**|Yichen Wang et.al.|[2509.16645](https://arxiv.org/abs/2509.16645)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.16615": "|**2025-09-20**|**LLM-Guided Task- and Affordance-Level Exploration in Reinforcement Learning**|Jelle Luijkx et.al.|[2509.16615](https://arxiv.org/abs/2509.16615)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16550": "|**2025-09-20**|**TranTac: Leveraging Transient Tactile Signals for Contact-Rich Robotic Manipulation**|Yinghao Wu et.al.|[2509.16550](https://arxiv.org/abs/2509.16550)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16532": "|**2025-09-20**|**No Need for Real 3D: Fusing 2D Vision with Pseudo 3D Representations for Robotic Manipulation Learning**|Run Yu et.al.|[2509.16532](https://arxiv.org/abs/2509.16532)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16434": "|**2025-09-19**|**End-to-end RL Improves Dexterous Grasping Policies**|Ritvik Singh et.al.|[2509.16434](https://arxiv.org/abs/2509.16434)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16353": "|**2025-09-19**|**Tactile-Based Human Intent Recognition for Robot Assistive Navigation**|Shaoting Peng et.al.|[2509.16353](https://arxiv.org/abs/2509.16353)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16338": "|**2025-09-19**|**Polarized Signatures of Variable Worlds: Modeling Heterogeneous Habitable Earth- and Early Mars-like (Exo)planets**|Kenneth E. Goodis Gordon et.al.|[2509.16338](https://arxiv.org/abs/2509.16338)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19292": "|**2025-09-23**|**SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration**|Yang Jin et.al.|[2509.19292](https://arxiv.org/abs/2509.19292)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19261": "|**2025-09-23**|**Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces**|Kuanqi Cai et.al.|[2509.19261](https://arxiv.org/abs/2509.19261)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19142": "|**2025-09-23**|**BiGraspFormer: End-to-End Bimanual Grasp Transformer**|Kangmin Kim et.al.|[2509.19142](https://arxiv.org/abs/2509.19142)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19117": "|**2025-09-23**|**LLM-based Vulnerability Discovery through the Lens of Code Metrics**|Felix Weissberg et.al.|[2509.19117](https://arxiv.org/abs/2509.19117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19102": "|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Hongli Xu et.al.|[2509.19102](https://arxiv.org/abs/2509.19102)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19080": "|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Zhennan Jiang et.al.|[2509.19080](https://arxiv.org/abs/2509.19080)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.19041": "|**2025-09-23**|**Position: Human-Robot Interaction in Embodied Intelligence Demands a Shift From Static Privacy Controls to Dynamic Learning**|Shuning Zhang et.al.|[2509.19041](https://arxiv.org/abs/2509.19041)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Hanqing Liu et.al.|[2509.18953](https://arxiv.org/abs/2509.18953)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.18830": "|**2025-09-23**|**DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation**|Suzannah Wistreich et.al.|[2509.18830](https://arxiv.org/abs/2509.18830)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2509.18757": "|**2025-09-23**|**MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning**|Omar Rayyan et.al.|[2509.18757](https://arxiv.org/abs/2509.18757)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18676": "|**2025-09-23**|**3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space**|Sangjun Noh et.al.|[2509.18676](https://arxiv.org/abs/2509.18676)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.18644": "|**2025-09-24**|**Do You Need Proprioceptive States in Visuomotor Policies?**|Juntu Zhao et.al.|[2509.18644](https://arxiv.org/abs/2509.18644)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.18631": "|**2025-09-24**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Shuo Cheng et.al.|[2509.18631](https://arxiv.org/abs/2509.18631)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang et.al.|[2509.18610](https://arxiv.org/abs/2509.18610)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18597": "|**2025-09-25**|**Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills**|Yuan Meng et.al.|[2509.18597](https://arxiv.org/abs/2509.18597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18581": "|**2025-09-23**|**A scaling law for large-deformation contact in soft materials**|Tong Mu et.al.|[2509.18581](https://arxiv.org/abs/2509.18581)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18463": "|**2025-09-22**|**Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task**|Jannick van Buuren et.al.|[2509.18463](https://arxiv.org/abs/2509.18463)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18455": "|**2025-09-22**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Yunshuang Li et.al.|[2509.18455](https://arxiv.org/abs/2509.18455)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat et.al.|[2509.18428](https://arxiv.org/abs/2509.18428)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.18282": "|**2025-09-22**|**PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies**|Jesse Zhang et.al.|[2509.18282](https://arxiv.org/abs/2509.18282)|**[link](https://huggingface.co/models/jesbu1/act-bridge-v2)**|\n", "2509.17393": "|**2025-09-23**|**Program Synthesis via Test-Time Transduction**|Kang-il Lee et.al.|[2509.17393](https://arxiv.org/abs/2509.17393)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20297": "|**2025-09-26**|**mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies**|Remo Steiner et.al.|[2509.20297](https://arxiv.org/abs/2509.20297)|**[link](https://huggingface.co/models/nvidia/PhysicalAI-Robotics-mindmap-Checkpoints)**|\n", "2509.20021": "|**2025-09-24**|**Embodied AI: From LLMs to World Models**|Tongtong Feng et.al.|[2509.20021](https://arxiv.org/abs/2509.20021)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.19958": "|**2025-09-24**|**Generalist Robot Manipulation beyond Action Labeled Data**|Alexander Spiridonov et.al.|[2509.19958](https://arxiv.org/abs/2509.19958)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.19892": "|**2025-09-24**|**D3Grasp: Diverse and Deformable Dexterous Grasping for General Objects**|Keyu Wang et.al.|[2509.19892](https://arxiv.org/abs/2509.19892)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19853": "|**2025-09-24**|**SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process**|BinXu Wu et.al.|[2509.19853](https://arxiv.org/abs/2509.19853)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19732": "|**2025-09-24**|**Simultaneous estimation of contact position and tool shape with high-dimensional parameters using force measurements and particle filtering**|Kyo Kutsuzawa et.al.|[2509.19732](https://arxiv.org/abs/2509.19732)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19712": "|**2025-09-24**|**TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies**|Liquan Wang et.al.|[2509.19712](https://arxiv.org/abs/2509.19712)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19626": "|**2025-09-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Ryan Punamiya et.al.|[2509.19626](https://arxiv.org/abs/2509.19626)|**[link](https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence)**|\n", "2509.19555": "|**2025-09-23**|**AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space**|Sankalp Agrawal et.al.|[2509.19555](https://arxiv.org/abs/2509.19555)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19538": "|**2025-09-23**|**DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions**|Zongyue Li et.al.|[2509.19538](https://arxiv.org/abs/2509.19538)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.19524": "|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Ramy ElMallah et.al.|[2509.19524](https://arxiv.org/abs/2509.19524)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21281": "|**2025-09-25**|**Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds**|Luis Augenstein et.al.|[2509.21281](https://arxiv.org/abs/2509.21281)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21145": "|**2025-09-25**|**DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps**|Md Faizal Karim et.al.|[2509.21145](https://arxiv.org/abs/2509.21145)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21027": "|**2025-09-25**|**KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models**|Sibo Li et.al.|[2509.21027](https://arxiv.org/abs/2509.21027)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.21006": "|**2025-09-25**|**AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation**|Konstantin Gubernatorov et.al.|[2509.21006](https://arxiv.org/abs/2509.21006)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20998": "|**2025-09-25**|**CORE: Full-Path Evaluation of LLM Agents Beyond Final State**|Panagiotis Michelakis et.al.|[2509.20998](https://arxiv.org/abs/2509.20998)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20841": "|**2025-09-25**|**ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation**|Dekun Lu et.al.|[2509.20841](https://arxiv.org/abs/2509.20841)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20703": "|**2025-09-25**|**Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations**|Xiaoxiang Dong et.al.|[2509.20703](https://arxiv.org/abs/2509.20703)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.20656": "|**2025-09-25**|**EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation**|Junzhe Wang et.al.|[2509.20656](https://arxiv.org/abs/2509.20656)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20646": "|**2025-09-25**|**Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation**|Sun Zhaole et.al.|[2509.20646](https://arxiv.org/abs/2509.20646)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20623": "|**2025-09-24**|**Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation**|Satyajeet Das et.al.|[2509.20623](https://arxiv.org/abs/2509.20623)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|Hanna Yurchyk et.al.|[2509.20579](https://arxiv.org/abs/2509.20579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20550": "|**2025-09-24**|**GraspFactory: A Large Object-Centric Grasping Dataset**|Srinidhi Kalgundi Srinivas et.al.|[2509.20550](https://arxiv.org/abs/2509.20550)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20510": "|**2025-09-24**|**MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors**|Petr Trunin et.al.|[2509.20510](https://arxiv.org/abs/2509.20510)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22652": "|**2025-09-26**|**Pixel Motion Diffusion is What We Need for Robot Control**|E-Ro Nguyen et.al.|[2509.22652](https://arxiv.org/abs/2509.22652)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo et.al.|[2509.22643](https://arxiv.org/abs/2509.22643)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi et.al.|[2509.22642](https://arxiv.org/abs/2509.22642)|**[link](https://huggingface.co/models/WoW-world-model/WoW-1-Wan-14B-600k)**|\n", "2509.22578": "|**2025-09-26**|**EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation**|Yuan Xu et.al.|[2509.22578](https://arxiv.org/abs/2509.22578)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.22544": "|**2025-09-26**|**HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection**|Mohammad Mahdi Hemmatyar et.al.|[2509.22544](https://arxiv.org/abs/2509.22544)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22407": "|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Zhehao Dong et.al.|[2509.22407](https://arxiv.org/abs/2509.22407)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.22402": "|**2025-09-26**|**ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation**|Nan Tang et.al.|[2509.22402](https://arxiv.org/abs/2509.22402)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22356": "|**2025-09-26**|**RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation**|Enguang Liu et.al.|[2509.22356](https://arxiv.org/abs/2509.22356)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22353": "|**2025-09-26**|**Context and Diversity Matter: The Emergence of In-Context Learning in World Models**|Fan Wang et.al.|[2509.22353](https://arxiv.org/abs/2509.22353)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.22175": "|**2025-09-26**|**DHAGrasp: Synthesizing Affordance-Aware Dual-Hand Grasps with Text Instructions**|Quanzhou Li et.al.|[2509.22175](https://arxiv.org/abs/2509.22175)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22149": "|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Haoqi Yuan et.al.|[2509.22149](https://arxiv.org/abs/2509.22149)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei et.al.|[2509.22093](https://arxiv.org/abs/2509.22093)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.21878": "|**2025-09-26**|**WAVE: Worm Gear-based Adaptive Variable Elasticity for Decoupling Actuators from External Forces**|Moses Gladson Selvamuthu et.al.|[2509.21878](https://arxiv.org/abs/2509.21878)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21797": "|**2025-09-26**|**MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation**|Yu Shang et.al.|[2509.21797](https://arxiv.org/abs/2509.21797)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.21790": "|**2025-09-26**|**LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE**|Yu Shang et.al.|[2509.21790](https://arxiv.org/abs/2509.21790)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.21776": "|**2025-09-26**|**The Turkish Ice Cream Robot: Examining Playful Deception in Social Human-Robot Interactions**|Hyeonseong Kim et.al.|[2509.21776](https://arxiv.org/abs/2509.21776)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21664": "|**2025-09-25**|**Generating Stable Placements via Physics-guided Diffusion Models**|Philippe Nadeau et.al.|[2509.21664](https://arxiv.org/abs/2509.21664)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21657": "|**2025-09-25**|**FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction**|Yixiang Dai et.al.|[2509.21657](https://arxiv.org/abs/2509.21657)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.21592": "|**2025-09-25**|**What Happens Next? Anticipating Future Motion by Generating Point Trajectories**|Gabrijel Boduljak et.al.|[2509.21592](https://arxiv.org/abs/2509.21592)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.21574": "|**2025-09-25**|**X-Streamer: Unified Human World Modeling with Audiovisual Interaction**|You Xie et.al.|[2509.21574](https://arxiv.org/abs/2509.21574)|**[link](https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation)**|\n", "2509.22421": "|**2025-09-24**|**Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping**|Leonel Giacobbe et.al.|[2509.22421](https://arxiv.org/abs/2509.22421)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24956": "|**2025-09-29**|**MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation**|Jan Ole von Hartz et.al.|[2509.24956](https://arxiv.org/abs/2509.24956)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao et.al.|[2509.24948](https://arxiv.org/abs/2509.24948)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Markus Peschl et.al.|[2509.24917](https://arxiv.org/abs/2509.24917)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24804": "|**2025-09-29**|**DyMoDreamer: World Modeling with Dynamic Modulation**|Boxuan Zhang et.al.|[2509.24804](https://arxiv.org/abs/2509.24804)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus et.al.|[2509.24768](https://arxiv.org/abs/2509.24768)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.24706": "|**2025-09-29**|**LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers**|Andreea Tulbure et.al.|[2509.24706](https://arxiv.org/abs/2509.24706)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24661": "|**2025-09-29**|**CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations**|Zhiyuan Wu et.al.|[2509.24661](https://arxiv.org/abs/2509.24661)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24591": "|**2025-09-29**|**PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control**|Haozhuo Zhang et.al.|[2509.24591](https://arxiv.org/abs/2509.24591)|**[link](https://github.com/wendell0218/Awesome-RL-for-Video-Generation)**|\n", "2509.24579": "|**2025-09-29**|**U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation**|Linzhi Wu et.al.|[2509.24579](https://arxiv.org/abs/2509.24579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24572": "|**2025-09-29**|**SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics**|Peter H\u00f6nig et.al.|[2509.24572](https://arxiv.org/abs/2509.24572)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari et.al.|[2509.24559](https://arxiv.org/abs/2509.24559)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.24527": "|**2025-09-29**|**Training Agents Inside of Scalable World Models**|Danijar Hafner et.al.|[2509.24527](https://arxiv.org/abs/2509.24527)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.24313": "|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Korbinian Moller et.al.|[2509.24313](https://arxiv.org/abs/2509.24313)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24241": "|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Seungwook Kim et.al.|[2509.24241](https://arxiv.org/abs/2509.24241)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.24163": "|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Wanming Yu et.al.|[2509.24163](https://arxiv.org/abs/2509.24163)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24160": "|**2025-09-29**|**Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation**|Tomoyuki Kagaya et.al.|[2509.24160](https://arxiv.org/abs/2509.24160)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24129": "|**2025-09-28**|**Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress**|Priyanka Mandikal et.al.|[2509.24129](https://arxiv.org/abs/2509.24129)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24116": "|**2025-09-30**|**Dual-Scale World Models for LLM Agents Towards Hard-Exploration Problems**|Minsoo Kim et.al.|[2509.24116](https://arxiv.org/abs/2509.24116)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24093": "|**2025-09-28**|**Clebsch-Gordan Transformer: Fast and Global Equivariant Attention**|Owen Lewis Howell et.al.|[2509.24093](https://arxiv.org/abs/2509.24093)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23979": "|**2025-09-28**|**ByteSized32Refactored: Towards an Extensible Interactive Text Games Corpus for LLM World Modeling and Evaluation**|Haonan Wang et.al.|[2509.23979](https://arxiv.org/abs/2509.23979)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23970": "|**2025-09-28**|**Binary Diff Summarization using Large Language Models**|Meet Udeshi et.al.|[2509.23970](https://arxiv.org/abs/2509.23970)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.23958": "|**2025-09-28**|**Reinforcement Learning with Inverse Rewards for World Model Post-training**|Yang Ye et.al.|[2509.23958](https://arxiv.org/abs/2509.23958)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.23827": "|**2025-09-28**|**Assessing Visual Privacy Risks in Multimodal AI: A Novel Taxonomy-Grounded Evaluation of Vision-Language Models**|Efthymios Tsaprazlis et.al.|[2509.23827](https://arxiv.org/abs/2509.23827)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.23802": "|**2025-09-28**|**STAIR: Addressing Stage Misalignment through Temporal-Aligned Preference Reinforcement Learning**|Yao Luan et.al.|[2509.23802](https://arxiv.org/abs/2509.23802)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas et.al.|[2509.23655](https://arxiv.org/abs/2509.23655)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.23651": "|**2025-09-28**|**HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot**|Xinrong Yang et.al.|[2509.23651](https://arxiv.org/abs/2509.23651)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23649": "|**2025-09-28**|**From Past To Path: Masked History Learning for Next-Item Prediction in Generative Recommendation**|KaiWen Wei et.al.|[2509.23649](https://arxiv.org/abs/2509.23649)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23612": "|**2025-09-28**|**InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects**|Xinhao Cai et.al.|[2509.23612](https://arxiv.org/abs/2509.23612)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2509.23575": "|**2025-09-28**|**Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints**|Jianshu Hu et.al.|[2509.23575](https://arxiv.org/abs/2509.23575)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23567": "|**2025-09-28**|**GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection**|Fangting Xu et.al.|[2509.23567](https://arxiv.org/abs/2509.23567)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23556": "|**2025-09-28**|**Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning**|Curtis C. Johnson et.al.|[2509.23556](https://arxiv.org/abs/2509.23556)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23555": "|**2025-09-28**|**From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations**|Javed Ahmad et.al.|[2509.23555](https://arxiv.org/abs/2509.23555)|**[link](https://github.com/3D-Vision-World/awesome-NeRF-and-3DGS-SLAM)**|\n", "2509.23488": "|**2025-10-01**|**Mapping Overlaps in Benchmarks through Perplexity in the Wild**|Siyang Wu et.al.|[2509.23488](https://arxiv.org/abs/2509.23488)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23468": "|**2025-09-27**|**Multi-Modal Manipulation via Multi-Modal Policy Consensus**|Haonan Chen et.al.|[2509.23468](https://arxiv.org/abs/2509.23468)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23288": "|**2025-09-27**|**A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier**|Yafes Enes \u015eahiner et.al.|[2509.23288](https://arxiv.org/abs/2509.23288)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23155": "|**2025-09-27**|**LAGEA: Language Guided Embodied Agents for Robotic Manipulation**|Abdul Monaf Chowdhury et.al.|[2509.23155](https://arxiv.org/abs/2509.23155)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23121": "|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Shuai Li et.al.|[2509.23121](https://arxiv.org/abs/2509.23121)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.23075": "|**2025-09-27**|**In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer**|Soofiyan Atar et.al.|[2509.23075](https://arxiv.org/abs/2509.23075)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23021": "|**2025-09-27**|**UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes**|Xiao Hu et.al.|[2509.23021](https://arxiv.org/abs/2509.23021)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23008": "|**2025-09-27**|**ARSS: Taming Decoder-only Autoregressive Visual Generation for View Synthesis From Single View**|Wenbin Teng et.al.|[2509.23008](https://arxiv.org/abs/2509.23008)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22914": "|**2025-09-26**|**ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality**|Rohan Walia et.al.|[2509.22914](https://arxiv.org/abs/2509.22914)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22865": "|**2025-09-26**|**Simulation of Transcatheter Therapies for Atrioventricular Valve Regurgitation in an Open-Source Finite Element Simulation Framework**|Seda Aslan et.al.|[2509.22865](https://arxiv.org/abs/2509.22865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22847": "|**2025-09-26**|**Empart: Interactive Convex Decomposition for Converting Meshes to Parts**|Brandon Vu et.al.|[2509.22847](https://arxiv.org/abs/2509.22847)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22814": "|**2025-09-26**|**Model Context Protocol for Vision Systems: Audit, Security, and Protocol Extensions**|Aditi Tiwari et.al.|[2509.22814](https://arxiv.org/abs/2509.22814)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2509.22801": "|**2025-09-30**|**Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem**|Huajing Zhao et.al.|[2509.22801](https://arxiv.org/abs/2509.22801)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu et.al.|[2509.26642](https://arxiv.org/abs/2509.26642)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.26339": "|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Eric R. Damm et.al.|[2509.26339](https://arxiv.org/abs/2509.26339)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.26308": "|**2025-09-30**|**Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation**|Niklas Grambow et.al.|[2509.26308](https://arxiv.org/abs/2509.26308)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.26255": "|**2025-10-01**|**ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning**|Yichao Liang et.al.|[2509.26255](https://arxiv.org/abs/2509.26255)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Zitong Bo et.al.|[2509.25852](https://arxiv.org/abs/2509.25852)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25794": "|**2025-09-30**|**Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding**|Haotian Xue et.al.|[2509.25794](https://arxiv.org/abs/2509.25794)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25756": "|**2025-09-30**|**SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling**|Yixian Zhang et.al.|[2509.25756](https://arxiv.org/abs/2509.25756)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25747": "|**2025-09-30**|**Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real**|Jialei Huang et.al.|[2509.25747](https://arxiv.org/abs/2509.25747)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25746": "|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Shuaijun Wang et.al.|[2509.25746](https://arxiv.org/abs/2509.25746)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25518": "|**2025-10-02**|**World Model for AI Autonomous Navigation in Mechanical Thrombectomy**|Harry Robertshaw et.al.|[2509.25518](https://arxiv.org/abs/2509.25518)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.25402": "|**2025-09-29**|**Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models**|Hanlan Yang et.al.|[2509.25402](https://arxiv.org/abs/2509.25402)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25373": "|**2025-09-29**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou et.al.|[2509.25373](https://arxiv.org/abs/2509.25373)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25358": "|**2025-10-02**|**SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation**|Qianzhong Chen et.al.|[2509.25358](https://arxiv.org/abs/2509.25358)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25352": "|**2025-09-29**|**SRMP: Search-Based Robot Motion Planning Library**|Itamar Mishani et.al.|[2509.25352](https://arxiv.org/abs/2509.25352)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25161": "|**2025-09-29**|**Rolling Forcing: Autoregressive Long Video Diffusion in Real Time**|Kunhao Liu et.al.|[2509.25161](https://arxiv.org/abs/2509.25161)|**[link](https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey)**|\n", "2509.25282": "|**2025-09-29**|**Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments**|Jiexi Xu et.al.|[2509.25282](https://arxiv.org/abs/2509.25282)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02287": "|**2025-10-02**|**MultiModal Action Conditioned Video Generation**|Yichen Li et.al.|[2510.02287](https://arxiv.org/abs/2510.02287)|**[link](https://github.com/wendell0218/Awesome-RL-for-Video-Generation)**|\n", "2510.02110": "|**2025-10-02**|**SoundReactor: Frame-level Online Video-to-Audio Generation**|Koichi Saito et.al.|[2510.02110](https://arxiv.org/abs/2510.02110)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02104": "|**2025-10-02**|**LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions**|Yunhan Lin et.al.|[2510.02104](https://arxiv.org/abs/2510.02104)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02081": "|**2025-10-02**|**Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions**|Zhaoyi Li et.al.|[2510.02081](https://arxiv.org/abs/2510.02081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim et.al.|[2510.01711](https://arxiv.org/abs/2510.01711)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.01699": "|**2025-10-02**|**Towards Imperceptible Adversarial Defense: A Gradient-Driven Shield against Facial Manipulations**|Yue Li et.al.|[2510.01699](https://arxiv.org/abs/2510.01699)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin et.al.|[2510.01642](https://arxiv.org/abs/2510.01642)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.01641": "|**2025-10-02**|**FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring**|Xiaoyang Liu et.al.|[2510.01641](https://arxiv.org/abs/2510.01641)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01607": "|**2025-10-02**|**ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations**|Qiyuan Zeng et.al.|[2510.01607](https://arxiv.org/abs/2510.01607)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2510.01603": "|**2025-10-02**|**MiniBEE: A New Form Factor for Compact Bimanual Dexterity**|Sharfin Islam et.al.|[2510.01603](https://arxiv.org/abs/2510.01603)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01545": "|**2025-10-02**|**Predictive Preference Learning from Human Interventions**|Haoyuan Cai et.al.|[2510.01545](https://arxiv.org/abs/2510.01545)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.01531": "|**2025-10-02**|**Information Seeking for Robust Decision Making under Partial Observability**|Djengo Cyun-Jyun Fang et.al.|[2510.01531](https://arxiv.org/abs/2510.01531)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01433": "|**2025-10-01**|**AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation**|Anukriti Singh et.al.|[2510.01433](https://arxiv.org/abs/2510.01433)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01184": "|**2025-10-01**|**Temporal Score Rescaling for Temperature Sampling in Diffusion and Flow Models**|Yanbo Xu et.al.|[2510.01184](https://arxiv.org/abs/2510.01184)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01183": "|**2025-10-01**|**EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory**|Jiahao Wang et.al.|[2510.01183](https://arxiv.org/abs/2510.01183)|**[link](https://github.com/worldbench/survey)**|\n", "2510.01179": "|**2025-10-01**|**TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments**|Zhangchen Xu et.al.|[2510.01179](https://arxiv.org/abs/2510.01179)|**[link](https://huggingface.co/models/Agent-Ark/Toucan-Qwen2.5-7B-Instruct-v0.1)**|\n", "2510.00855": "|**2025-10-01**|**Can World Models Benefit VLMs for World Dynamics?**|Kevin Zhang et.al.|[2510.00855](https://arxiv.org/abs/2510.00855)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.00770": "|**2025-10-06**|**Tele-rehabilitation with online skill transfer and adaptation in $\\mathbb{R}^3 \\times \\mathit{S}^3$**|Tianle Ni et.al.|[2510.00770](https://arxiv.org/abs/2510.00770)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00739": "|**2025-10-01**|**TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning**|Marco Bagatella et.al.|[2510.00739](https://arxiv.org/abs/2510.00739)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00726": "|**2025-10-01**|**CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation**|Giovanni Minelli et.al.|[2510.00726](https://arxiv.org/abs/2510.00726)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00695": "|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo et.al.|[2510.00695](https://arxiv.org/abs/2510.00695)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.00682": "|**2025-10-01**|**Shared Object Manipulation with a Team of Collaborative Quadrupeds**|Shengzhi Wang et.al.|[2510.00682](https://arxiv.org/abs/2510.00682)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00600": "|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia et.al.|[2510.00600](https://arxiv.org/abs/2510.00600)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.00506": "|**2025-10-01**|**Affordance-Guided Diffusion Prior for 3D Hand Reconstruction**|Naru Suzuki et.al.|[2510.00506](https://arxiv.org/abs/2510.00506)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00493": "|**2025-10-01**|**Correlation function metrology for warm dense matter: Recent developments and practical guidelines**|Maximilian Peter B\u00f6hme et.al.|[2510.00493](https://arxiv.org/abs/2510.00493)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li et.al.|[2510.00406](https://arxiv.org/abs/2510.00406)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.00154": "|**2025-09-30**|**RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes**|Xinyi Liu et.al.|[2510.00154](https://arxiv.org/abs/2510.00154)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03198": "|**2025-10-03**|**Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft**|Junchao Huang et.al.|[2510.03198](https://arxiv.org/abs/2510.03198)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03135": "|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Gen Li et.al.|[2510.03135](https://arxiv.org/abs/2510.03135)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.02851": "|**2025-10-03**|**Action Deviation-Aware Inference for Low-Latency Wireless Robots**|Jeyoung Park et.al.|[2510.02851](https://arxiv.org/abs/2510.02851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02738": "|**2025-10-03**|**Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data**|Tianyu Li et.al.|[2510.02738](https://arxiv.org/abs/2510.02738)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02594": "|**2025-10-02**|**SubSense: VR-Haptic and Motor Feedback for Immersive Control in Subsea Telerobotics**|Ruo Chen et.al.|[2510.02594](https://arxiv.org/abs/2510.02594)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02538": "|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Yilin Wang et.al.|[2510.02538](https://arxiv.org/abs/2510.02538)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.02526": "|**2025-10-02**|**U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation**|Anamika J H et.al.|[2510.02526](https://arxiv.org/abs/2510.02526)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02387": "|**2025-09-30**|**CWM: An Open-Weights LLM for Research on Code Generation with World Models**|FAIR CodeGen team et.al.|[2510.02387](https://arxiv.org/abs/2510.02387)|**[link](https://github.com/DSXiangLi/DecryptPrompt)**|\n", "2510.05057": "|**2025-10-06**|**StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation**|Mingyu Liu et.al.|[2510.05057](https://arxiv.org/abs/2510.05057)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.04978": "|**2025-10-06**|**Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI**|Kun Xiang et.al.|[2510.04978](https://arxiv.org/abs/2510.04978)|**[link](https://github.com/minnie-lin/Awesome-Physics-Cognition-based-Video-Generation)**|\n", "2510.04781": "|**2025-10-06**|**Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization**|Javed Ahmad et.al.|[2510.04781](https://arxiv.org/abs/2510.04781)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04585": "|**2025-10-06**|**Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation**|Jianshu Zhou et.al.|[2510.04585](https://arxiv.org/abs/2510.04585)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04542": "|**2025-10-06**|**Code World Models for General Game Playing**|Wolfgang Lehrach et.al.|[2510.04542](https://arxiv.org/abs/2510.04542)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.04391": "|**2025-10-05**|**Internal World Models as Imagination Networks in Cognitive Agents**|Saurabh Ranjan et.al.|[2510.04391](https://arxiv.org/abs/2510.04391)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.04390": "|**2025-10-05**|**MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator**|Xuehai He et.al.|[2510.04390](https://arxiv.org/abs/2510.04390)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.04374": "|**2025-10-05**|**GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks**|Tejal Patwardhan et.al.|[2510.04374](https://arxiv.org/abs/2510.04374)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04354": "|**2025-10-05**|**Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators**|Apurva Badithela et.al.|[2510.04354](https://arxiv.org/abs/2510.04354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04263": "|**2025-10-05**|**Efficient Latent Variable Causal Discovery: Combining Score Search and Targeted Testing**|Joseph Ramsey et.al.|[2510.04263](https://arxiv.org/abs/2510.04263)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04171": "|**2025-10-05**|**VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs**|Lakshadeep Naik et.al.|[2510.04171](https://arxiv.org/abs/2510.04171)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.04020": "|**2025-10-09**|**Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models**|Hao Wu et.al.|[2510.04020](https://arxiv.org/abs/2510.04020)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.03895": "|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Zheng Huang et.al.|[2510.03895](https://arxiv.org/abs/2510.03895)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.03827": "|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Xueyang Zhou et.al.|[2510.03827](https://arxiv.org/abs/2510.03827)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.03727": "|**2025-10-04**|**Bridging the Gap Between Multimodal Foundation Models and World Models**|Xuehai He et.al.|[2510.03727](https://arxiv.org/abs/2510.03727)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03706": "|**2025-10-04**|**EmbodiSwap for Zero-Shot Robot Imitation Learning**|Eadom Dessalene et.al.|[2510.03706](https://arxiv.org/abs/2510.03706)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03460": "|**2025-10-03**|**Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching**|Sibo Tian et.al.|[2510.03460](https://arxiv.org/abs/2510.03460)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03420": "|**2025-10-03**|**A Generalized Second-Order Positivity-Preserving Numerical Method for Non-Autonomous Dynamical Systems with Applications**|Manh Tuan Hoang et.al.|[2510.03420](https://arxiv.org/abs/2510.03420)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06209": "|**2025-10-07**|**Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models**|Jiahao Wang et.al.|[2510.06209](https://arxiv.org/abs/2510.06209)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06207": "|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zefu Lin et.al.|[2510.06207](https://arxiv.org/abs/2510.06207)|**[link](https://github.com/xjywhu/Awesome-Multimodal-LLM-for-Code)**|\n", "2510.06146": "|**2025-10-07**|**Vision-Guided Targeted Grasping and Vibration for Robotic Pollination in Controlled Environments**|Jaehwan Jeong et.al.|[2510.06146](https://arxiv.org/abs/2510.06146)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06068": "|**2025-10-07**|**Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning**|Heng Zhang et.al.|[2510.06068](https://arxiv.org/abs/2510.06068)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05865": "|**2025-10-07**|**The Safety Challenge of World Models for Embodied AI Agents: A Review**|Lorenzo Baraldi et.al.|[2510.05865](https://arxiv.org/abs/2510.05865)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2510.05827": "|**2025-10-07**|**VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation**|Haoran Zhang et.al.|[2510.05827](https://arxiv.org/abs/2510.05827)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05705": "|**2025-10-07**|**The Software Observatory: aggregating and analysing software metadata for trend computation and FAIR assessment**|Eva Mart\u00edn del Pico et.al.|[2510.05705](https://arxiv.org/abs/2510.05705)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05662": "|**2025-10-07**|**DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation**|Taeyeop Lee et.al.|[2510.05662](https://arxiv.org/abs/2510.05662)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05619": "|**2025-10-07**|**Teaching Machines to Speak Using Articulatory Control**|Akshay Anand et.al.|[2510.05619](https://arxiv.org/abs/2510.05619)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2510.05536": "|**2025-10-07**|**Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation**|Mahboubeh Zarei et.al.|[2510.05536](https://arxiv.org/abs/2510.05536)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05188": "|**2025-10-06**|**Plug-and-Play Dramaturge: A Divide-and-Conquer Approach for Iterative Narrative Script Refinement via Collaborative LLM Agents**|Wenda Xie et.al.|[2510.05188](https://arxiv.org/abs/2510.05188)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.07313": "|**2025-10-08**|**WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation**|Zezhong Qian et.al.|[2510.07313](https://arxiv.org/abs/2510.07313)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.07181": "|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Yi Han et.al.|[2510.07181](https://arxiv.org/abs/2510.07181)|**[link](https://huggingface.co/models/hany01rye/TIGeR)**|\n", "2510.07092": "|**2025-10-08**|**Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report**|Riccardo Mereu et.al.|[2510.07092](https://arxiv.org/abs/2510.07092)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.07027": "|**2025-10-08**|**Tailoring materials into kirigami robots**|Saravana Prashanth Murali Babu et.al.|[2510.07027](https://arxiv.org/abs/2510.07027)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06492": "|**2025-10-07**|**What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?**|Matthew Kim et.al.|[2510.06492](https://arxiv.org/abs/2510.06492)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06448": "|**2025-10-07**|**How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation**|Prabhant Singh et.al.|[2510.06448](https://arxiv.org/abs/2510.06448)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06339": "|**2025-10-07**|**Vi-TacMan: Articulated Object Manipulation via Vision and Touch**|Leiyao Cui et.al.|[2510.06339](https://arxiv.org/abs/2510.06339)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08568": "|**2025-10-09**|**NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos**|Hongyu Li et.al.|[2510.08568](https://arxiv.org/abs/2510.08568)|**[link](https://github.com/ALEEEHU/World-Simulator)**|\n", "2510.08558": "|**2025-10-13**|**Agent Learning via Early Experience**|Kai Zhang et.al.|[2510.08558](https://arxiv.org/abs/2510.08558)|**[link](https://github.com/DSXiangLi/DecryptPrompt)**|\n", "2510.08553": "|**2025-10-09**|**Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation**|Yunzhe Xu et.al.|[2510.08553](https://arxiv.org/abs/2510.08553)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08547": "|**2025-10-09**|**R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation**|Xiuwei Xu et.al.|[2510.08547](https://arxiv.org/abs/2510.08547)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Zeqing Wang et.al.|[2510.08398](https://arxiv.org/abs/2510.08398)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.08316": "|**2025-10-09**|**Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge**|Yu Huang et.al.|[2510.08316](https://arxiv.org/abs/2510.08316)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08022": "|**2025-10-09**|**FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset**|Kehui Liu et.al.|[2510.08022](https://arxiv.org/abs/2510.08022)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07975": "|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Mingyang Sun et.al.|[2510.07975](https://arxiv.org/abs/2510.07975)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07974": "|**2025-10-11**|**Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning**|Jialu Du et.al.|[2510.07974](https://arxiv.org/abs/2510.07974)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.07944": "|**2025-10-09**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Tianrui Zhang et.al.|[2510.07944](https://arxiv.org/abs/2510.07944)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.07865": "|**2025-10-09**|**DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation**|Guowei Zou et.al.|[2510.07865](https://arxiv.org/abs/2510.07865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07773": "|**2025-10-09**|**Trajectory Conditioned Cross-embodiment Skill Transfer**|YuHang Tang et.al.|[2510.07773](https://arxiv.org/abs/2510.07773)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.07674": "|**2025-10-11**|**Differentiable Particle Optimization for Fast Sequential Manipulation**|Lucas Chen et.al.|[2510.07674](https://arxiv.org/abs/2510.07674)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07548": "|**2025-10-08**|**AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation**|Adam Hung et.al.|[2510.07548](https://arxiv.org/abs/2510.07548)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07456": "|**2025-10-08**|**ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning**|Binrong Zhu et.al.|[2510.07456](https://arxiv.org/abs/2510.07456)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.07417": "|**2025-10-08**|**FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams**|Corban Rivera et.al.|[2510.07417](https://arxiv.org/abs/2510.07417)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong et.al.|[2510.09607](https://arxiv.org/abs/2510.09607)|**[link](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)**|\n", "2510.09507": "|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Zixin Zhang et.al.|[2510.09507](https://arxiv.org/abs/2510.09507)|**[link](https://huggingface.co/datasets/zhangzixin02/PhysToolBench)**|\n", "2510.09267": "|**2025-10-10**|**Placeit! A Framework for Learning Robot Object Placement Skills**|Amina Ferrad et.al.|[2510.09267](https://arxiv.org/abs/2510.09267)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09229": "|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Yuyang Gao et.al.|[2510.09229](https://arxiv.org/abs/2510.09229)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09209": "|**2025-10-10**|**PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation**|Yuki Kuroda et.al.|[2510.09209](https://arxiv.org/abs/2510.09209)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09036": "|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Chuanrui Zhang et.al.|[2510.09036](https://arxiv.org/abs/2510.09036)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.08753": "|**2025-10-09**|**Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics**|A. Wang et.al.|[2510.08753](https://arxiv.org/abs/2510.08753)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2510.08713": "|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Yifei Dong et.al.|[2510.08713](https://arxiv.org/abs/2510.08713)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Maggie Wang et.al.|[2510.11689](https://arxiv.org/abs/2510.11689)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2510.11687": "|**2025-10-13**|**Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View**|Jinyu Zhang et.al.|[2510.11687](https://arxiv.org/abs/2510.11687)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Hang Liu et.al.|[2510.11682](https://arxiv.org/abs/2510.11682)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.11664": "|**2025-10-13**|**Proprioceptive Misestimation of Hand Speed**|Caitlin Callaghan et.al.|[2510.11664](https://arxiv.org/abs/2510.11664)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11660": "|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Yi Yang et.al.|[2510.11660](https://arxiv.org/abs/2510.11660)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.11413": "|**2025-10-13**|**Trajectory control of a suspended load with non-stopping flying carriers**|Sofia Girardello et.al.|[2510.11413](https://arxiv.org/abs/2510.11413)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.11321": "|**2025-10-13**|**HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data**|Ruizhe Liu et.al.|[2510.11321](https://arxiv.org/abs/2510.11321)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11036": "|**2025-10-13**|**XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation**|Yeonseo Lee et.al.|[2510.11036](https://arxiv.org/abs/2510.11036)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11011": "|**2025-10-13**|**GrASP: A Generalizable Address-based Semantic Prefetcher for Scalable Transactional and Analytical Workloads**|Farzaneh Zirak et.al.|[2510.11011](https://arxiv.org/abs/2510.11011)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10960": "|**2025-10-13**|**Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving**|Dong Hu et.al.|[2510.10960](https://arxiv.org/abs/2510.10960)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.10903": "|**2025-10-13**|**Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey**|Shuanghao Bai et.al.|[2510.10903](https://arxiv.org/abs/2510.10903)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.10778": "|**2025-10-12**|**Real2USD: Scene Representations in Universal Scene Description Language**|Christopher D. Hsu et.al.|[2510.10778](https://arxiv.org/abs/2510.10778)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10670": "|**2025-10-12**|**AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes**|Yu Li et.al.|[2510.10670](https://arxiv.org/abs/2510.10670)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.10637": "|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Haoyu Zhao et.al.|[2510.10637](https://arxiv.org/abs/2510.10637)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|\n", "2510.10602": "|**2025-10-12**|**SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams**|Zhuoheng Gao et.al.|[2510.10602](https://arxiv.org/abs/2510.10602)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10556": "|**2025-10-12**|**Self-Supervised Representation Learning with ID-Content Modality Alignment for Sequential Recommendation**|Donglin Zhou et.al.|[2510.10556](https://arxiv.org/abs/2510.10556)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10516": "|**2025-10-12**|**Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control**|Kanishkha Jaisankar et.al.|[2510.10516](https://arxiv.org/abs/2510.10516)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10325": "|**2025-10-11**|**KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments**|Walid Abdela et.al.|[2510.10325](https://arxiv.org/abs/2510.10325)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10273": "|**2025-10-14**|**Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles**|Vincent Schoenbach et.al.|[2510.10273](https://arxiv.org/abs/2510.10273)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10221": "|**2025-10-11**|**A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots**|Hyogo Hiruma et.al.|[2510.10221](https://arxiv.org/abs/2510.10221)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10125": "|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Yanjiang Guo et.al.|[2510.10125](https://arxiv.org/abs/2510.10125)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.10016": "|**2025-10-11**|**Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations**|Shahid Ansari et.al.|[2510.10016](https://arxiv.org/abs/2510.10016)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09682": "|**2025-10-08**|**Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices**|Rupam Patir et.al.|[2510.09682](https://arxiv.org/abs/2510.09682)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12796": "|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Yingyan Li et.al.|[2510.12796](https://arxiv.org/abs/2510.12796)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.12724": "|**2025-10-14**|**T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping**|Xin Fei et.al.|[2510.12724](https://arxiv.org/abs/2510.12724)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12560": "|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Xiaoji Zheng et.al.|[2510.12560](https://arxiv.org/abs/2510.12560)|**[link](https://huggingface.co/models/Student-Xiaoji/CoIRL-AD-models)**|\n", "2510.12528": "|**2025-10-14**|**Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception**|Muxing Huang et.al.|[2510.12528](https://arxiv.org/abs/2510.12528)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12509": "|**2025-10-14**|**Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge**|Gaoyuan Liu et.al.|[2510.12509](https://arxiv.org/abs/2510.12509)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12483": "|**2025-10-14**|**Fast Visuomotor Policy for Robotic Manipulation**|Jingkai Jia et.al.|[2510.12483](https://arxiv.org/abs/2510.12483)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12392": "|**2025-10-14**|**Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking**|Junhyuk So et.al.|[2510.12392](https://arxiv.org/abs/2510.12392)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12312": "|**2025-10-14**|**Deep SPI: Safe Policy Improvement via World Models**|Florent Delgrange et.al.|[2510.12312](https://arxiv.org/abs/2510.12312)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.12088": "|**2025-10-14**|**One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration**|Zaid Khan et.al.|[2510.12088](https://arxiv.org/abs/2510.12088)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.11892": "|**2025-10-13**|**R-WoM: Retrieval-augmented World Model For Computer-use Agents**|Kai Mei et.al.|[2510.11892](https://arxiv.org/abs/2510.11892)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.13809": "|**2025-10-15**|**PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning**|Sihui Ji et.al.|[2510.13809](https://arxiv.org/abs/2510.13809)|**[link](https://github.com/minnie-lin/Awesome-Physics-Cognition-based-Video-Generation)**|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Xinchen Zhang et.al.|[2510.13804](https://arxiv.org/abs/2510.13804)|**[link](https://huggingface.co/models/comin/OmniVerifier-7B)**|\n", "2510.13626": "|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei et.al.|[2510.13626](https://arxiv.org/abs/2510.13626)|**[link](https://huggingface.co/models/Sylvest/openvla-7b-oft-finetuned-libero-plus-mixdata)**|\n", "2510.13616": "|**2025-10-15**|**Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor**|Preston Fairchild et.al.|[2510.13616](https://arxiv.org/abs/2510.13616)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13595": "|**2025-10-15**|**Active Tactile Exploration for Rigid Body Pose and Shape Estimation**|Ethan K. Gordon et.al.|[2510.13595](https://arxiv.org/abs/2510.13595)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13553": "|**2025-10-16**|**Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping**|Wentao Guo et.al.|[2510.13553](https://arxiv.org/abs/2510.13553)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13535": "|**2025-10-15**|**A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints**|Wentao Guo et.al.|[2510.13535](https://arxiv.org/abs/2510.13535)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13324": "|**2025-10-15**|**Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation**|Erik Helmut et.al.|[2510.13324](https://arxiv.org/abs/2510.13324)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13247": "|**2025-10-15**|**Agency cannot be a purely quantum phenomenon**|Emily C. Adlam et.al.|[2510.13247](https://arxiv.org/abs/2510.13247)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Haochuan Xu et.al.|[2510.13237](https://arxiv.org/abs/2510.13237)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal et.al.|[2510.13054](https://arxiv.org/abs/2510.13054)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.13005": "|**2025-10-18**|**Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations**|Robert Muldrow et.al.|[2510.13005](https://arxiv.org/abs/2510.13005)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12971": "|**2025-10-14**|**Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation**|Anran Zhang et.al.|[2510.12971](https://arxiv.org/abs/2510.12971)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12866": "|**2025-10-14**|**Learning to Grasp Anything by Playing with Random Toys**|Dantong Niu et.al.|[2510.12866](https://arxiv.org/abs/2510.12866)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2510.14977": "|**2025-10-16**|**Terra: Explorable Native 3D World Model with Point Latents**|Yuanhui Huang et.al.|[2510.14977](https://arxiv.org/abs/2510.14977)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.14874": "|**2025-10-16**|**TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions**|Guangyi Han et.al.|[2510.14874](https://arxiv.org/abs/2510.14874)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14830": "|**2025-10-16**|**RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning**|Kun Lei et.al.|[2510.14830](https://arxiv.org/abs/2510.14830)|**[link](https://github.com/YanjieZe/3D-Diffusion-Policy)**|\n", "2510.14783": "|**2025-10-16**|**SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning**|Aderik Verraest et.al.|[2510.14783](https://arxiv.org/abs/2510.14783)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14771": "|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Xu Chi et.al.|[2510.14771](https://arxiv.org/abs/2510.14771)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14768": "|**2025-10-16**|**Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery**|Fan Yang et.al.|[2510.14768](https://arxiv.org/abs/2510.14768)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14615": "|**2025-10-16**|**Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models**|Edward Sandra et.al.|[2510.14615](https://arxiv.org/abs/2510.14615)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14584": "|**2025-10-16**|**A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning**|Benno Wingender et.al.|[2510.14584](https://arxiv.org/abs/2510.14584)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14300": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Weijie Shen et.al.|[2510.14300](https://arxiv.org/abs/2510.14300)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.14117": "|**2025-10-15**|**ViTacGen: Robotic Pushing with Vision-to-Touch Generation**|Zhiyuan Wu et.al.|[2510.14117](https://arxiv.org/abs/2510.14117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14065": "|**2025-10-15**|**Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning**|Gaoyuan Liu et.al.|[2510.14065](https://arxiv.org/abs/2510.14065)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14049": "|**2025-10-17**|**CausalVerse: Benchmarking Causal Representation Learning with Configurable High-Fidelity Simulations**|Guangyi Chen et.al.|[2510.14049](https://arxiv.org/abs/2510.14049)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15786": "|**2025-10-23**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Xinyue Xu et.al.|[2510.15786](https://arxiv.org/abs/2510.15786)|**[link](https://huggingface.co/datasets/DEXROBOT/DexCanvas)**|\n", "2510.15638": "|**2025-10-17**|**Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS**|Jared K. Lepora et.al.|[2510.15638](https://arxiv.org/abs/2510.15638)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15530": "|**2025-10-23**|**VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation**|Zehao Ni et.al.|[2510.15530](https://arxiv.org/abs/2510.15530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15422": "|**2025-10-17**|**Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction**|Lin Wang et.al.|[2510.15422](https://arxiv.org/abs/2510.15422)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15189": "|**2025-10-16**|**RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation**|Xiangyu Chen et.al.|[2510.15189](https://arxiv.org/abs/2510.15189)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15144": "|**2025-10-16**|**HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks**|Chance Jiajie Li et.al.|[2510.15144](https://arxiv.org/abs/2510.15144)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15047": "|**2025-10-16**|**Internalizing World Models via Self-Play Finetuning for Agentic RL**|Shiqi Chen et.al.|[2510.15047](https://arxiv.org/abs/2510.15047)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.15041": "|**2025-10-16**|**Generalized Dynamics Generation towards Scannable Physical World Model**|Yichen Li et.al.|[2510.15041](https://arxiv.org/abs/2510.15041)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17731": "|**2025-10-20**|**Can Image-To-Video Models Simulate Pedestrian Dynamics?**|Aaron Appelle et.al.|[2510.17731](https://arxiv.org/abs/2510.17731)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Yuquan Xue et.al.|[2510.17640](https://arxiv.org/abs/2510.17640)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.17598": "|**2025-10-20**|**Reasoning Distillation and Structural Alignment for Improved Code Generation**|Amir Jalilifard et.al.|[2510.17598](https://arxiv.org/abs/2510.17598)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17576": "|**2025-10-20**|**Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries**|Cansu Erdogan et.al.|[2510.17576](https://arxiv.org/abs/2510.17576)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17482": "|**2025-10-22**|**SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries**|Chenxu Dang et.al.|[2510.17482](https://arxiv.org/abs/2510.17482)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.17448": "|**2025-10-20**|**A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions**|Mirko Mizzoni et.al.|[2510.17448](https://arxiv.org/abs/2510.17448)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17150": "|**2025-10-22**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Heng Zhang et.al.|[2510.17150](https://arxiv.org/abs/2510.17150)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17086": "|**2025-10-20**|**Learning to Design Soft Hands using Reward Models**|Xueqian Bai et.al.|[2510.17086](https://arxiv.org/abs/2510.17086)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Kangrui Wang et.al.|[2510.16907](https://arxiv.org/abs/2510.16907)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.16756": "|**2025-10-19**|**End-to-end Listen, Look, Speak and Act**|Siyin Wang et.al.|[2510.16756](https://arxiv.org/abs/2510.16756)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16732": "|**2025-10-19**|**A Comprehensive Survey on World Models for Embodied AI**|Xinqing Li et.al.|[2510.16732](https://arxiv.org/abs/2510.16732)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.16729": "|**2025-10-19**|**Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models**|Jianbiao Mei et.al.|[2510.16729](https://arxiv.org/abs/2510.16729)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ruihan Zhao et.al.|[2510.16617](https://arxiv.org/abs/2510.16617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16524": "|**2025-10-18**|**Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping**|Haokai Ding et.al.|[2510.16524](https://arxiv.org/abs/2510.16524)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16517": "|**2025-10-18**|**A Novel Gripper with Semi-Peaucellier Linkage and Idle-Stroke Mechanism for Linear Pinching and Self-Adaptive Grasping**|Haokai Ding et.al.|[2510.16517](https://arxiv.org/abs/2510.16517)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16500": "|**2025-10-18**|**Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks**|Chen Min et.al.|[2510.16500](https://arxiv.org/abs/2510.16500)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16231": "|**2025-10-17**|**DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly**|Bihao Zhang et.al.|[2510.16231](https://arxiv.org/abs/2510.16231)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16123": "|**2025-10-17**|**Zero-shot World Models via Search in Memory**|Federico Malato et.al.|[2510.16123](https://arxiv.org/abs/2510.16123)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.16039": "|**2025-10-16**|**Vector Quantization in the Brain: Grid-like Codes in World Models**|Xiangyuan Peng et.al.|[2510.16039](https://arxiv.org/abs/2510.16039)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.18876": "|**2025-10-22**|**Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs**|Haochen Wang et.al.|[2510.18876](https://arxiv.org/abs/2510.18876)|**[link](https://huggingface.co/spaces/laolida-w/1)**|\n", "2510.18558": "|**2025-10-21**|**Flexbee: A Grasping and Perching UAV Based on Soft Vector-Propulsion Nozzle**|Yue Wang et.al.|[2510.18558](https://arxiv.org/abs/2510.18558)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18315": "|**2025-10-21**|**Higher Embedding Dimension Creates a Stronger World Model for a Simple Sorting Task**|Brady Bhalla et.al.|[2510.18315](https://arxiv.org/abs/2510.18315)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.18313": "|**2025-10-24**|**OmniNWM: Omniscient Driving Navigation World Models**|Bohan Li et.al.|[2510.18313](https://arxiv.org/abs/2510.18313)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.18135": "|**2025-10-20**|**World-in-World: World Models in a Closed-Loop World**|Jiahan Zhang et.al.|[2510.18135](https://arxiv.org/abs/2510.18135)|**[link](https://huggingface.co/datasets/zonszer/WIW_datasets)**|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Jacob Berg et.al.|[2510.19818](https://arxiv.org/abs/2510.19818)|**[link](https://github.com/microsoft/OpenKP)**|\n", "2510.19788": "|**2025-10-23**|**Benchmarking World-Model Learning**|Archana Warrier et.al.|[2510.19788](https://arxiv.org/abs/2510.19788)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19654": "|**2025-10-22**|**From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction**|Zhida Zhao et.al.|[2510.19654](https://arxiv.org/abs/2510.19654)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team et.al.|[2510.19430](https://arxiv.org/abs/2510.19430)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng et.al.|[2510.19400](https://arxiv.org/abs/2510.19400)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.19364": "|**2025-10-22**|**ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling**|Golnaz Raja et.al.|[2510.19364](https://arxiv.org/abs/2510.19364)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19289": "|**2025-10-22**|**TARMAC: A Taxonomy for Robot Manipulation in Chemistry**|Kefeng Huang et.al.|[2510.19289](https://arxiv.org/abs/2510.19289)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19270": "|**2025-10-22**|**Social World Model-Augmented Mechanism Design Policy Learning**|Xiaoyuan Zhang et.al.|[2510.19270](https://arxiv.org/abs/2510.19270)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19200": "|**2025-10-22**|**GRASPLAT: Enabling dexterous grasping through novel view synthesis**|Matteo Bortolon et.al.|[2510.19200](https://arxiv.org/abs/2510.19200)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2510.19195": "|**2025-10-24**|**Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks**|Kai Zeng et.al.|[2510.19195](https://arxiv.org/abs/2510.19195)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.19128": "|**2025-10-21**|**A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model**|Mehran Ghafarian Tamizi et.al.|[2510.19128](https://arxiv.org/abs/2510.19128)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19081": "|**2025-10-21**|**Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory**|Shifa Sulaiman et.al.|[2510.19081](https://arxiv.org/abs/2510.19081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19057": "|**2025-10-21**|**Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in Plan-to-Grasp Visuomotor Tasks**|Anna Cetera et.al.|[2510.19057](https://arxiv.org/abs/2510.19057)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20822": "|**2025-10-23**|**HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives**|Yihao Meng et.al.|[2510.20822](https://arxiv.org/abs/2510.20822)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2510.20813": "|**2025-10-23**|**GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation**|Guangqi Jiang et.al.|[2510.20813](https://arxiv.org/abs/2510.20813)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.20774": "|**2025-10-28**|**FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation**|Wenhao Wang et.al.|[2510.20774](https://arxiv.org/abs/2510.20774)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.20751": "|**2025-10-23**|**Black Hole-Host Galaxy Correlations with Machine Learning: A Comparative Study of Illustris, TNG, and EAGLE**|Jacob Reinheimer et.al.|[2510.20751](https://arxiv.org/abs/2510.20751)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20668": "|**2025-10-23**|**From Masks to Worlds: A Hitchhiker's Guide to World Models**|Jinbin Bai et.al.|[2510.20668](https://arxiv.org/abs/2510.20668)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.20496": "|**2025-10-23**|**A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator**|Tobias Marauli et.al.|[2510.20496](https://arxiv.org/abs/2510.20496)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20483": "|**2025-10-23**|**Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty**|Victor Vantilborgh et.al.|[2510.20483](https://arxiv.org/abs/2510.20483)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20407": "|**2025-10-23**|**MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control**|Kohei Nishi et.al.|[2510.20407](https://arxiv.org/abs/2510.20407)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20406": "|**2025-10-23**|**PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning**|Xiaogang Jia et.al.|[2510.20406](https://arxiv.org/abs/2510.20406)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20390": "|**2025-10-23**|**NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control**|Yijiong Lin et.al.|[2510.20390](https://arxiv.org/abs/2510.20390)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Ajay Sridhar et.al.|[2510.20328](https://arxiv.org/abs/2510.20328)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|\n", "2510.19944": "|**2025-10-22**|**Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets**|Jiashi Feng et.al.|[2510.19944](https://arxiv.org/abs/2510.19944)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21691": "|**2025-10-27**|**On Uncertainty Calibration for Equivariant Functions**|Edward Berman et.al.|[2510.21691](https://arxiv.org/abs/2510.21691)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21682": "|**2025-10-24**|**WorldGrow: Generating Infinite 3D World**|Sikuang Li et.al.|[2510.21682](https://arxiv.org/abs/2510.21682)|**[link](https://github.com/hzxie/Awesome-3D-Scene-Generation)**|\n", "2510.21609": "|**2025-10-24**|**Enhancing Tactile-based Reinforcement Learning for Robotic Control**|Elle Miller et.al.|[2510.21609](https://arxiv.org/abs/2510.21609)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Qixiu Li et.al.|[2510.21571](https://arxiv.org/abs/2510.21571)|**[link](https://github.com/microsoft/VITRA)**|\n", "2510.21447": "|**2025-10-24**|**PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis**|Yu Yang et.al.|[2510.21447](https://arxiv.org/abs/2510.21447)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.21418": "|**2025-10-24**|**DreamerV3-XP: Optimizing exploration through uncertainty estimation**|Lukas Bierling et.al.|[2510.21418](https://arxiv.org/abs/2510.21418)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.21232": "|**2025-10-24**|**How Hard is it to Confuse a World Model?**|Waris Radji et.al.|[2510.21232](https://arxiv.org/abs/2510.21232)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.21219": "|**2025-10-24**|**World Models Should Prioritize the Unification of Physical and Social Dynamics**|Xiaoyuan Zhang et.al.|[2510.21219](https://arxiv.org/abs/2510.21219)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.21121": "|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Haibo Zhao et.al.|[2510.21121](https://arxiv.org/abs/2510.21121)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21000": "|**2025-10-23**|**BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies**|Jiaqi Hu et.al.|[2510.21000](https://arxiv.org/abs/2510.21000)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Jesse Haworth et.al.|[2510.20965](https://arxiv.org/abs/2510.20965)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.20884": "|**2025-10-23**|**ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning**|Pranamya Kulkarni et.al.|[2510.20884](https://arxiv.org/abs/2510.20884)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Yash Jangir et.al.|[2510.23571](https://arxiv.org/abs/2510.23571)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23509": "|**2025-10-27**|**Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model**|Weizheng Wang et.al.|[2510.23509](https://arxiv.org/abs/2510.23509)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.23262": "|**2025-10-27**|**Moderating Role of Presence in EEG Responses to Visuo-haptic Prediction Error in Virtual Reality**|Lukas Gehrke et.al.|[2510.23262](https://arxiv.org/abs/2510.23262)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23258": "|**2025-10-27**|**Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation**|Riko Yokozawa et.al.|[2510.23258](https://arxiv.org/abs/2510.23258)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.23234": "|**2025-10-27**|**Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation**|Klaus Zauner et.al.|[2510.23234](https://arxiv.org/abs/2510.23234)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23227": "|**2025-10-27**|**Workspace Registration and Collision Detection for Industrial Robotics Applications**|Klaus Zauner et.al.|[2510.23227](https://arxiv.org/abs/2510.23227)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23119": "|**2025-10-27**|**OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback**|Yi-Lin Wei et.al.|[2510.23119](https://arxiv.org/abs/2510.23119)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22738": "|**2025-10-26**|**SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping**|Wentao Guo et.al.|[2510.22738](https://arxiv.org/abs/2510.22738)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22732": "|**2025-10-26**|**ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation**|Jiali Cheng et.al.|[2510.22732](https://arxiv.org/abs/2510.22732)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22420": "|**2025-10-25**|**A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems**|Mohammad Ali Labbaf Khaniki et.al.|[2510.22420](https://arxiv.org/abs/2510.22420)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22304": "|**2025-10-28**|**ODesign: A World Model for Biomolecular Interaction Design**|Odin Zhang et.al.|[2510.22304](https://arxiv.org/abs/2510.22304)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.22208": "|**2025-10-25**|**Simplifying Knowledge Transfer in Pretrained Models**|Siddharth Jain et.al.|[2510.22208](https://arxiv.org/abs/2510.22208)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22200": "|**2025-10-28**|**LongCat-Video Technical Report**|Meituan LongCat Team et.al.|[2510.22200](https://arxiv.org/abs/2510.22200)|**[link](https://huggingface.co/spaces/multimodalart/LongCat-Video)**|\n", "2510.22199": "|**2025-10-25**|**MOGRAS: Human Motion with Grasping in 3D Scenes**|Kunal Bhosikar et.al.|[2510.22199](https://arxiv.org/abs/2510.22199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22113": "|**2025-10-25**|**RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation**|Zitiantao Lin et.al.|[2510.22113](https://arxiv.org/abs/2510.22113)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21991": "|**2025-10-24**|**Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising**|Mateo Clemente et.al.|[2510.21991](https://arxiv.org/abs/2510.21991)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21867": "|**2025-10-23**|**Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs**|Haicheng Liao et.al.|[2510.21867](https://arxiv.org/abs/2510.21867)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21840": "|**2025-10-22**|**Improving the Physics of Video Generation with VJEPA-2 Reward Signal**|Jianhao Yuan et.al.|[2510.21840](https://arxiv.org/abs/2510.21840)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.24690": "|**2025-10-28**|**Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning**|Shengjie Liu et.al.|[2510.24690](https://arxiv.org/abs/2510.24690)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24654": "|**2025-10-28**|**Evolving Diagnostic Agents in a Virtual Clinical Environment**|Pengcheng Qiu et.al.|[2510.24654](https://arxiv.org/abs/2510.24654)|**[link](https://huggingface.co/models/Henrychur/DiagAgent-8B)**|\n", "2510.24546": "|**2025-10-28**|**Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks**|Lingyi Wang et.al.|[2510.24546](https://arxiv.org/abs/2510.24546)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.24459": "|**2025-10-28**|**Affordance Representation and Recognition for Autonomous Agents**|Habtom Kahsay Gidey et.al.|[2510.24459](https://arxiv.org/abs/2510.24459)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.24261": "|**2025-10-28**|**DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation**|Jingyi Tian et.al.|[2510.24261](https://arxiv.org/abs/2510.24261)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24257": "|**2025-10-28**|**Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors**|Ziqi Ma et.al.|[2510.24257](https://arxiv.org/abs/2510.24257)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.24194": "|**2025-10-28**|**Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames**|Ev Zisselman et.al.|[2510.24194](https://arxiv.org/abs/2510.24194)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Wenbin Ding et.al.|[2510.24109](https://arxiv.org/abs/2510.24109)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.24095": "|**2025-10-28**|**Learning Parameterized Skills from Demonstrations**|Vedant Gupta et.al.|[2510.24095](https://arxiv.org/abs/2510.24095)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24055": "|**2025-10-28**|**Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation**|Xiucheng Zhang et.al.|[2510.24055](https://arxiv.org/abs/2510.24055)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24030": "|**2025-10-28**|**Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts**|Ahmet Akkaya Melih et.al.|[2510.24030](https://arxiv.org/abs/2510.24030)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.23963": "|**2025-10-28**|**Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping**|Hiroki Ishikawa et.al.|[2510.23963](https://arxiv.org/abs/2510.23963)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23763": "|**2025-11-01**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Siyin Wang et.al.|[2510.23763](https://arxiv.org/abs/2510.23763)|**[link](https://huggingface.co/models/fnlp/RoboOmni)**|\n", "2510.25754": "|**2025-10-29**|**GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions**|Bohan Wu et.al.|[2510.25754](https://arxiv.org/abs/2510.25754)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25529": "|**2025-10-29**|**Off-policy Reinforcement Learning with Model-based Exploration Augmentation**|Likun Wang et.al.|[2510.25529](https://arxiv.org/abs/2510.25529)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.25405": "|**2025-10-29**|**Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning**|Kei Ikemura et.al.|[2510.25405](https://arxiv.org/abs/2510.25405)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Wang zhi et.al.|[2510.25268](https://arxiv.org/abs/2510.25268)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25255": "|**2025-10-29**|**Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths**|Klaus Zauner et.al.|[2510.25255](https://arxiv.org/abs/2510.25255)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25233": "|**2025-10-29**|**Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery**|Jee Won Lee et.al.|[2510.25233](https://arxiv.org/abs/2510.25233)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25129": "|**2025-10-29**|**AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians**|Xiyu Zhang et.al.|[2510.25129](https://arxiv.org/abs/2510.25129)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jiahong Chen et.al.|[2510.25122](https://arxiv.org/abs/2510.25122)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.24856": "|**2025-10-28**|**Do Large Language Models Grasp The Grammar? Evidence from Grammar-Book-Guided Probing in Luxembourgish**|Lujun Li et.al.|[2510.24856](https://arxiv.org/abs/2510.24856)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24785": "|**2025-10-27**|**Semantic Communications with World Models**|Peiwen Jiang et.al.|[2510.24785](https://arxiv.org/abs/2510.24785)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.26796": "|**2025-10-30**|**SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting**|Dongyue Lu et.al.|[2510.26796](https://arxiv.org/abs/2510.26796)|**[link](https://github.com/ALEEEHU/World-Simulator)**|\n", "2510.26782": "|**2025-10-30**|**Clone Deterministic 3D Worlds with Geometrically-Regularized World Models**|Zaishuo Xia et.al.|[2510.26782](https://arxiv.org/abs/2510.26782)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.26742": "|**2025-10-30**|**Running VLAs at Real-time Speed**|Yunchao Ma et.al.|[2510.26742](https://arxiv.org/abs/2510.26742)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.26670": "|**2025-10-30**|**Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation**|Qianyou Zhao et.al.|[2510.26670](https://arxiv.org/abs/2510.26670)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26654": "|**2025-10-30**|**Bridge and Bound: A Logic-Based Framework for Abstracting (Preliminary Report)**|Andrzej Szalas et.al.|[2510.26654](https://arxiv.org/abs/2510.26654)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26583": "|**2025-10-30**|**Emu3.5: Native Multimodal Models are World Learners**|Yufeng Cui et.al.|[2510.26583](https://arxiv.org/abs/2510.26583)|**[link](https://huggingface.co/models/BAAI/Emu3.5)**|\n", "2510.26551": "|**2025-10-30**|**Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics**|Prathamesh Kothavale et.al.|[2510.26551](https://arxiv.org/abs/2510.26551)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26433": "|**2025-10-30**|**Co-Evolving Latent Action World Models**|Yucen Wang et.al.|[2510.26433](https://arxiv.org/abs/2510.26433)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.26406": "|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Guanxing Lu et.al.|[2510.26406](https://arxiv.org/abs/2510.26406)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.26363": "|**2025-10-30**|**Towards Reinforcement Learning Based Log Loading Automation**|Ilya Kurinov et.al.|[2510.26363](https://arxiv.org/abs/2510.26363)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26241": "|**2025-10-30**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shiho Matta et.al.|[2510.26241](https://arxiv.org/abs/2510.26241)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25927": "|**2025-10-29**|**Constraints on the resolution of spacetime singularities**|Arvin Shahbazi-Moghaddam et.al.|[2510.25927](https://arxiv.org/abs/2510.25927)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25848": "|**2025-10-29**|**Spiral Structure Diversity in Milky Way Analogs from TNG50: The Role of Gas and Disk Dynamics**|Soumavo Ghosh et.al.|[2510.25848](https://arxiv.org/abs/2510.25848)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27666": "|**2025-10-31**|**Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping**|Dong Heon Han et.al.|[2510.27666](https://arxiv.org/abs/2510.27666)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|John Won et.al.|[2510.27607](https://arxiv.org/abs/2510.27607)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.27558": "|**2025-10-31**|**Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs**|Sushil Samuel Dinesh et.al.|[2510.27558](https://arxiv.org/abs/2510.27558)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27420": "|**2025-10-31**|**Towards a Multi-Embodied Grasping Agent**|Roman Freiberg et.al.|[2510.27420](https://arxiv.org/abs/2510.27420)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27184": "|**2025-10-31**|**Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets**|Hoang Hiep Ly et.al.|[2510.27184](https://arxiv.org/abs/2510.27184)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27114": "|**2025-10-31**|**Learning Generalizable Visuomotor Policy through Dynamics-Alignment**|Dohyeok Lee et.al.|[2510.27114](https://arxiv.org/abs/2510.27114)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27048": "|**2025-10-30**|**SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation**|Eric T. Chang et.al.|[2510.27048](https://arxiv.org/abs/2510.27048)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27002": "|**2025-10-30**|**Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase**|Mihir Mahajan et.al.|[2510.27002](https://arxiv.org/abs/2510.27002)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.02824": "|**2025-11-05**|**Kosmos: An AI Scientist for Autonomous Discovery**|Ludovico Mitchener et.al.|[2511.02824](https://arxiv.org/abs/2511.02824)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.02748": "|**2025-11-04**|**Agentic World Modeling for 6G: Near-Real-Time Generative State-Space Reasoning**|Farhad Rezazadeh et.al.|[2511.02748](https://arxiv.org/abs/2511.02748)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.02347": "|**2025-11-04**|**LTD-Bench: Evaluating Large Language Models by Letting Them Draw**|Liuhao Lin et.al.|[2511.02347](https://arxiv.org/abs/2511.02347)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.02239": "|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Youngjin Hong et.al.|[2511.02239](https://arxiv.org/abs/2511.02239)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.02225": "|**2025-11-04**|**Learning Interactive World Model for Object-Centric Reinforcement Learning**|Fan Feng et.al.|[2511.02225](https://arxiv.org/abs/2511.02225)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.02091": "|**2025-11-03**|**Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling**|Lancelot Da Costa et.al.|[2511.02091](https://arxiv.org/abs/2511.02091)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01999": "|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Sangyun Park et.al.|[2511.01999](https://arxiv.org/abs/2511.01999)|**[link](https://huggingface.co/datasets/jink-ucla/TRACE)**|\n", "2511.01775": "|**2025-11-03**|**How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment**|Zhen Chen et.al.|[2511.01775](https://arxiv.org/abs/2511.01775)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.01774": "|**2025-11-03**|**MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll**|Alexander Schperberg et.al.|[2511.01774](https://arxiv.org/abs/2511.01774)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01770": "|**2025-11-03**|**Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping**|Liudi Yang et.al.|[2511.01770](https://arxiv.org/abs/2511.01770)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01520": "|**2025-11-03**|**Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals**|Shipeng Lyu et.al.|[2511.01520](https://arxiv.org/abs/2511.01520)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01517": "|**2025-11-03**|**NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation**|Serkan Ozturk et.al.|[2511.01517](https://arxiv.org/abs/2511.01517)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01501": "|**2025-11-03**|**SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation**|Yufeng Jin et.al.|[2511.01501](https://arxiv.org/abs/2511.01501)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01331": "|**2025-11-03**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Hongyin Zhang et.al.|[2511.01331](https://arxiv.org/abs/2511.01331)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01310": "|**2025-11-03**|**From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models**|Sureyya Akin et.al.|[2511.01310](https://arxiv.org/abs/2511.01310)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.01281": "|**2025-11-03**|**Particle Filter Made Simple: A Step-by-Step Beginner-friendly Guide**|Sahil Rajesh Dhayalkar et.al.|[2511.01281](https://arxiv.org/abs/2511.01281)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01276": "|**2025-11-03**|**Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation**|Yiyao Ma et.al.|[2511.01276](https://arxiv.org/abs/2511.01276)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01256": "|**2025-11-03**|**Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control**|Yasamin Foroutani et.al.|[2511.01256](https://arxiv.org/abs/2511.01256)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01249": "|**2025-11-03**|**KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records**|Kun-Wei Lin et.al.|[2511.01249](https://arxiv.org/abs/2511.01249)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.01177": "|**2025-11-03**|**Scaling Cross-Embodiment World Models for Dexterous Manipulation**|Zihao He et.al.|[2511.01177](https://arxiv.org/abs/2511.01177)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.01093": "|**2025-11-02**|**Continual Learning, Not Training: Online Adaptation For Agents**|Aman Jaglan et.al.|[2511.01093](https://arxiv.org/abs/2511.01093)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.00940": "|**2025-11-02**|**URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model**|Zhe Li et.al.|[2511.00940](https://arxiv.org/abs/2511.00940)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.00693": "|**2025-11-01**|**Object-Centric Analysis of XES Event Logs: Integrating OCED Modeling with SPARQL Queries**|Saba Latif et.al.|[2511.00693](https://arxiv.org/abs/2511.00693)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00555": "|**2025-11-01**|**Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy**|Dianye Huang et.al.|[2511.00555](https://arxiv.org/abs/2511.00555)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00549": "|**2025-11-01**|**Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations**|Qiang Li et.al.|[2511.00549](https://arxiv.org/abs/2511.00549)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.00516": "|**2025-11-01**|**Adaptive and Multi-object Grasping via Deformable Origami Modules**|Peiyi Wang et.al.|[2511.00516](https://arxiv.org/abs/2511.00516)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00450": "|**2025-11-01**|**SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin**|Vahid Etemadi et.al.|[2511.00450](https://arxiv.org/abs/2511.00450)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.00423": "|**2025-11-01**|**Bootstrap Off-policy with World Model**|Guojian Zhan et.al.|[2511.00423](https://arxiv.org/abs/2511.00423)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.01914": "|**2025-11-01**|**iFlyBot-VLA Technical Report**|Yuan Zhang et.al.|[2511.01914](https://arxiv.org/abs/2511.01914)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.02097": "|**2025-10-31**|**A Step Toward World Models: A Survey on Robotic Manipulation**|Peng-Fei Zhang et.al.|[2511.02097](https://arxiv.org/abs/2511.02097)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.03691": "|**2025-11-05**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al.|[2511.03691](https://arxiv.org/abs/2511.03691)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03550": "|**2025-11-05**|**Indicating Robot Vision Capabilities with Augmented Reality**|Hong Wang et.al.|[2511.03550](https://arxiv.org/abs/2511.03550)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.03481": "|**2025-11-09**|**Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control**|Jianbo Yuan et.al.|[2511.03481](https://arxiv.org/abs/2511.03481)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03471": "|**2025-11-05**|**Towards Scalable Web Accessibility Audit with MLLMs as Copilots**|Ming Gu et.al.|[2511.03471](https://arxiv.org/abs/2511.03471)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03400": "|**2025-11-05**|**GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement**|Minquan Gao et.al.|[2511.03400](https://arxiv.org/abs/2511.03400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03098": "|**2025-11-05**|**ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly**|Miftahur Rahman et.al.|[2511.03098](https://arxiv.org/abs/2511.03098)|**[link](https://github.com/isLinXu/paper-list)**|\n", "2511.03078": "|**2025-11-04**|**3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors**|Rohan Kota et.al.|[2511.03078](https://arxiv.org/abs/2511.03078)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03077": "|**2025-11-04**|**WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models**|R. Khorrambakht et.al.|[2511.03077](https://arxiv.org/abs/2511.03077)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.04670": "|**2025-11-06**|**Cambrian-S: Towards Spatial Supersensing in Video**|Shusheng Yang et.al.|[2511.04670](https://arxiv.org/abs/2511.04670)|**[link](https://huggingface.co/models/nyu-visionx/Cambrian-S-7B)**|\n", "2511.04665": "|**2025-11-10**|**Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions**|Kaifeng Zhang et.al.|[2511.04665](https://arxiv.org/abs/2511.04665)|**[link](https://github.com/Jianghanxiao/PhysTwin)**|\n", "2511.04646": "|**2025-11-06**|**DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration**|Narjes Nourzad et.al.|[2511.04646](https://arxiv.org/abs/2511.04646)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.04541": "|**2025-11-06**|**LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems**|Baptiste Bonin et.al.|[2511.04541](https://arxiv.org/abs/2511.04541)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04381": "|**2025-11-06**|**ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation**|Dexin wang et.al.|[2511.04381](https://arxiv.org/abs/2511.04381)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.04357": "|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Ma\u00eblic Neau et.al.|[2511.04357](https://arxiv.org/abs/2511.04357)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.04199": "|**2025-11-06**|**GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments**|Shenglin Wang et.al.|[2511.04199](https://arxiv.org/abs/2511.04199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04009": "|**2025-11-06**|**Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration**|Chenzui Li et.al.|[2511.04009](https://arxiv.org/abs/2511.04009)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03782": "|**2025-11-05**|**Expert Evaluation of LLM World Models: A High-$T_c$ Superconductivity Case Study**|Haoyu Guo et.al.|[2511.03782](https://arxiv.org/abs/2511.03782)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.01210": "|**2025-11-06**|**OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation**|Heyu Guo et.al.|[2511.01210](https://arxiv.org/abs/2511.01210)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05403": "|**2025-11-07**|**PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior**|Zicong Fan et.al.|[2511.05403](https://arxiv.org/abs/2511.05403)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05397": "|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samarth Chopra et.al.|[2511.05397](https://arxiv.org/abs/2511.05397)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05379": "|**2025-11-07**|**ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality**|Eric Godden et.al.|[2511.05379](https://arxiv.org/abs/2511.05379)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05307": "|**2025-11-07**|**Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators**|Akua K. Dickson et.al.|[2511.05307](https://arxiv.org/abs/2511.05307)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05256": "|**2025-11-07**|**Entanglement, defects, and $T\\bar{T}$ on a black hole background**|Ankur Dey et.al.|[2511.05256](https://arxiv.org/abs/2511.05256)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05234": "|**2025-11-07**|**Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning**|Philipp Dahlinger et.al.|[2511.05234](https://arxiv.org/abs/2511.05234)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.05199": "|**2025-11-07**|**Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation**|Yichen Zhu et.al.|[2511.05199](https://arxiv.org/abs/2511.05199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05143": "|**2025-11-07**|**Synthesizing speech with selected perceptual voice qualities - A case study with creaky voice**|Frederik Rautenberg et.al.|[2511.05143](https://arxiv.org/abs/2511.05143)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2511.05052": "|**2025-11-07**|**TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments**|Zihao Li et.al.|[2511.05052](https://arxiv.org/abs/2511.05052)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05007": "|**2025-11-07**|**MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery**|Baiye Cheng et.al.|[2511.05007](https://arxiv.org/abs/2511.05007)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04847": "|**2025-11-06**|**Grounded Test-Time Adaptation for LLM Agents**|Arthur Chen et.al.|[2511.04847](https://arxiv.org/abs/2511.04847)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.04769": "|**2025-11-06**|**ReGen: Generative Robot Simulation via Inverse Design**|Phat Nguyen et.al.|[2511.04769](https://arxiv.org/abs/2511.04769)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2511.07418": "|**2025-11-11**|**Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields**|Zhao-Heng Yin et.al.|[2511.07418](https://arxiv.org/abs/2511.07418)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.07416": "|**2025-11-10**|**Robot Learning from a Physical World Model**|Jiageng Mao et.al.|[2511.07416](https://arxiv.org/abs/2511.07416)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.07403": "|**2025-11-10**|**SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards**|Hunar Batra et.al.|[2511.07403](https://arxiv.org/abs/2511.07403)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2511.07081": "|**2025-11-10**|**HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects**|Guanghu Xie et.al.|[2511.07081](https://arxiv.org/abs/2511.07081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06946": "|**2025-11-10**|**Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning**|Daniel De Dios Allegue et.al.|[2511.06946](https://arxiv.org/abs/2511.06946)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2511.06754": "|**2025-11-10**|**SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation**|Taisei Hanyu et.al.|[2511.06754](https://arxiv.org/abs/2511.06754)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06745": "|**2025-11-10**|**Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning**|Lan Thi Ha Nguyen et.al.|[2511.06745](https://arxiv.org/abs/2511.06745)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06515": "|**2025-11-09**|**Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control**|Cormac O'Neill et.al.|[2511.06515](https://arxiv.org/abs/2511.06515)|**[link](https://github.com/jterrone1/Koopman-for-Rimless-Wheel)**|\n", "2511.06434": "|**2025-11-09**|**Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator**|Wenkang Hu et.al.|[2511.06434](https://arxiv.org/abs/2511.06434)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2511.06311": "|**2025-11-09**|**External Photoreflective Tactile Sensing Based on Surface Deformation Measurement**|Seiichi Yamamoto et.al.|[2511.06311](https://arxiv.org/abs/2511.06311)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06267": "|**2025-11-09**|**Robust Differentiable Collision Detection for General Objects**|Jiayi Chen et.al.|[2511.06267](https://arxiv.org/abs/2511.06267)|**[link](https://github.com/JYChen18/DiffCollision)**|\n", "2511.06252": "|**2025-11-09**|**MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios**|Xuantang Xiong et.al.|[2511.06252](https://arxiv.org/abs/2511.06252)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.06202": "|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Shahram Najam Syed et.al.|[2511.06202](https://arxiv.org/abs/2511.06202)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.06136": "|**2025-11-08**|**When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks**|Stefano Ferraro et.al.|[2511.06136](https://arxiv.org/abs/2511.06136)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05996": "|**2025-11-08**|**Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds**|Xianhui Meng et.al.|[2511.05996](https://arxiv.org/abs/2511.05996)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05972": "|**2025-11-08**|**DWM-RO: Decentralized World Models with Reasoning Offloading for SWIPT-enabled Satellite-Terrestrial HetNets**|Guangyuan Liu et.al.|[2511.05972](https://arxiv.org/abs/2511.05972)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05963": "|**2025-11-08**|**Next-Latent Prediction Transformers Learn Compact World Models**|Jayden Teoh et.al.|[2511.05963](https://arxiv.org/abs/2511.05963)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.05816": "|**2025-11-08**|**3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots**|Taku Okawara et.al.|[2511.05816](https://arxiv.org/abs/2511.05816)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05809": "|**2025-11-08**|**Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis**|Yu Chen et.al.|[2511.05809](https://arxiv.org/abs/2511.05809)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05791": "|**2025-11-08**|**VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models**|Manav Kulshrestha et.al.|[2511.05791](https://arxiv.org/abs/2511.05791)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05680": "|**2025-11-07**|**VLM-driven Skill Selection for Robotic Assembly Tasks**|Jeong-Jung Kim et.al.|[2511.05680](https://arxiv.org/abs/2511.05680)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "1709.02924": "|**2019-02-11**|**Robust Object Manipulation for Tactile-based Blind Grasping**|Wenceslao Shaw-Cortez et.al.|[1709.02924](https://arxiv.org/abs/1709.02924)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2501.02149": "|**2025-01-07**|**Attribute-Based Robotic Grasping with Data-Efficient Adaptation**|Yang Yang et.al.|[2501.02149](https://arxiv.org/abs/2501.02149)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2309.09556": "|**2023-11-06**|**Affordance-Driven Next-Best-View Planning for Robotic Grasping**|Xuechao Zhang et.al.|[2309.09556](https://arxiv.org/abs/2309.09556)|**[link](https://github.com/hq-King/Awesome-Affordance-Learning)**|\n", "2101.02842": "|**2021-01-11**|**Grasp and Motion Planning for Dexterous Manipulation for the Real Robot Challenge**|Takuma Yoneda et.al.|[2101.02842](https://arxiv.org/abs/2101.02842)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2403.01611": "|**2024-03-05**|**The Grasp Loop Signature: A Topological Representation for Manipulation Planning with Ropes and Cables**|Peter Mitrano et.al.|[2403.01611](https://arxiv.org/abs/2403.01611)|**[link](https://github.com/ryanbgriffiths/ICRA2024PaperList)**|\n", "1904.02530": "|**2019-04-05**|**Interactive Open-Ended Object, Affordance and Grasp Learning for Robotic Manipulation**|S. Hamidreza Kasaei et.al.|[1904.02530](https://arxiv.org/abs/1904.02530)|**[link](https://github.com/PaoPaoRobot/ICRA2019-paper-list)**|\n", "2404.04643": "|**2024-07-16**|**Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation**|Gaurav Singh et.al.|[2404.04643](https://arxiv.org/abs/2404.04643)|**[link](https://github.com/constrained-grasp-diffusion/constrained-grasp-diffusion)**|\n", "2412.06983": "|**2025-09-15**|**Collision-Inclusive Manipulation Planning for Occluded Object Grasping via Compliant Robot Motions**|Kejia Ren et.al.|[2412.06983](https://arxiv.org/abs/2412.06983)|**[link](https://github.com/wadeKeith/Awesome-Embodied-AI)**|\n", "1809.03210": "|**2018-09-11**|**Intelligent flat-and-textureless object manipulation in Service Robots**|Abel Pacheco-Ortega et.al.|[1809.03210](https://arxiv.org/abs/1809.03210)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2001.05443": "|**2020-01-16**|**Robotic Grasp Manipulation Using Evolutionary Computing and Deep Reinforcement Learning**|Priya Shukla et.al.|[2001.05443](https://arxiv.org/abs/2001.05443)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2502.03072": "|**2025-02-06**|**RoboGrasp: A Universal Grasping Policy for Robust Robotic Control**|Yiqi Huang et.al.|[2502.03072](https://arxiv.org/abs/2502.03072)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2503.05020": "|**2025-07-04**|**GRIP: A General Robotic Incremental Potential Contact Simulation Dataset for Unified Deformable-Rigid Coupled Grasping**|Siyu Ma et.al.|[2503.05020](https://arxiv.org/abs/2503.05020)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2108.01483": "|**2021-12-10**|**Research Challenges and Progress in Robotic Grasping and Manipulation Competitions**|Yu Sun et.al.|[2108.01483](https://arxiv.org/abs/2108.01483)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2302.07824": "|**2023-02-16**|**Instance-wise Grasp Synthesis for Robotic Grasping**|Yucheng Xu et.al.|[2302.07824](https://arxiv.org/abs/2302.07824)|**[link](https://github.com/ryanbgriffiths/ICRA2023PaperList)**|\n", "2104.02271": "|**2021-04-07**|**Attribute-Based Robotic Grasping with One-Grasp Adaptation**|Yang Yang et.al.|[2104.02271](https://arxiv.org/abs/2104.02271)|**[link](https://github.com/dectrfov/ICRA2021PaperList)**|\n", "2309.09017": "|**2024-11-01**|**Triple Regression for Camera Agnostic Sim2Real Robot Grasping and Manipulation Tasks**|Yuanhong Zeng et.al.|[2309.09017](https://arxiv.org/abs/2309.09017)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1810.03043": "|**2018-10-09**|**Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning**|Frederik Ebert et.al.|[1810.03043](https://arxiv.org/abs/1810.03043)|**[link](https://github.com/jason718/awesome-self-supervised-learning)**|\n", "2410.01702": "|**2025-03-17**|**$\\mathcal{D(R,O)}$ Grasp: A Unified Representation of Robot and Object Interaction for Cross-Embodiment Dexterous Grasping**|Zhenyu Wei et.al.|[2410.01702](https://arxiv.org/abs/2410.01702)|**[link](https://github.com/zhenyuwei2003/DRO-Grasp)**|\n", "2309.09818": "|**2023-09-19**|**Grasp-Anything: Large-scale Grasp Dataset from Foundation Models**|An Dinh Vuong et.al.|[2309.09818](https://arxiv.org/abs/2309.09818)|**[link](https://github.com/DirtyHarryLYL/LLM-in-Vision)**|\n", "1707.08150": "|**2017-07-27**|**Safe Robotic Grasping: Minimum Impact-Force Grasp Selection**|Nikos Mavrakis et.al.|[1707.08150](https://arxiv.org/abs/1707.08150)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2010.06544": "|**2021-03-02**|**Real-Time Deep Learning Approach to Visual Servo Control and Grasp Detection for Autonomous Robotic Manipulation**|Eduardo Godinho Ribeiro et.al.|[2010.06544](https://arxiv.org/abs/2010.06544)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1905.12920": "|**2019-09-17**|**Bayesian Grasp: Robotic visual stable grasp based on prior tactile knowledge**|Teng Xue et.al.|[1905.12920](https://arxiv.org/abs/1905.12920)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1811.10757": "|**2018-11-28**|**Grasp Constraint Satisfaction for Object Manipulation using Robotic Hands**|Wenceslao Shaw Cortez et.al.|[1811.10757](https://arxiv.org/abs/1811.10757)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1911.04397": "|**2019-11-26**|**Estimation and Exploitation of Objects' Inertial Parameters in Robotic Grasping and Manipulation: A Survey**|Nikos Mavrakis et.al.|[1911.04397](https://arxiv.org/abs/1911.04397)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2404.14968": "|**2024-04-24**|**CenterArt: Joint Shape Reconstruction and 6-DoF Grasp Estimation of Articulated Objects**|Sassan Mokhtar et.al.|[2404.14968](https://arxiv.org/abs/2404.14968)|**[link](https://github.com/dougefla/Awesome-Articulated-Object-Understanding)**|\n", "2411.05212": "|**2024-11-11**|**RT-Grasp: Reasoning Tuning Robotic Grasping via Multi-modal Large Language Model**|Jinxuan Xu et.al.|[2411.05212](https://arxiv.org/abs/2411.05212)|**[link](https://github.com/ryanbgriffiths/IROS2024PaperList)**|\n", "1907.11035": "|**2019-07-26**|**Robot Learning of Shifting Objects for Grasping in Cluttered Environments**|Lars Berscheid et.al.|[1907.11035](https://arxiv.org/abs/1907.11035)|**[link](https://github.com/GeorgeDu/vision-based-robotic-grasping)**|\n", "1809.07081": "|**2019-03-05**|**A Multi-task Convolutional Neural Network for Autonomous Robotic Grasping in Object Stacking Scenes**|Hanbo Zhang et.al.|[1809.07081](https://arxiv.org/abs/1809.07081)|**[link](https://github.com/GeorgeDu/vision-based-robotic-grasping)**|\n", "2410.22893": "|**2024-10-31**|**Human-inspired Grasping Strategies of Fresh Fruits and Vegetables Applied to Robotic Manipulation**|Romeo Orsolino et.al.|[2410.22893](https://arxiv.org/abs/2410.22893)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1607.03366": "|**2016-07-13**|**Human-Planned Robotic Grasp Ranges: Capture and Validation**|Brendon John et.al.|[1607.03366](https://arxiv.org/abs/1607.03366)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2504.19683": "|**2025-10-15**|**GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial Task Learning**|Juyi Sheng et.al.|[2504.19683](https://arxiv.org/abs/2504.19683)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1911.01557": "|**2019-11-28**|**Benchmarking Simulated Robotic Manipulation through a Real World Dataset**|Jack Collins et.al.|[1911.01557](https://arxiv.org/abs/1911.01557)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2104.11446": "|**2021-08-27**|**OCRTOC: A Cloud-Based Competition and Benchmark for Robotic Grasping and Manipulation**|Ziyuan Liu et.al.|[2104.11446](https://arxiv.org/abs/2104.11446)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2210.03173": "|**2022-10-10**|**CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration**|Abhinav K. Keshari et.al.|[2210.03173](https://arxiv.org/abs/2210.03173)|**[link](https://github.com/rhett-chen/Robotic-grasping-papers)**|\n", "2306.07392": "|**2024-05-30**|**Learning Any-View 6DoF Robotic Grasping in Cluttered Scenes via Neural Surface Rendering**|Snehal Jauhri et.al.|[2306.07392](https://arxiv.org/abs/2306.07392)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2208.10580": "|**2022-08-24**|**Robotic Perception in Agri-food Manipulation: A Review**|Jack Foster et.al.|[2208.10580](https://arxiv.org/abs/2208.10580)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2405.16692": "|**2024-05-28**|**Planning Robot Placement for Object Grasping**|Manish Saini et.al.|[2405.16692](https://arxiv.org/abs/2405.16692)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1911.10280": "|**2021-01-14**|**Manipulation Trajectory Optimization with Online Grasp Synthesis and Selection**|Lirui Wang et.al.|[1911.10280](https://arxiv.org/abs/1911.10280)|**[link](https://github.com/GeorgeDu/vision-based-robotic-grasping)**|\n", "2211.02647": "|**2023-12-29**|**Neural Grasp Distance Fields for Robot Manipulation**|Thomas Weng et.al.|[2211.02647](https://arxiv.org/abs/2211.02647)|**[link](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)**|\n", "2206.15159": "|**2022-07-01**|**EfficientGrasp: A Unified Data-Efficient Learning to Grasp Method for Multi-fingered Robot Hands**|Kelin Li et.al.|[2206.15159](https://arxiv.org/abs/2206.15159)|**[link](https://github.com/rhett-chen/Robotic-grasping-papers)**|\n", "2410.24035": "|**2024-11-01**|**State- and context-dependent robotic manipulation and grasping via uncertainty-aware imitation learning**|Tim R. Winter et.al.|[2410.24035](https://arxiv.org/abs/2410.24035)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2305.13591": "|**2023-05-24**|**A Single Multi-Task Deep Neural Network with a Multi-Scale Feature Aggregation Mechanism for Manipulation Relationship Reasoning in Robotic Grasping**|Mingshuai Dong et.al.|[2305.13591](https://arxiv.org/abs/2305.13591)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2407.03531": "|**2024-11-11**|**OrbitGrasp: $SE(3)$-Equivariant Grasp Learning**|Boce Hu et.al.|[2407.03531](https://arxiv.org/abs/2407.03531)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2005.09240": "|**2020-05-20**|**Robust Robot-assisted Tele-grasping Through Intent-Uncertainty-Aware Planning**|Michael Bowman et.al.|[2005.09240](https://arxiv.org/abs/2005.09240)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2505.01399": "|**2025-10-03**|**Physics-Constrained Robot Grasp Planning for Dynamic Tool Use**|Noah Trupin et.al.|[2505.01399](https://arxiv.org/abs/2505.01399)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10627": "|**2025-11-13**|**Querying Labeled Time Series Data with Scenario Programs**|Edward Kim et.al.|[2511.10627](https://arxiv.org/abs/2511.10627)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel et.al.|[2511.10615](https://arxiv.org/abs/2511.10615)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10590": "|**2025-11-13**|**Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs**|Miles Wang-Henderson et.al.|[2511.10590](https://arxiv.org/abs/2511.10590)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10572": "|**2025-11-13**|**Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback**|Mohammadsina Almasi et.al.|[2511.10572](https://arxiv.org/abs/2511.10572)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10571": "|**2025-11-13**|**Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations**|Reginald Zhiyan Chen et.al.|[2511.10571](https://arxiv.org/abs/2511.10571)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10539": "|**2025-11-13**|**Dynamic Avatar-Scene Rendering from Human-centric Context**|Wenqing Wang et.al.|[2511.10539](https://arxiv.org/abs/2511.10539)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Wei Li et.al.|[2511.10518](https://arxiv.org/abs/2511.10518)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10516": "|**2025-11-13**|**How Worrying Are Privacy Attacks Against Machine Learning?**|Josep Domingo-Ferrer et.al.|[2511.10516](https://arxiv.org/abs/2511.10516)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10515": "|**2025-11-13**|**LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025**|Dong-Shan Jian et.al.|[2511.10515](https://arxiv.org/abs/2511.10515)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10502": "|**2025-11-13**|**On the Detectability of Active Gradient Inversion Attacks in Federated Learning**|Vincenzo Carletti et.al.|[2511.10502](https://arxiv.org/abs/2511.10502)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10501": "|**2025-11-13**|**Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling**|Georgios Chalkiadakis et.al.|[2511.10501](https://arxiv.org/abs/2511.10501)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10459": "|**2025-11-13**|**LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning**|Zihan Gao et.al.|[2511.10459](https://arxiv.org/abs/2511.10459)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10434": "|**2025-11-13**|**Unlocking Dynamic Inter-Client Spatial Dependencies: A Federated Spatio-Temporal Graph Learning Method for Traffic Flow Forecasting**|Feng Wang et.al.|[2511.10434](https://arxiv.org/abs/2511.10434)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10411": "|**2025-11-13**|**LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction**|Benjamin Stoler et.al.|[2511.10411](https://arxiv.org/abs/2511.10411)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10403": "|**2025-11-13**|**nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation**|Mingxing Peng et.al.|[2511.10403](https://arxiv.org/abs/2511.10403)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10400": "|**2025-11-13**|**Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance**|Lifan Zheng et.al.|[2511.10400](https://arxiv.org/abs/2511.10400)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10394": "|**2025-11-13**|**LLM-YOLOMS: Large Language Model-based Semantic Interpretation and Fault Diagnosis for Wind Turbine Components**|Yaru Li et.al.|[2511.10394](https://arxiv.org/abs/2511.10394)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10390": "|**2025-11-13**|**MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns**|Jiarui Zhang et.al.|[2511.10390](https://arxiv.org/abs/2511.10390)|**[link](https://github.com/Yuliang-Liu/MonkeyOCR)**|\n", "2511.10387": "|**2025-11-13**|**Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery**|Prince Mensah et.al.|[2511.10387](https://arxiv.org/abs/2511.10387)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10385": "|**2025-11-13**|**SAMIRO: Spatial Attention Mutual Information Regularization with a Pre-trained Model as Oracle for Lane Detection**|Hyunjong Lee et.al.|[2511.10385](https://arxiv.org/abs/2511.10385)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10383": "|**2025-11-13**|**Operator Models for Continuous-Time Offline Reinforcement Learning**|Nicolas Hoischen et.al.|[2511.10383](https://arxiv.org/abs/2511.10383)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10370": "|**2025-11-13**|**SHRUG-FM: Reliability-Aware Foundation Models for Earth Observation**|Kai-Hendrik Cohrs et.al.|[2511.10370](https://arxiv.org/abs/2511.10370)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10325": "|**2025-11-13**|**TMDC: A Two-Stage Modality Denoising and Complementation Framework for Multimodal Sentiment Analysis with Missing and Noisy Modalities**|Yan Zhuang et.al.|[2511.10325](https://arxiv.org/abs/2511.10325)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10296": "|**2025-11-13**|**Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions**|Florian Ebmeier et.al.|[2511.10296](https://arxiv.org/abs/2511.10296)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10292": "|**2025-11-13**|**Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models**|Zhengtao Zou et.al.|[2511.10292](https://arxiv.org/abs/2511.10292)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10291": "|**2025-11-13**|**Causal Model-Based Reinforcement Learning for Sample-Efficient IoT Channel Access**|Aswin Arun et.al.|[2511.10291](https://arxiv.org/abs/2511.10291)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10281": "|**2025-11-13**|**FactGuard: Event-Centric and Commonsense-Guided Fake News Detection**|Jing He et.al.|[2511.10281](https://arxiv.org/abs/2511.10281)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10277": "|**2025-11-13**|**Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware**|Martin Braas et.al.|[2511.10277](https://arxiv.org/abs/2511.10277)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10276": "|**2025-11-13**|**RoboBenchMart: Benchmarking Robots in Retail Environment**|Konstantin Soshin et.al.|[2511.10276](https://arxiv.org/abs/2511.10276)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10271": "|**2025-11-13**|**Quality Assurance of LLM-generated Code: Addressing Non-Functional Quality Characteristics**|Xin Sun et.al.|[2511.10271](https://arxiv.org/abs/2511.10271)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10233": "|**2025-11-13**|**Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation**|Jianghan Zhu et.al.|[2511.10233](https://arxiv.org/abs/2511.10233)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10218": "|**2025-11-13**|**MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion**|Haolong Xiang et.al.|[2511.10218](https://arxiv.org/abs/2511.10218)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10198": "|**2025-11-13**|**Population-mobility coevolution drives spatial heterogeneity of cities**|Hao Huang et.al.|[2511.10198](https://arxiv.org/abs/2511.10198)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10182": "|**2025-11-13**|**Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA**|Yiran Zhang et.al.|[2511.10182](https://arxiv.org/abs/2511.10182)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10180": "|**2025-11-13**|**Selection of Supervised Learning-based Sparse Matrix Reordering Algorithms**|Tao Tang et.al.|[2511.10180](https://arxiv.org/abs/2511.10180)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10173": "|**2025-11-13**|**CephRes-MHNet: A Multi-Head Residual Network for Accurate and Robust Cephalometric Landmark Detection**|Ahmed Jaheen et.al.|[2511.10173](https://arxiv.org/abs/2511.10173)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10166": "|**2025-11-13**|**Physically Interpretable Multi-Degradation Image Restoration via Deep Unfolding and Explainable Convolution**|Hu Gao et.al.|[2511.10166](https://arxiv.org/abs/2511.10166)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10130": "|**2025-11-13**|**RI-Loss: A Learnable Residual-Informed Loss for Time Series Forecasting**|Jieting Wang et.al.|[2511.10130](https://arxiv.org/abs/2511.10130)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.10110": "|**2025-11-13**|**Learning a Thousand Tasks in a Day**|Kamil Dreczkowski et.al.|[2511.10110](https://arxiv.org/abs/2511.10110)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10107": "|**2025-11-13**|**RobIA: Robust Instance-aware Continual Test-time Adaptation for Deep Stereo**|Jueun Ko et.al.|[2511.10107](https://arxiv.org/abs/2511.10107)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10098": "|**2025-11-13**|**MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models**|Zihan Wang et.al.|[2511.10098](https://arxiv.org/abs/2511.10098)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2511.10089": "|**2025-11-13**|**T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models**|Abu Sufian et.al.|[2511.10089](https://arxiv.org/abs/2511.10089)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10087": "|**2025-11-13**|**Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning**|Haidong Huang et.al.|[2511.10087](https://arxiv.org/abs/2511.10087)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2511.10079": "|**2025-11-13**|**Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks**|Yizheng Wang et.al.|[2511.10079](https://arxiv.org/abs/2511.10079)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10073": "|**2025-11-13**|**Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement**|Yuhao Ren et.al.|[2511.10073](https://arxiv.org/abs/2511.10073)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10067": "|**2025-11-13**|**Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning**|Yuxuan Zhou et.al.|[2511.10067](https://arxiv.org/abs/2511.10067)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10065": "|**2025-11-13**|**Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation**|Bodong Du et.al.|[2511.10065](https://arxiv.org/abs/2511.10065)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.10015": "|**2025-11-13**|**Efficient Verification and Falsification of ReLU Neural Barrier Certificates**|Dejin Ren et.al.|[2511.10015](https://arxiv.org/abs/2511.10015)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10011": "|**2025-11-13**|**Reinforcing Trustworthiness in Multimodal Emotional Support Systems**|Huy M. Le et.al.|[2511.10011](https://arxiv.org/abs/2511.10011)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10008": "|**2025-11-13**|**Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks**|Xuancun Lu et.al.|[2511.10008](https://arxiv.org/abs/2511.10008)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11562": "|**2025-11-14**|**PRBench: Large-Scale Expert Rubrics for Evaluating High-Stakes Professional Reasoning**|Afra Feyza Aky\u00fcrek et.al.|[2511.11562](https://arxiv.org/abs/2511.11562)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11533": "|**2025-11-14**|**Volumetric Ergodic Control**|Jueun Kwon et.al.|[2511.11533](https://arxiv.org/abs/2511.11533)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11520": "|**2025-11-14**|**Scalable Policy Evaluation with Video World Models**|Wei-Cheng Tseng et.al.|[2511.11520](https://arxiv.org/abs/2511.11520)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.11503": "|**2025-11-14**|**SynthSoM-Twin: A Multi-Modal Sensing-Communication Digital-Twin Dataset for Sim2Real Transfer via Synesthesia of Machines**|Junlong Chen et.al.|[2511.11503](https://arxiv.org/abs/2511.11503)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11478": "|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Nhat Chung et.al.|[2511.11478](https://arxiv.org/abs/2511.11478)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11473": "|**2025-11-14**|**Proactive Hearing Assistants that Isolate Egocentric Conversations**|Guilin Hu et.al.|[2511.11473](https://arxiv.org/abs/2511.11473)|**[link](https://huggingface.co/models/guilinhu/proactive_hearing)**|\n", "2511.11470": "|**2025-11-14**|**Sat2RealCity: Geometry-Aware and Appearance-Controllable 3D Urban Generation from Satellite Imagery**|Yijie Kang et.al.|[2511.11470](https://arxiv.org/abs/2511.11470)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11462": "|**2025-11-14**|**MoCap2Radar: A Spatiotemporal Transformer for Synthesizing Micro-Doppler Radar Signatures from Motion Capture**|Kevin Chen et.al.|[2511.11462](https://arxiv.org/abs/2511.11462)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.11459": "|**2025-11-14**|**FairReweighing: Density Estimation-Based Reweighing Framework for Improving Separation in Fair Regression**|Xiaoyin Xi et.al.|[2511.11459](https://arxiv.org/abs/2511.11459)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11450": "|**2025-11-14**|**VoxTell: Free-Text Promptable Universal 3D Medical Image Segmentation**|Maximilian Rokuss et.al.|[2511.11450](https://arxiv.org/abs/2511.11450)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11440": "|**2025-11-14**|**From Synthetic Scenes to Real Performance: Enhancing Spatial Reasoning in VLMs**|Massimo Rizzoli et.al.|[2511.11440](https://arxiv.org/abs/2511.11440)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11438": "|**2025-11-14**|**VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models**|Mingjie Xu et.al.|[2511.11438](https://arxiv.org/abs/2511.11438)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11434": "|**2025-11-14**|**WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation**|Wei Chow et.al.|[2511.11434](https://arxiv.org/abs/2511.11434)|**[link](https://huggingface.co/models/WeiChow/Bagel-weave)**|\n", "2511.11393": "|**2025-11-14**|**Robust and Efficient Communication in Multi-Agent Reinforcement Learning**|Zejiao Liu et.al.|[2511.11393](https://arxiv.org/abs/2511.11393)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11357": "|**2025-11-14**|**KarmaTS: A Universal Simulation Platform for Multivariate Time Series with Functional Causal Dynamics**|Haixin Li et.al.|[2511.11357](https://arxiv.org/abs/2511.11357)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.11338": "|**2025-11-14**|**Extreme-PLS with missing data under weak dependence**|St\u00e9phane Girard et.al.|[2511.11338](https://arxiv.org/abs/2511.11338)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11323": "|**2025-11-14**|**RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms**|Yitian Kou et.al.|[2511.11323](https://arxiv.org/abs/2511.11323)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11315": "|**2025-11-14**|**LAET: A Layer-wise Adaptive Ensemble Tuning Framework for Pretrained Language Models**|Jawad Ibn Ahad et.al.|[2511.11315](https://arxiv.org/abs/2511.11315)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Yihao Zhang et.al.|[2511.11298](https://arxiv.org/abs/2511.11298)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11294": "|**2025-11-14**|**Decomposing Direct and Indirect Biases in Linear Models under Demographic Parity Constraint**|Bertille Tierny et.al.|[2511.11294](https://arxiv.org/abs/2511.11294)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11286": "|**2025-11-14**|**D-GAP: Improving Out-of-Domain Robustness via Dataset-Agnostic and Gradient-Guided Augmentation in Amplitude and Pixel Spaces**|Ruoqi Wang et.al.|[2511.11286](https://arxiv.org/abs/2511.11286)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11262": "|**2025-11-14**|**Discovering Meaningful Units with Visually Grounded Semantics from Image Captions**|Melika Behjati et.al.|[2511.11262](https://arxiv.org/abs/2511.11262)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11257": "|**2025-11-14**|**AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery**|Yuqi Yin et.al.|[2511.11257](https://arxiv.org/abs/2511.11257)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11255": "|**2025-11-14**|**Align$^3$GR: Unified Multi-Level Alignment for LLM-based Generative Recommendation**|Wencai Ye et.al.|[2511.11255](https://arxiv.org/abs/2511.11255)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11251": "|**2025-11-14**|**Testbed Evaluation of AI-based Precoding in Distributed MIMO Systems**|Tianzheng Miao et.al.|[2511.11251](https://arxiv.org/abs/2511.11251)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11245": "|**2025-11-14**|**Heterogeneous Attributed Graph Learning via Neighborhood-Aware Star Kernels**|Hong Huang et.al.|[2511.11245](https://arxiv.org/abs/2511.11245)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.11244": "|**2025-11-14**|**Toward Gaze Target Detection of Young Autistic Children**|Shijian Deng et.al.|[2511.11244](https://arxiv.org/abs/2511.11244)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11239": "|**2025-11-14**|**Beyond Flatlands: Unlocking Spatial Intelligence by Decoupling 3D Reasoning from Numerical Regression**|Zhongbin Guo et.al.|[2511.11239](https://arxiv.org/abs/2511.11239)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11223": "|**2025-11-14**|**Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects**|Sverre Herland et.al.|[2511.11223](https://arxiv.org/abs/2511.11223)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11218": "|**2025-11-14**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Chenhao Liu et.al.|[2511.11218](https://arxiv.org/abs/2511.11218)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.11177": "|**2025-11-14**|**Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation**|Quoc-Huy Trinh et.al.|[2511.11177](https://arxiv.org/abs/2511.11177)|**[link](https://huggingface.co/models/huyquoctrinh/Viper-F1)**|\n", "2511.11165": "|**2025-11-14**|**Explainable Deep Convolutional Multi-Type Anomaly Detection**|Alex George et.al.|[2511.11165](https://arxiv.org/abs/2511.11165)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11152": "|**2025-11-14**|**Deep Learning for Short-Term Precipitation Prediction in Four Major Indian Cities: A ConvLSTM Approach with Explainable AI**|Tanmay Ghosh et.al.|[2511.11152](https://arxiv.org/abs/2511.11152)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11124": "|**2025-11-14**|**AV-Dialog: Spoken Dialogue Models with Audio-Visual Input**|Tuochao Chen et.al.|[2511.11124](https://arxiv.org/abs/2511.11124)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11090": "|**2025-11-14**|**A Space-Time Transformer for Precipitation Forecasting**|Levi Harris et.al.|[2511.11090](https://arxiv.org/abs/2511.11090)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11088": "|**2025-11-14**|**ResBench: A Comprehensive Framework for Evaluating Database Resilience**|Puyun Hu et.al.|[2511.11088](https://arxiv.org/abs/2511.11088)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11086": "|**2025-11-14**|**Latent space models for grouped multiplex networks**|Alexander Kagan et.al.|[2511.11086](https://arxiv.org/abs/2511.11086)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11079": "|**2025-11-14**|**ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving**|Sejin Kim et.al.|[2511.11079](https://arxiv.org/abs/2511.11079)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.11077": "|**2025-11-14**|**Phys-Liquid: A Physics-Informed Dataset for Estimating 3D Geometry and Volume of Transparent Deformable Liquids**|Ke Ma et.al.|[2511.11077](https://arxiv.org/abs/2511.11077)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11052": "|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Jinxuan Zhu et.al.|[2511.11052](https://arxiv.org/abs/2511.11052)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11043": "|**2025-11-14**|**Autonomous Vehicle Path Planning by Searching With Differentiable Simulation**|Asen Nachkov et.al.|[2511.11043](https://arxiv.org/abs/2511.11043)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11025": "|**2025-11-14**|**AirCopBench: A Benchmark for Multi-drone Collaborative Embodied Perception and Reasoning**|Jirong Zha et.al.|[2511.11025](https://arxiv.org/abs/2511.11025)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11017": "|**2025-11-14**|**AI Agent-Driven Framework for Automated Product Knowledge Graph Construction in E-Commerce**|Dimitar Peshevski et.al.|[2511.11017](https://arxiv.org/abs/2511.11017)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11011": "|**2025-11-14**|**Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation**|Zhiwei Zhang et.al.|[2511.11011](https://arxiv.org/abs/2511.11011)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.11000": "|**2025-11-14**|**DialogGraph-LLM: Graph-Informed LLMs for End-to-End Audio Dialogue Intent Recognition**|HongYu Liu et.al.|[2511.11000](https://arxiv.org/abs/2511.11000)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10997": "|**2025-11-14**|**PROMISE: Prompt-Attentive Hierarchical Contrastive Learning for Robust Cross-Modal Representation with Missing Modalities**|Jiajun Chen et.al.|[2511.10997](https://arxiv.org/abs/2511.10997)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10987": "|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Wenbin Bai et.al.|[2511.10987](https://arxiv.org/abs/2511.10987)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10962": "|**2025-11-14**|**LEMUR: Large scale End-to-end MUltimodal Recommendation**|Xintian Han et.al.|[2511.10962](https://arxiv.org/abs/2511.10962)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10946": "|**2025-11-14**|**Abstract 3D Perception for Spatial Intelligence in Vision-Language Models**|Yifan Liu et.al.|[2511.10946](https://arxiv.org/abs/2511.10946)|null|\n", "2511.10940": "|**2025-11-14**|**Facial Expression Recognition with YOLOv11 and YOLOv12: A Comparative Study**|Umma Aymon et.al.|[2511.10940](https://arxiv.org/abs/2511.10940)|null|\n", "2511.13717": "|**2025-11-17**|**TZ-LLM: Protecting On-Device Large Language Models with Arm TrustZone**|Xunjie Wang et.al.|[2511.13717](https://arxiv.org/abs/2511.13717)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13715": "|**2025-11-17**|**Segment Anything Across Shots: A Method and Benchmark**|Hengrui Hu et.al.|[2511.13715](https://arxiv.org/abs/2511.13715)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13713": "|**2025-11-17**|**Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine**|Xincheng Shuai et.al.|[2511.13713](https://arxiv.org/abs/2511.13713)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13712": "|**2025-11-17**|**From Black Box to Insight: Explainable AI for Extreme Event Preparedness**|Kiana Vu et.al.|[2511.13712](https://arxiv.org/abs/2511.13712)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13710": "|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Jianglong Ye et.al.|[2511.13710](https://arxiv.org/abs/2511.13710)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13703": "|**2025-11-17**|**Generalist Foundation Models Are Not Clinical Enough for Hospital Operations**|Lavender Y. Jiang et.al.|[2511.13703](https://arxiv.org/abs/2511.13703)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13661": "|**2025-11-17**|**Ontology-Driven Model-to-Model Transformation of Workflow Specifications**|Francisco Abreu et.al.|[2511.13661](https://arxiv.org/abs/2511.13661)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13655": "|**2025-11-17**|**OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation**|Henry Herzog et.al.|[2511.13655](https://arxiv.org/abs/2511.13655)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13648": "|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziang Cao et.al.|[2511.13648](https://arxiv.org/abs/2511.13648)|**[link](https://huggingface.co/datasets/Caoza/PhysX-Mobility)**|\n", "2511.13646": "|**2025-11-17**|**Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?**|Chunqiu Steven Xia et.al.|[2511.13646](https://arxiv.org/abs/2511.13646)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13629": "|**2025-11-17**|**Sensitivity to low-mass WIMPs with an improved liquid argon ionization response model within the DarkSide programme**|F. Acerbi et.al.|[2511.13629](https://arxiv.org/abs/2511.13629)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13590": "|**2025-11-17**|**Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation**|Hao Wang et.al.|[2511.13590](https://arxiv.org/abs/2511.13590)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13541": "|**2025-11-17**|**Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries**|Yue Hou et.al.|[2511.13541](https://arxiv.org/abs/2511.13541)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13523": "|**2025-11-17**|**Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports**|Nikita Neveditsin et.al.|[2511.13523](https://arxiv.org/abs/2511.13523)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13502": "|**2025-11-17**|**Tight and Practical Privacy Auditing for Differentially Private In-Context Learning**|Yuyang Xia et.al.|[2511.13502](https://arxiv.org/abs/2511.13502)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13481": "|**2025-11-17**|**Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns**|Attapol T. Rutherford et.al.|[2511.13481](https://arxiv.org/abs/2511.13481)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13478": "|**2025-11-17**|**Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling**|Adam Hazimeh et.al.|[2511.13478](https://arxiv.org/abs/2511.13478)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13476": "|**2025-11-17**|**Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation**|Zhipeng Ma et.al.|[2511.13476](https://arxiv.org/abs/2511.13476)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13463": "|**2025-11-17**|**Multi-task GINN-LP for Multi-target Symbolic Regression**|Hussein Rajabu et.al.|[2511.13463](https://arxiv.org/abs/2511.13463)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13459": "|**2025-11-17**|**Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness**|Bingkun Huang et.al.|[2511.13459](https://arxiv.org/abs/2511.13459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13411": "|**2025-11-17**|**An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence**|Przemyslaw Chojecki et.al.|[2511.13411](https://arxiv.org/abs/2511.13411)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.13397": "|**2025-11-17**|**Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)**|Nikos Theodoridis et.al.|[2511.13397](https://arxiv.org/abs/2511.13397)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13381": "|**2025-11-17**|**Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts**|Siyu Zhu et.al.|[2511.13381](https://arxiv.org/abs/2511.13381)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13371": "|**2025-11-17**|**Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning**|Caroline Baumgartner et.al.|[2511.13371](https://arxiv.org/abs/2511.13371)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13357": "|**2025-11-17**|**FLOWER: Flow-Oriented Entity-Relationship Tool**|Dmitry Moskalev et.al.|[2511.13357](https://arxiv.org/abs/2511.13357)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13327": "|**2025-11-17**|**ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning**|Juntao Jian et.al.|[2511.13327](https://arxiv.org/abs/2511.13327)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13326": "|**2025-11-17**|**TacEleven: generative tactic discovery for football open play**|Siyao Zhao et.al.|[2511.13326](https://arxiv.org/abs/2511.13326)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13312": "|**2025-11-17**|**EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation**|Jonas Bode et.al.|[2511.13312](https://arxiv.org/abs/2511.13312)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13305": "|**2025-11-17**|**SAINT: Service-level Integration Test Generation with Program Analysis and LLM-based Agents**|Rangeet Pan et.al.|[2511.13305](https://arxiv.org/abs/2511.13305)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13297": "|**2025-11-17**|**CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving**|Enhui Ma et.al.|[2511.13297](https://arxiv.org/abs/2511.13297)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13288": "|**2025-11-17**|**Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO**|Haoyang Hong et.al.|[2511.13288](https://arxiv.org/abs/2511.13288)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13260": "|**2025-11-17**|**Robust Control Design Using a Hybrid-Gain Finite-Time Sliding-Mode Controller**|Amit Shivam et.al.|[2511.13260](https://arxiv.org/abs/2511.13260)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13247": "|**2025-11-17**|**Force-Aware 3D Contact Modeling for Stable Grasp Generation**|Zhuo Chen et.al.|[2511.13247](https://arxiv.org/abs/2511.13247)|**[link](https://github.com/chzh9311/force-aware-grasp)**|\n", "2511.13240": "|**2025-11-17**|**Incoherent Beliefs & Inconsistent Actions in Large Language Models**|Arka Pal et.al.|[2511.13240](https://arxiv.org/abs/2511.13240)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13204": "|**2025-11-17**|**RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection**|Junhee Lee et.al.|[2511.13204](https://arxiv.org/abs/2511.13204)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13181": "|**2025-11-17**|**Probabilistic dynamics of small groups in crowd flows**|Chiel van der Laan et.al.|[2511.13181](https://arxiv.org/abs/2511.13181)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13147": "|**2025-11-17**|**OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs**|Shaoyuan Chen et.al.|[2511.13147](https://arxiv.org/abs/2511.13147)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13133": "|**2025-11-17**|**Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning**|Shudong Wang et.al.|[2511.13133](https://arxiv.org/abs/2511.13133)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13132": "|**2025-11-17**|**Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack**|Chenyang Li et.al.|[2511.13132](https://arxiv.org/abs/2511.13132)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13113": "|**2025-11-17**|**Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining**|Zhaocheng Yu et.al.|[2511.13113](https://arxiv.org/abs/2511.13113)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13110": "|**2025-11-17**|**Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing**|Shuaibin Fan et.al.|[2511.13110](https://arxiv.org/abs/2511.13110)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13078": "|**2025-11-17**|**A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning**|Liuyi Jin et.al.|[2511.13078](https://arxiv.org/abs/2511.13078)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2511.13065": "|**2025-11-17**|**RobustGait: Robustness Analysis for Appearance Based Gait Recognition**|Reeshoon Sayera et.al.|[2511.13065](https://arxiv.org/abs/2511.13065)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13062": "|**2025-11-17**|**Self-Adaptive Graph Mixture of Models**|Mohit Meena et.al.|[2511.13062](https://arxiv.org/abs/2511.13062)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.13061": "|**2025-11-17**|**MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity**|Vladim\u00edr Macko et.al.|[2511.13061](https://arxiv.org/abs/2511.13061)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.13057": "|**2025-11-17**|**Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact**|Satyanarayan Pati et.al.|[2511.13057](https://arxiv.org/abs/2511.13057)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13055": "|**2025-11-17**|**Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries**|Ruixin Liu et.al.|[2511.13055](https://arxiv.org/abs/2511.13055)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13043": "|**2025-11-17**|**Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training**|Xinyuan Zhou et.al.|[2511.13043](https://arxiv.org/abs/2511.13043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13021": "|**2025-11-17**|**PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics**|Sachin Vashistha et.al.|[2511.13021](https://arxiv.org/abs/2511.13021)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13005": "|**2025-11-17**|**SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias**|Wenqian Ye et.al.|[2511.13005](https://arxiv.org/abs/2511.13005)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14759": "|**2025-11-18**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Ali Amin et.al.|[2511.14759](https://arxiv.org/abs/2511.14759)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2511.14756": "|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Lai Wei et.al.|[2511.14756](https://arxiv.org/abs/2511.14756)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.14738": "|**2025-11-18**|**LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data**|Tzu-Hsuan Chou et.al.|[2511.14738](https://arxiv.org/abs/2511.14738)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14715": "|**2025-11-18**|**\\textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning**|Abolfazl Younesi et.al.|[2511.14715](https://arxiv.org/abs/2511.14715)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14711": "|**2025-11-18**|**Why Do We Code? A Theory on Motivations and Challenges in Software Engineering from Education to Practice**|Aaliyah Chang et.al.|[2511.14711](https://arxiv.org/abs/2511.14711)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14698": "|**2025-11-18**|**HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring**|Sriram Srinivasan et.al.|[2511.14698](https://arxiv.org/abs/2511.14698)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al.|[2511.14659](https://arxiv.org/abs/2511.14659)|**[link](https://huggingface.co/models/declare-lab/nora-1.5)**|\n", "2511.14640": "|**2025-11-18**|**Doppler Invariant CNN for Signal Classification**|Avi Bagchi et.al.|[2511.14640](https://arxiv.org/abs/2511.14640)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14638": "|**2025-11-18**|**A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases**|Tao Yang et.al.|[2511.14638](https://arxiv.org/abs/2511.14638)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14620": "|**2025-11-18**|**Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction: Characterizing and Mitigating the Simulation-to-Reality Gap**|Md Fokhrul Islam et.al.|[2511.14620](https://arxiv.org/abs/2511.14620)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14604": "|**2025-11-18**|**XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation**|Yilin Zhang et.al.|[2511.14604](https://arxiv.org/abs/2511.14604)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14599": "|**2025-11-18**|**CCSD: Cross-Modal Compositional Self-Distillation for Robust Brain Tumor Segmentation with Missing Modalities**|Dongqing Xie et.al.|[2511.14599](https://arxiv.org/abs/2511.14599)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14543": "|**2025-11-18**|**MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation**|Youran Zhou et.al.|[2511.14543](https://arxiv.org/abs/2511.14543)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14536": "|**2025-11-18**|**A General Framework for Physician Rostering Using Mixed-Integer Programming and a Web-Based Graphical User Interface**|Florian Meier et.al.|[2511.14536](https://arxiv.org/abs/2511.14536)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14533": "|**2025-11-18**|**A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning**|Jiahao Wu et.al.|[2511.14533](https://arxiv.org/abs/2511.14533)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.14473": "|**2025-11-18**|**Learning Subglacial Bed Topography from Sparse Radar with Physics-Guided Residuals**|Bayu Adhi Tama et.al.|[2511.14473](https://arxiv.org/abs/2511.14473)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14441": "|**2025-11-18**|**Skewness-Robust Causal Discovery in Location-Scale Noise Models**|Daniel Klippert et.al.|[2511.14441](https://arxiv.org/abs/2511.14441)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14440": "|**2025-11-18**|**Learning to See Through a Baby's Eyes: Early Visual Diets Enable Robust Visual Intelligence in Humans and Machines**|Yusen Cai et.al.|[2511.14440](https://arxiv.org/abs/2511.14440)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14427": "|**2025-11-18**|**Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning**|Rickmer Krohn et.al.|[2511.14427](https://arxiv.org/abs/2511.14427)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14416": "|**2025-11-18**|**Toward Robust and Harmonious Adaptation for Cross-modal Retrieval**|Haobin Li et.al.|[2511.14416](https://arxiv.org/abs/2511.14416)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14396": "|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi et.al.|[2511.14396](https://arxiv.org/abs/2511.14396)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14386": "|**2025-11-18**|**Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving**|Kangqiao Zhao et.al.|[2511.14386](https://arxiv.org/abs/2511.14386)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14385": "|**2025-11-18**|**Mitigating Label Length Bias in Large Language Models**|Mario Sanz-Guerrero et.al.|[2511.14385](https://arxiv.org/abs/2511.14385)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14368": "|**2025-11-18**|**O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model**|Rishi Gupta et.al.|[2511.14368](https://arxiv.org/abs/2511.14368)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14366": "|**2025-11-18**|**ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning**|Hongwei Liu et.al.|[2511.14366](https://arxiv.org/abs/2511.14366)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14349": "|**2025-11-18**|**ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries**|Junfu Pu et.al.|[2511.14349](https://arxiv.org/abs/2511.14349)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14343": "|**2025-11-18**|**Silhouette-to-Contour Registration: Aligning Intraoral Scan Models with Cephalometric Radiographs**|Yiyi Miao et.al.|[2511.14343](https://arxiv.org/abs/2511.14343)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.14317": "|**2025-11-18**|**Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect**|Yuwen Zhang et.al.|[2511.14317](https://arxiv.org/abs/2511.14317)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14301": "|**2025-11-18**|**Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion**|Eric Xue et.al.|[2511.14301](https://arxiv.org/abs/2511.14301)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14291": "|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Yuxin Zhang et.al.|[2511.14291](https://arxiv.org/abs/2511.14291)|**[link](https://github.com/yyeboah/Awesome-Text-to-3D)**|\n", "2511.14282": "|**2025-11-18**|**Weight Variance Amplifier Improves Accuracy in High-Sparsity One-Shot Pruning**|Vincent-Daniel Yun et.al.|[2511.14282](https://arxiv.org/abs/2511.14282)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14262": "|**2025-11-18**|**Object-Centric World Models for Causality-Aware Reinforcement Learning**|Yosuke Nishimoto et.al.|[2511.14262](https://arxiv.org/abs/2511.14262)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.14224": "|**2025-11-18**|**KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation**|Anji Li et.al.|[2511.14224](https://arxiv.org/abs/2511.14224)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14221": "|**2025-11-18**|**LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation**|Hao Jiang et.al.|[2511.14221](https://arxiv.org/abs/2511.14221)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14219": "|**2025-11-18**|**Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation**|Kumud Tripathi et.al.|[2511.14219](https://arxiv.org/abs/2511.14219)|**[link](https://github.com/halsay/ASR-TTS-paper-daily)**|\n", "2511.14185": "|**2025-11-18**|**PAVE: An End-to-End Dataset for Production Autonomous Vehicle Evaluation**|Xiangyu Li et.al.|[2511.14185](https://arxiv.org/abs/2511.14185)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14178": "|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Zhuo Li et.al.|[2511.14178](https://arxiv.org/abs/2511.14178)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14168": "|**2025-11-18**|**Certified Signed Graph Unlearning**|Junpeng Zhao et.al.|[2511.14168](https://arxiv.org/abs/2511.14168)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.14162": "|**2025-11-18**|**Chipmink: Efficient Delta Identification for Massive Object Graph**|Supawit Chockchowwat et.al.|[2511.14162](https://arxiv.org/abs/2511.14162)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14161": "|**2025-11-18**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Xiaoquan Sun et.al.|[2511.14161](https://arxiv.org/abs/2511.14161)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.14159": "|**2025-11-18**|**MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs**|Huiyi Chen et.al.|[2511.14159](https://arxiv.org/abs/2511.14159)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14152": "|**2025-11-18**|**Wave-Former: Through-Occlusion 3D Reconstruction via Wireless Shape Completion**|Laura Dodds et.al.|[2511.14152](https://arxiv.org/abs/2511.14152)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14148": "|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Yuhua Jiang et.al.|[2511.14148](https://arxiv.org/abs/2511.14148)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.14140": "|**2025-11-18**|**Beyond Fixed and Dynamic Prompts: Embedded Jailbreak Templates for Advancing LLM Security**|Hajun Kim et.al.|[2511.14140](https://arxiv.org/abs/2511.14140)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14139": "|**2025-11-18**|**FlexiCup: Wireless Multimodal Suction Cup with Dual-Zone Vision-Tactile Sensing**|Junhao Gong et.al.|[2511.14139](https://arxiv.org/abs/2511.14139)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14133": "|**2025-11-18**|**Synthetic Survival Control: Extending Synthetic Controls for \"When-If\" Decision**|Jessy Xinyi Han et.al.|[2511.14133](https://arxiv.org/abs/2511.14133)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14131": "|**2025-11-18**|**Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation**|Yu Zhong et.al.|[2511.14131](https://arxiv.org/abs/2511.14131)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14130": "|**2025-11-18**|**PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval**|Chun Chet Ng et.al.|[2511.14130](https://arxiv.org/abs/2511.14130)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14129": "|**2025-11-18**|**MalRAG: A Retrieval-Augmented LLM Framework for Open-set Malicious Traffic Identification**|Xiang Luo et.al.|[2511.14129](https://arxiv.org/abs/2511.14129)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14116": "|**2025-11-18**|**FailSafe: High-performance Resilient Serving**|Ziyi Xu et.al.|[2511.14116](https://arxiv.org/abs/2511.14116)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15706": "|**2025-11-19**|**RoMa v2: Harder Better Faster Denser Feature Matching**|Johan Edstedt et.al.|[2511.15706](https://arxiv.org/abs/2511.15706)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.15705": "|**2025-11-19**|**GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization**|Yikun Wang et.al.|[2511.15705](https://arxiv.org/abs/2511.15705)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15633": "|**2025-11-19**|**Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning**|Tao Hu et.al.|[2511.15633](https://arxiv.org/abs/2511.15633)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15605": "|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei et.al.|[2511.15605](https://arxiv.org/abs/2511.15605)|**[link](https://github.com/sii-research/siiRL)**|\n", "2511.15567": "|**2025-11-19**|**Computer-Use Agents as Judges for Generative User Interface**|Kevin Qinghong Lin et.al.|[2511.15567](https://arxiv.org/abs/2511.15567)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15565": "|**2025-11-19**|**Scriboora: Rethinking Human Pose Forecasting**|Daniel Bermuth et.al.|[2511.15565](https://arxiv.org/abs/2511.15565)|**[link](https://github.com/halsay/ASR-TTS-paper-daily)**|\n", "2511.15532": "|**2025-11-19**|**NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception**|Chen Cai et.al.|[2511.15532](https://arxiv.org/abs/2511.15532)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15520": "|**2025-11-19**|**Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies**|Gabriel Lauzier et.al.|[2511.15520](https://arxiv.org/abs/2511.15520)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15511": "|**2025-11-19**|**Efficient Exoplanet Imaging Simulations of the Habitable Worlds Observatory**|Jamila Taaki et.al.|[2511.15511](https://arxiv.org/abs/2511.15511)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15479": "|**2025-11-19**|**Towards a Formal Verification of Secure Vehicle Software Updates**|Martin Slind Hagen et.al.|[2511.15479](https://arxiv.org/abs/2511.15479)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15468": "|**2025-11-19**|**Deep Learning for Accurate Vision-based Catch Composition in Tropical Tuna Purse Seiners**|Xabier Lekunberri et.al.|[2511.15468](https://arxiv.org/abs/2511.15468)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15463": "|**2025-11-19**|**How To Cook The Fragmented Rug Pull?**|Minh Trung Tran et.al.|[2511.15463](https://arxiv.org/abs/2511.15463)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15443": "|**2025-11-19**|**CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search**|Ao Xie et.al.|[2511.15443](https://arxiv.org/abs/2511.15443)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15429": "|**2025-11-19**|**WarNav: An Autonomous Driving Benchmark for Segmentation of Navigable Zones in War Scenes**|Marc-Emmanuel Coupvent des Graviers et.al.|[2511.15429](https://arxiv.org/abs/2511.15429)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15411": "|**2025-11-19**|**D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models**|Wenlun Zhang et.al.|[2511.15411](https://arxiv.org/abs/2511.15411)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15407": "|**2025-11-19**|**IPR-1: Interactive Physical Reasoner**|Mingyu Zhang et.al.|[2511.15407](https://arxiv.org/abs/2511.15407)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15392": "|**2025-11-19**|**DEPO: Dual-Efficiency Preference Optimization for LLM Agents**|Sirui Chen et.al.|[2511.15392](https://arxiv.org/abs/2511.15392)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15390": "|**2025-11-19**|**Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models**|Haidong Kang et.al.|[2511.15390](https://arxiv.org/abs/2511.15390)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15379": "|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Yunjiao Zhou et.al.|[2511.15379](https://arxiv.org/abs/2511.15379)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15377": "|**2025-11-19**|**Towards Evolutionary Optimization Using the Ising Model**|Simon Kl\u00fcttermann et.al.|[2511.15377](https://arxiv.org/abs/2511.15377)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15375": "|**2025-11-19**|**Parameter Importance-Driven Continual Learning for Foundation Models**|Lingxiang Wang et.al.|[2511.15375](https://arxiv.org/abs/2511.15375)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15374": "|**2025-11-19**|**Judicial Sentencing Prediction Based on Hybrid Models and Two-Stage Learning Algorithms**|Ruifen Dai et.al.|[2511.15374](https://arxiv.org/abs/2511.15374)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15352": "|**2025-11-19**|**People readily follow personal advice from AI but it does not improve their well-being**|Lennart Luettgau et.al.|[2511.15352](https://arxiv.org/abs/2511.15352)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15351": "|**2025-11-19**|**Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration**|Yifu Guo et.al.|[2511.15351](https://arxiv.org/abs/2511.15351)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15350": "|**2025-11-19**|**Multi-layer Stack Ensembles for Time Series Forecasting**|Nathanael Bosch et.al.|[2511.15350](https://arxiv.org/abs/2511.15350)|**[link](https://github.com/autogluon/autogluon)**|\n", "2511.15342": "|**2025-11-19**|**Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions**|Shan Shan et.al.|[2511.15342](https://arxiv.org/abs/2511.15342)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15341": "|**2025-11-19**|**Anchor-and-Connect: Robotic Aerial Base Stations Transforming 6G Infrastructure**|Wen Shang et.al.|[2511.15341](https://arxiv.org/abs/2511.15341)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15311": "|**2025-11-19**|**Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models**|Mehran Tamjidi et.al.|[2511.15311](https://arxiv.org/abs/2511.15311)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Jiashu Yang et.al.|[2511.15279](https://arxiv.org/abs/2511.15279)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15274": "|**2025-11-19**|**Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms**|Alexander Boldachev et.al.|[2511.15274](https://arxiv.org/abs/2511.15274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15266": "|**2025-11-19**|**ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing**|Liangyu Chen et.al.|[2511.15266](https://arxiv.org/abs/2511.15266)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15256": "|**2025-11-19**|**GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning**|Yanchen Xu et.al.|[2511.15256](https://arxiv.org/abs/2511.15256)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15251": "|**2025-11-19**|**PLATONT: Learning a Platonic Representation for Unified Network Tomography**|Chengze Du et.al.|[2511.15251](https://arxiv.org/abs/2511.15251)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15239": "|**2025-11-19**|**Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy**|Tomoki Nakao et.al.|[2511.15239](https://arxiv.org/abs/2511.15239)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15229": "|**2025-11-19**|**From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras**|Bashar Abdallah et.al.|[2511.15229](https://arxiv.org/abs/2511.15229)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15218": "|**2025-11-19**|**Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding of Complex Visual Imagery**|Byoung-Hee Kwon et.al.|[2511.15218](https://arxiv.org/abs/2511.15218)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15200": "|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Tairan He et.al.|[2511.15200](https://arxiv.org/abs/2511.15200)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.15197": "|**2025-11-19**|**Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition**|Raghu Vamsi Chittersu et.al.|[2511.15197](https://arxiv.org/abs/2511.15197)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2511.15194": "|**2025-11-19**|**Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization**|Jian Deng et.al.|[2511.15194](https://arxiv.org/abs/2511.15194)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15183": "|**2025-11-19**|**HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples**|Rishikant Chigrupaatii et.al.|[2511.15183](https://arxiv.org/abs/2511.15183)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15168": "|**2025-11-19**|**Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework**|Nguyen-Khang Le et.al.|[2511.15168](https://arxiv.org/abs/2511.15168)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15159": "|**2025-11-19**|**Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation**|Firdavs Nasriddinov et.al.|[2511.15159](https://arxiv.org/abs/2511.15159)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15155": "|**2025-11-19**|**Robust outlier-adjusted mean-shift estimation of state-space models**|Rajan Shankar et.al.|[2511.15155](https://arxiv.org/abs/2511.15155)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.15131": "|**2025-11-19**|**CASTELLA: Long Audio Dataset with Captions and Temporal Boundaries**|Hokuto Munakata et.al.|[2511.15131](https://arxiv.org/abs/2511.15131)|**[link](https://huggingface.co/datasets/lighthouse-emnlp2024/CASTELLA_CLAP_features)**|\n", "2511.15083": "|**2025-11-19**|**Fourier-KAN-Mamba: A Novel State-Space Equation Approach for Time-Series Anomaly Detection**|Xiancheng Wang et.al.|[2511.15083](https://arxiv.org/abs/2511.15083)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.15059": "|**2025-11-19**|**Evaluating Multimodal Large Language Models on Vertically Written Japanese Text**|Keito Sasagawa et.al.|[2511.15059](https://arxiv.org/abs/2511.15059)|**[link](https://huggingface.co/datasets/llm-jp/JSSODa)**|\n", "2511.15010": "|**2025-11-19**|**Latent space analysis and generalization to out-of-distribution data**|Katie Rainey et.al.|[2511.15010](https://arxiv.org/abs/2511.15010)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14989": "|**2025-11-19**|**Critical Evaluation of Quantum Machine Learning for Adversarial Robustness**|Saeefa Rubaiyet Nowmi et.al.|[2511.14989](https://arxiv.org/abs/2511.14989)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14963": "|**2025-11-18**|**LFreeDA: Label-Free Drift Adaptation for Windows Malware Detection**|Adrian Shuai Li et.al.|[2511.14963](https://arxiv.org/abs/2511.14963)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14945": "|**2025-11-18**|**Unsupervised Discovery of Long-Term Spatiotemporal Periodic Workflows in Human Activities**|Fan Yang et.al.|[2511.14945](https://arxiv.org/abs/2511.14945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16669": "|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Junhao Cheng et.al.|[2511.16669](https://arxiv.org/abs/2511.16669)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16668": "|**2025-11-20**|**V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models**|Yang Luo et.al.|[2511.16668](https://arxiv.org/abs/2511.16668)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16661": "|**2025-11-20**|**Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations**|Irmak Guzey et.al.|[2511.16661](https://arxiv.org/abs/2511.16661)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.16655": "|**2025-11-20**|**Solving Spatial Supersensing Without Spatial Supersensing**|Vishaal Udandarao et.al.|[2511.16655](https://arxiv.org/abs/2511.16655)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Yang Tian et.al.|[2511.16651](https://arxiv.org/abs/2511.16651)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16624": "|**2025-11-20**|**SAM 3D: 3Dfy Anything in Images**|SAM 3D Team et.al.|[2511.16624](https://arxiv.org/abs/2511.16624)|**[link](https://huggingface.co/spaces/nicka360/sam3d)**|\n", "2511.16602": "|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Yi Zhang et.al.|[2511.16602](https://arxiv.org/abs/2511.16602)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16596": "|**2025-11-20**|**Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies**|Zohar Rimon et.al.|[2511.16596](https://arxiv.org/abs/2511.16596)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2511.16571": "|**2025-11-20**|**Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion**|Md. Tawfique Ihsan et.al.|[2511.16571](https://arxiv.org/abs/2511.16571)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16555": "|**2025-11-20**|**Lite Any Stereo: Efficient Zero-Shot Stereo Matching**|Junpeng Jing et.al.|[2511.16555](https://arxiv.org/abs/2511.16555)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16551": "|**2025-11-20**|**Toward Valid Generative Clinical Trial Data with Survival Endpoints**|Perrine Chassat et.al.|[2511.16551](https://arxiv.org/abs/2511.16551)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16549": "|**2025-11-20**|**FairLRF: Achieving Fairness through Sparse Low Rank Factorization**|Yuanbo Guo et.al.|[2511.16549](https://arxiv.org/abs/2511.16549)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16528": "|**2025-11-20**|**TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval**|\u00d6zay Ezerceli et.al.|[2511.16528](https://arxiv.org/abs/2511.16528)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16484": "|**2025-11-20**|**Flow and Depth Assisted Video Prediction with Latent Transformer**|Eliyas Suleyman et.al.|[2511.16484](https://arxiv.org/abs/2511.16484)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16482": "|**2025-11-20**|**Correlation-Aware Feature Attribution Based Explainable AI**|Poushali Sengupta et.al.|[2511.16482](https://arxiv.org/abs/2511.16482)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16450": "|**2025-11-20**|**Optimizing Federated Learning in the Era of LLMs: Message Quantization and Streaming**|Ziyue Xu et.al.|[2511.16450](https://arxiv.org/abs/2511.16450)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16449": "|**2025-11-20**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Ziyan Liu et.al.|[2511.16449](https://arxiv.org/abs/2511.16449)|**[link](https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling)**|\n", "2511.16440": "|**2025-11-20**|**StreetView-Waste: A Multi-Task Dataset for Urban Waste Management**|Diogo J. Paulo et.al.|[2511.16440](https://arxiv.org/abs/2511.16440)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16432": "|**2025-11-20**|**From generative AI to the brain: five takeaways**|Claudius Gros et.al.|[2511.16432](https://arxiv.org/abs/2511.16432)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16427": "|**2025-11-20**|**Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations**|Muhammad Aslanimoghanloo et.al.|[2511.16427](https://arxiv.org/abs/2511.16427)|null|\n", "2511.16426": "|**2025-11-20**|**FreqFlow: Long-term forecasting using lightweight flow matching**|Seyed Mohamad Moghadas et.al.|[2511.16426](https://arxiv.org/abs/2511.16426)|null|\n", "2511.16424": "|**2025-11-20**|**Second-Order MPC-Based Distributed Q-Learning**|Samuel Mallick et.al.|[2511.16424](https://arxiv.org/abs/2511.16424)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16418": "|**2025-11-20**|**End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss**|Hai Lan et.al.|[2511.16418](https://arxiv.org/abs/2511.16418)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16414": "|**2025-11-20**|**An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm**|Hao Liu et.al.|[2511.16414](https://arxiv.org/abs/2511.16414)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16406": "|**2025-11-20**|**Homogeneous Proportional-Integral-Derivative Controller in Mobile Robotic Manipulators**|Luis Luna et.al.|[2511.16406](https://arxiv.org/abs/2511.16406)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16398": "|**2025-11-20**|**Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method**|Yidong Chai et.al.|[2511.16398](https://arxiv.org/abs/2511.16398)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16372": "|**2025-11-20**|**Flow-Aided Flight Through Dynamic Clutters From Point To Motion**|Bowen Xu et.al.|[2511.16372](https://arxiv.org/abs/2511.16372)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16364": "|**2025-11-20**|**DetailSemNet: Elevating Signature Verification through Detail-Semantic Integration**|Meng-Cheng Shih et.al.|[2511.16364](https://arxiv.org/abs/2511.16364)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16333": "|**2025-11-20**|**Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning**|Mohammad Areeb Qazi et.al.|[2511.16333](https://arxiv.org/abs/2511.16333)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16324": "|**2025-11-20**|**SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning**|Wei Xia et.al.|[2511.16324](https://arxiv.org/abs/2511.16324)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16278": "|**2025-11-20**|**\"To Survive, I Must Defect\": Jailbreaking LLMs via the Game-Theory Scenarios**|Zhen Sun et.al.|[2511.16278](https://arxiv.org/abs/2511.16278)|null|\n", "2511.16260": "|**2025-11-20**|**Low-Complexity Rydberg Array Reuse: Modeling and Receiver Design for Sparse Channels**|Hao Wu et.al.|[2511.16260](https://arxiv.org/abs/2511.16260)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16248": "|**2025-11-20**|**Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob**|Yun Lu et.al.|[2511.16248](https://arxiv.org/abs/2511.16248)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16224": "|**2025-11-20**|**Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts**|Francesco Salzano et.al.|[2511.16224](https://arxiv.org/abs/2511.16224)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16223": "|**2025-11-20**|**DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks**|Vincenzo Pomponi et.al.|[2511.16223](https://arxiv.org/abs/2511.16223)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.16218": "|**2025-11-20**|**Mind the Gap: Bridging Prior Shift in Realistic Few-Shot Crop-Type Classification**|Joana Reuss et.al.|[2511.16218](https://arxiv.org/abs/2511.16218)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16216": "|**2025-11-20**|**FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks**|Zhen Hao Wong et.al.|[2511.16216](https://arxiv.org/abs/2511.16216)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16204": "|**2025-11-20**|**Causal Synthetic Data Generation in Recruitment**|Andrea Iommi et.al.|[2511.16204](https://arxiv.org/abs/2511.16204)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16203": "|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan et.al.|[2511.16203](https://arxiv.org/abs/2511.16203)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.16184": "|**2025-11-20**|**Domain-Shared Learning and Gradual Alignment for Unsupervised Domain Adaptation Visible-Infrared Person Re-Identification**|Nianchang Huang et.al.|[2511.16184](https://arxiv.org/abs/2511.16184)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Yi Yang et.al.|[2511.16175](https://arxiv.org/abs/2511.16175)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16169": "|**2025-11-20**|**UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea**|Zijian Wang et.al.|[2511.16169](https://arxiv.org/abs/2511.16169)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16166": "|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Zeting Liu et.al.|[2511.16166](https://arxiv.org/abs/2511.16166)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16160": "|**2025-11-20**|**Video2Layout: Recall and Reconstruct Metric-Grounded Cognitive Map for Spatial Reasoning**|Yibin Huang et.al.|[2511.16160](https://arxiv.org/abs/2511.16160)|**[link](https://huggingface.co/models/ybrrraway/V2LO-7B)**|\n", "2511.16158": "|**2025-11-20**|**MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics**|Lara Bergmann et.al.|[2511.16158](https://arxiv.org/abs/2511.16158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16149": "|**2025-11-20**|**Approximation rates of quantum neural networks for periodic functions via Jackson's inequality**|Ariel Neufeld et.al.|[2511.16149](https://arxiv.org/abs/2511.16149)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16139": "|**2025-11-20**|**Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints**|Yongnan Jin et.al.|[2511.16139](https://arxiv.org/abs/2511.16139)|**[link](https://huggingface.co/models/mingpinDZJ/Shanzhi-M1)**|\n", "2511.16137": "|**2025-11-20**|**Degradation-Aware Hierarchical Termination for Blind Quality Enhancement of Compressed Video**|Li Yu et.al.|[2511.16137](https://arxiv.org/abs/2511.16137)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16136": "|**2025-11-20**|**How Noise Benefits AI-generated Image Detection**|Jiazhen Yan et.al.|[2511.16136](https://arxiv.org/abs/2511.16136)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16110": "|**2025-11-20**|**Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models**|Yijun Yang et.al.|[2511.16110](https://arxiv.org/abs/2511.16110)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.17502": "|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen et.al.|[2511.17502](https://arxiv.org/abs/2511.17502)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.17496": "|**2025-11-21**|**MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments**|Zhiyu Huang et.al.|[2511.17496](https://arxiv.org/abs/2511.17496)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.17492": "|**2025-11-21**|**EvDiff: High Quality Video with an Event Camera**|Weilun Li et.al.|[2511.17492](https://arxiv.org/abs/2511.17492)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17484": "|**2025-11-21**|**Radar2Shape: 3D Shape Reconstruction from High-Frequency Radar using Multiresolution Signed Distance Functions**|Neel Sortur et.al.|[2511.17484](https://arxiv.org/abs/2511.17484)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17481": "|**2025-11-21**|**Counterfactual World Models via Digital Twin-conditioned Video Diffusion**|Yiqing Shen et.al.|[2511.17481](https://arxiv.org/abs/2511.17481)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.17441": "|**2025-11-21**|**RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation**|Shihan Wu et.al.|[2511.17441](https://arxiv.org/abs/2511.17441)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2511.17421": "|**2025-11-21**|**Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers**|Christopher Boland et.al.|[2511.17421](https://arxiv.org/abs/2511.17421)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17411": "|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Nikolay Nikolov et.al.|[2511.17411](https://arxiv.org/abs/2511.17411)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17400": "|**2025-11-21**|**Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?**|Sukwon Yun et.al.|[2511.17400](https://arxiv.org/abs/2511.17400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17384": "|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yifan Li et.al.|[2511.17384](https://arxiv.org/abs/2511.17384)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.17368": "|**2025-11-21**|**Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software**|Eric L. Melin et.al.|[2511.17368](https://arxiv.org/abs/2511.17368)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu et.al.|[2511.17366](https://arxiv.org/abs/2511.17366)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17353": "|**2025-11-21**|**Learning Latent Transmission and Glare Maps for Lens Veiling Glare Removal**|Xiaolong Qian et.al.|[2511.17353](https://arxiv.org/abs/2511.17353)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17304": "|**2025-11-21**|**Law-Strength Frontiers and a No-Free-Lunch Result for Law-Seeking Reinforcement Learning on Volatility Law Manifolds**|Jian'an Zhang et.al.|[2511.17304](https://arxiv.org/abs/2511.17304)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.17276": "|**2025-11-21**|**Leveraging CVAE for Joint Configuration Estimation of Multifingered Grippers from Point Cloud Data**|Julien Merand et.al.|[2511.17276](https://arxiv.org/abs/2511.17276)|**[link](https://github.com/RainbowNebula/robot-paper-daily)**|\n", "2511.17247": "|**2025-11-21**|**Signed Networks: theory, methods, and applications**|Fernando Diaz-Diaz et.al.|[2511.17247](https://arxiv.org/abs/2511.17247)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.17245": "|**2025-11-21**|**Simulated Annealing for Quadratic and Higher-Order Unconstrained Integer Optimization**|Kohei Suzuki et.al.|[2511.17245](https://arxiv.org/abs/2511.17245)|**[link](https://github.com/suruoxi/WorldModel-VLA-arxiv-daily)**|\n", "2511.17238": "|**2025-11-21**|**Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables**|Anshul Singh et.al.|[2511.17238](https://arxiv.org/abs/2511.17238)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17237": "|**2025-11-21**|**A ROS2 Interface for Universal Robots Collaborative Manipulators Based on ur_rtde**|Alessio Saccuti et.al.|[2511.17237](https://arxiv.org/abs/2511.17237)|**[link](https://github.com/SuperDiodo/ur_ros_rtde)**|\n", "2511.17235": "|**2025-11-21**|**NX-CGRA: A Programmable Hardware Accelerator for Core Transformer Algorithms on Edge Devices**|Rohit Prasad et.al.|[2511.17235](https://arxiv.org/abs/2511.17235)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17228": "|**2025-11-21**|**Intrinsic preservation of plasticity in continual quantum learning**|Yu-Qin Chen et.al.|[2511.17228](https://arxiv.org/abs/2511.17228)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17226": "|**2025-11-21**|**Randomness as Reference: Benchmark Metric for Optimization in Engineering**|Stefan Ivi\u0107 et.al.|[2511.17226](https://arxiv.org/abs/2511.17226)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17220": "|**2025-11-21**|**Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs**|Yusuf \u00c7elebi et.al.|[2511.17220](https://arxiv.org/abs/2511.17220)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17217": "|**2025-11-21**|**Dual-domain Adaptation Networks for Realistic Image Super-resolution**|Chaowei Fang et.al.|[2511.17217](https://arxiv.org/abs/2511.17217)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17199": "|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Hanyu Zhou et.al.|[2511.17199](https://arxiv.org/abs/2511.17199)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17196": "|**2025-11-21**|**Real Noise Decoupling for Hyperspectral Image Denoising**|Yingkai Zhang et.al.|[2511.17196](https://arxiv.org/abs/2511.17196)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17185": "|**2025-11-21**|**PostCam: Camera-Controllable Novel-View Video Generation with Query-Shared Cross-Attention**|Yipeng Chen et.al.|[2511.17185](https://arxiv.org/abs/2511.17185)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17184": "|**2025-11-21**|**Attention-Guided Feature Fusion (AGFF) Model for Integrating Statistical and Semantic Features in News Text Classification**|Mohammad Zare et.al.|[2511.17184](https://arxiv.org/abs/2511.17184)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17126": "|**2025-11-21**|**OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation**|Qi Jiang et.al.|[2511.17126](https://arxiv.org/abs/2511.17126)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17124": "|**2025-11-21**|**A Counterfactual LLM Framework for Detecting Human Biases: A Case Study of Sex/Gender in Emergency Triage**|Ariel Guerra-Adames et.al.|[2511.17124](https://arxiv.org/abs/2511.17124)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17102": "|**2025-11-21**|**KNN and Time Series Based Prediction of Power Generation from Renewable Resources**|Ismum Ul Hossain et.al.|[2511.17102](https://arxiv.org/abs/2511.17102)|**[link](https://github.com/Lionelsy/RSS)**|\n", "2511.17094": "|**2025-11-21**|**Sparse Reasoning is Enough: Biological-Inspired Framework for Video Anomaly Detection with Large Pre-trained Models**|He Huang et.al.|[2511.17094](https://arxiv.org/abs/2511.17094)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17079": "|**2025-11-21**|**H-GAR: A Hierarchical Interaction Framework via Goal-Driven Observation-Action Refinement for Robotic Manipulation**|Yijie Zhu et.al.|[2511.17079](https://arxiv.org/abs/2511.17079)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17071": "|**2025-11-21**|**Flexible unimodal density estimation in hidden Markov models**|Jan-Ole Koslik et.al.|[2511.17071](https://arxiv.org/abs/2511.17071)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.17069": "|**2025-11-21**|**Principled Design of Interpretable Automated Scoring for Large-Scale Educational Assessments**|Yunsung Kim et.al.|[2511.17069](https://arxiv.org/abs/2511.17069)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17059": "|**2025-11-21**|**REArtGS++: Generalizable Articulation Reconstruction with Temporal Geometry Constraint via Planar Gaussian Splatting**|Di Wu et.al.|[2511.17059](https://arxiv.org/abs/2511.17059)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17043": "|**2025-11-21**|**MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays**|Rama Krishna Boya et.al.|[2511.17043](https://arxiv.org/abs/2511.17043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17041": "|**2025-11-21**|**CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation**|Xiangrui Xiong et.al.|[2511.17041](https://arxiv.org/abs/2511.17041)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17036": "|**2025-11-21**|**Do Vision-Language Models Understand Visual Persuasiveness?**|Gyuwon Park et.al.|[2511.17036](https://arxiv.org/abs/2511.17036)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2511.17013": "|**2025-11-21**|**MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints**|Yiwen Ying et.al.|[2511.17013](https://arxiv.org/abs/2511.17013)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16993": "|**2025-11-21**|**DepthFocus: Controllable Depth Estimation for See-Through Scenes**|Junhong Min et.al.|[2511.16993](https://arxiv.org/abs/2511.16993)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16990": "|**2025-11-21**|**Senti-iFusion: An Integrity-centered Hierarchical Fusion Framework for Multimodal Sentiment Analysis under Uncertain Modality Missingness**|Liling Li et.al.|[2511.16990](https://arxiv.org/abs/2511.16990)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16937": "|**2025-11-21**|**OmniGround: A Comprehensive Spatio-Temporal Grounding Benchmark for Real-World Complex Scenarios**|Hong Gao et.al.|[2511.16937](https://arxiv.org/abs/2511.16937)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16931": "|**2025-11-21**|**OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists**|Chenyang Shao et.al.|[2511.16931](https://arxiv.org/abs/2511.16931)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16929": "|**2025-11-21**|**CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection**|Rui Xue et.al.|[2511.16929](https://arxiv.org/abs/2511.16929)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.16928": "|**2025-11-21**|**Rethinking Diffusion Model-Based Video Super-Resolution: Leveraging Dense Guidance from Aligned Features**|Jingyi Xu et.al.|[2511.16928](https://arxiv.org/abs/2511.16928)|**[link](https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion)**|\n", "2511.16901": "|**2025-11-21**|**R-AVST: Empowering Video-LLMs with Fine-Grained Spatio-Temporal Reasoning in Complex Audio-Visual Scenarios**|Lu Zhu et.al.|[2511.16901](https://arxiv.org/abs/2511.16901)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16897": "|**2025-11-21**|**Near-Optimal Dropout-Robust Sortition**|Maya Pal Gambhir et.al.|[2511.16897](https://arxiv.org/abs/2511.16897)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16887": "|**2025-11-21**|**Glass Surface Detection: Leveraging Reflection Dynamics in Flash/No-flash Imagery**|Tao Yan et.al.|[2511.16887](https://arxiv.org/abs/2511.16887)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16860": "|**2025-11-21**|**Parts-Mamba: Augmenting Joint Context with Part-Level Scanning for Occluded Human Skeleton**|Tianyi Shen et.al.|[2511.16860](https://arxiv.org/abs/2511.16860)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19435": "|**2025-11-24**|**Are Image-to-Video Models Good Zero-Shot Image Editors?**|Zechuan Zhang et.al.|[2511.19435](https://arxiv.org/abs/2511.19435)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19433": "|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Dong Jing et.al.|[2511.19433](https://arxiv.org/abs/2511.19433)|**[link](https://github.com/Timsty1/MixtureOfHorizons)**|\n", "2511.19431": "|**2025-11-24**|**Cloud4D**|Jacob Lin et.al.|[2511.19431](https://arxiv.org/abs/2511.19431)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19430": "|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Dingkang Liang et.al.|[2511.19430](https://arxiv.org/abs/2511.19430)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19427": "|**2025-11-24**|**Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering**|Jayanaka L. Dantanarayana et.al.|[2511.19427](https://arxiv.org/abs/2511.19427)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19388": "|**2025-11-24**|**Conformal symmetry of the massless Staruszkiewicz model**|A. Duviryak et.al.|[2511.19388](https://arxiv.org/abs/2511.19388)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19368": "|**2025-11-24**|**LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems**|Tianyang Duan et.al.|[2511.19368](https://arxiv.org/abs/2511.19368)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.19344": "|**2025-11-24**|**Annotation-Free Class-Incremental Learning**|Hari Chandana Kuchibhotla et.al.|[2511.19344](https://arxiv.org/abs/2511.19344)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19320": "|**2025-11-24**|**SteadyDancer: Harmonized and Coherent Human Image Animation with First-Frame Preservation**|Jiaming Zhang et.al.|[2511.19320](https://arxiv.org/abs/2511.19320)|**[link](https://huggingface.co/models/MCG-NJU/SteadyDancer-14B)**|\n", "2511.19319": "|**2025-11-24**|**SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis**|Lingwei Dang et.al.|[2511.19319](https://arxiv.org/abs/2511.19319)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19317": "|**2025-11-24**|**MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset**|Md. Tanzim Ferdous et.al.|[2511.19317](https://arxiv.org/abs/2511.19317)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19316": "|**2025-11-24**|**Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach**|Xincheng Wang et.al.|[2511.19316](https://arxiv.org/abs/2511.19316)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19315": "|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Weiliang Tang et.al.|[2511.19315](https://arxiv.org/abs/2511.19315)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19304": "|**2025-11-24**|**AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning**|Jiayi Zhang et.al.|[2511.19304](https://arxiv.org/abs/2511.19304)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19300": "|**2025-11-24**|**On Yukawa Potential Centrality for Identification of Influential Spreaders in Complex Networks**|Pouria Bazyarrezaei et.al.|[2511.19300](https://arxiv.org/abs/2511.19300)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19283": "|**2025-11-24**|**Data Flows and Colonial Regimes in Africa: A Critical Analysis of the Colonial Futurities Embedded in AI Ecosystems**|Ndaka. A et.al.|[2511.19283](https://arxiv.org/abs/2511.19283)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19279": "|**2025-11-24**|**MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings**|Victor Rambaud et.al.|[2511.19279](https://arxiv.org/abs/2511.19279)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19257": "|**2025-11-24**|**Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation**|Yingjia Shang et.al.|[2511.19257](https://arxiv.org/abs/2511.19257)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.19240": "|**2025-11-24**|**Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform**|Minxin Chen et.al.|[2511.19240](https://arxiv.org/abs/2511.19240)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19236": "|**2025-11-24**|**SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control**|Yuxuan Wang et.al.|[2511.19236](https://arxiv.org/abs/2511.19236)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19233": "|**2025-11-24**|**An O-RAN Framework for AI/ML-Based Localization with OpenAirInterface and FlexRIC**|Nada Bouknana et.al.|[2511.19233](https://arxiv.org/abs/2511.19233)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19229": "|**2025-11-24**|**Learning Plug-and-play Memory for Guiding Video Diffusion Models**|Selena Song et.al.|[2511.19229](https://arxiv.org/abs/2511.19229)|**[link](https://huggingface.co/models/Thrcle/DiT-Mem-1.3B)**|\n", "2511.19221": "|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Jianhua Han et.al.|[2511.19221](https://arxiv.org/abs/2511.19221)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19218": "|**2025-11-24**|**Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization**|Xurui Li et.al.|[2511.19218](https://arxiv.org/abs/2511.19218)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.19201": "|**2025-11-24**|**Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap**|Ann-Sophia M\u00fcller et.al.|[2511.19201](https://arxiv.org/abs/2511.19201)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2511.19199": "|**2025-11-24**|**CLASH: A Benchmark for Cross-Modal Contradiction Detection**|Teodora Popordanoska et.al.|[2511.19199](https://arxiv.org/abs/2511.19199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19176": "|**2025-11-24**|**From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation**|Jeeho Shin et.al.|[2511.19176](https://arxiv.org/abs/2511.19176)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19171": "|**2025-11-24**|**Can LLMs Threaten Human Survival? Benchmarking Potential Existential Threats from LLMs via Prefix Completion**|Yu Cui et.al.|[2511.19171](https://arxiv.org/abs/2511.19171)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.19170": "|**2025-11-24**|**Perplexity-Homophily Index: Homophily through Diversity in Hypergraphs**|Gaurav Kumar et.al.|[2511.19170](https://arxiv.org/abs/2511.19170)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19151": "|**2025-11-24**|**Modeling smooth and localized mortality patterns across age, time, and space to uncover small-area inequalities**|Jacob Martin et.al.|[2511.19151](https://arxiv.org/abs/2511.19151)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19150": "|**2025-11-24**|**Feature Ranking in Credit-Risk with Qudit-Based Networks**|Georgios Maragkopoulos et.al.|[2511.19150](https://arxiv.org/abs/2511.19150)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19143": "|**2025-11-24**|**Optimal policy design for innovation diffusion: shaping today's incentives for transforming the future**|Lisa Piccinin et.al.|[2511.19143](https://arxiv.org/abs/2511.19143)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19141": "|**2025-11-24**|**Automated RF Phase Adjustment for Beam Stabilization in the Fermilab Linac**|R. R. Chichili et.al.|[2511.19141](https://arxiv.org/abs/2511.19141)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19135": "|**2025-11-24**|**Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts**|Pascal Goldschmid et.al.|[2511.19135](https://arxiv.org/abs/2511.19135)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19134": "|**2025-11-24**|**MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery**|Shuyu Cao et.al.|[2511.19134](https://arxiv.org/abs/2511.19134)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19119": "|**2025-11-24**|**MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images**|Qirui Wang et.al.|[2511.19119](https://arxiv.org/abs/2511.19119)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19111": "|**2025-11-24**|**DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection**|Hai Ci et.al.|[2511.19111](https://arxiv.org/abs/2511.19111)|**[link](https://huggingface.co/datasets/Chaos2629/Diffseg30k)**|\n", "2511.19071": "|**2025-11-24**|**DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image Segmentation**|Fangda Chen et.al.|[2511.19071](https://arxiv.org/abs/2511.19071)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2511.19059": "|**2025-11-24**|**LLMAID: Identifying AI Capabilities in Android Apps with LLMs**|Pei Liu et.al.|[2511.19059](https://arxiv.org/abs/2511.19059)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19057": "|**2025-11-24**|**LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space**|Hai Wu et.al.|[2511.19057](https://arxiv.org/abs/2511.19057)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19055": "|**2025-11-24**|**Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study**|Xinda Zheng et.al.|[2511.19055](https://arxiv.org/abs/2511.19055)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19017": "|**2025-11-24**|**\"Don't Fall Behind\": A Unified Framework of Dynastic Survival, Two-Stage Belief Error, and the Modern Involution Trap**|Dong Yang et.al.|[2511.19017](https://arxiv.org/abs/2511.19017)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19005": "|**2025-11-24**|**Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding**|Di Wu et.al.|[2511.19005](https://arxiv.org/abs/2511.19005)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18989": "|**2025-11-24**|**Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning**|Wassim Benabbas et.al.|[2511.18989](https://arxiv.org/abs/2511.18989)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18983": "|**2025-11-24**|**UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection**|Ching-Yi Lai et.al.|[2511.18983](https://arxiv.org/abs/2511.18983)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18964": "|**2025-11-24**|**Synthesizing Visual Concepts as Vision-Language Programs**|Antonia W\u00fcst et.al.|[2511.18964](https://arxiv.org/abs/2511.18964)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18960": "|**2025-11-24**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Lei Xiao et.al.|[2511.18960](https://arxiv.org/abs/2511.18960)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18950": "|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Juntao Gao et.al.|[2511.18950](https://arxiv.org/abs/2511.18950)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18929": "|**2025-11-24**|**Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search**|Zijian Song et.al.|[2511.18929](https://arxiv.org/abs/2511.18929)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18922": "|**2025-11-24**|**One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control**|Zhenxing Mi et.al.|[2511.18922](https://arxiv.org/abs/2511.18922)|**[link](https://github.com/ALEEEHU/World-Simulator)**|\n", "2511.20648": "|**2025-11-25**|**LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight**|Yunze Man et.al.|[2511.20648](https://arxiv.org/abs/2511.20648)|null|\n", "2511.20641": "|**2025-11-25**|**Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition**|Wei Tang et.al.|[2511.20641](https://arxiv.org/abs/2511.20641)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Jiahui Zhang et.al.|[2511.20633](https://arxiv.org/abs/2511.20633)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20620": "|**2025-11-25**|**Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI**|Xinhao Liu et.al.|[2511.20620](https://arxiv.org/abs/2511.20620)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20616": "|**2025-11-25**|**Discovering Spatial Patterns of Readmission Risk Using a Bayesian Competing Risks Model with Spatially Varying Coefficients**|Yueming Shen et.al.|[2511.20616](https://arxiv.org/abs/2511.20616)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20613": "|**2025-11-25**|**Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning**|Panayiotis Danassis et.al.|[2511.20613](https://arxiv.org/abs/2511.20613)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20612": "|**2025-11-25**|**Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition**|Yujin Kim et.al.|[2511.20612](https://arxiv.org/abs/2511.20612)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20605": "|**2025-11-25**|**How to Purchase Labels? A Cost-Effective Approach Using Active Learning Markets**|Xiwen Huang et.al.|[2511.20605](https://arxiv.org/abs/2511.20605)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20597": "|**2025-11-25**|**BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents**|Kaiyuan Zhang et.al.|[2511.20597](https://arxiv.org/abs/2511.20597)|**[link](https://huggingface.co/models/perplexity-ai/browsesafe)**|\n", "2511.20586": "|**2025-11-25**|**PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic**|Koffi Ismael Ouattara et.al.|[2511.20586](https://arxiv.org/abs/2511.20586)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.20577": "|**2025-11-25**|**MSTN: Fast and Efficient Multivariate Time Series Model**|Sumit S Shevtekar et.al.|[2511.20577](https://arxiv.org/abs/2511.20577)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.20573": "|**2025-11-25**|**VQ-VA World: Towards High-Quality Visual Question-Visual Answering**|Chenhui Gou et.al.|[2511.20573](https://arxiv.org/abs/2511.20573)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20558": "|**2025-11-25**|**Spatio-Temporal Hierarchical Causal Models**|Xintong Li et.al.|[2511.20558](https://arxiv.org/abs/2511.20558)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20546": "|**2025-11-25**|**Modelling the Spread of Toxicity and Exploring its Mitigation on Online Social Networks**|Aatman Vaidya et.al.|[2511.20546](https://arxiv.org/abs/2511.20546)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20541": "|**2025-11-25**|**Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation**|Andrea Ranieri et.al.|[2511.20541](https://arxiv.org/abs/2511.20541)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20540": "|**2025-11-25**|**Proceedings Twentieth Conference on Theoretical Aspects of Rationality and Knowledge**|Adam Bjorndahl et.al.|[2511.20540](https://arxiv.org/abs/2511.20540)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20510": "|**2025-11-25**|**FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization**|Yuto Suzuki et.al.|[2511.20510](https://arxiv.org/abs/2511.20510)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20490": "|**2025-11-25**|**MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology**|Kiril Vasilev et.al.|[2511.20490](https://arxiv.org/abs/2511.20490)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20480": "|**2025-11-25**|**Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders**|Sidahmed Benabderrahmane et.al.|[2511.20480](https://arxiv.org/abs/2511.20480)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.20462": "|**2025-11-25**|**STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow**|Jiatao Gu et.al.|[2511.20462](https://arxiv.org/abs/2511.20462)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20456": "|**2025-11-25**|**Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks**|Shreevanth Krishnaa Gopalakrishnan et.al.|[2511.20456](https://arxiv.org/abs/2511.20456)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.20422": "|**2025-11-25**|**VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning**|Bo Pang et.al.|[2511.20422](https://arxiv.org/abs/2511.20422)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20415": "|**2025-11-25**|**MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts**|Zilong Huang et.al.|[2511.20415](https://arxiv.org/abs/2511.20415)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20359": "|**2025-11-25**|**From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations**|Zhiqing Guo et.al.|[2511.20359](https://arxiv.org/abs/2511.20359)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2511.20351": "|**2025-11-25**|**Thinking in 360\u00b0: Humanoid Visual Search in the Wild**|Heyang Yu et.al.|[2511.20351](https://arxiv.org/abs/2511.20351)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20325": "|**2025-11-25**|**AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models**|Tianyi Yan et.al.|[2511.20325](https://arxiv.org/abs/2511.20325)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20299": "|**2025-11-25**|**How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks**|R\u00f3is\u00edn Keenan et.al.|[2511.20299](https://arxiv.org/abs/2511.20299)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20297": "|**2025-11-25**|**Improving Language Agents through BREW**|Shashank Kirtania et.al.|[2511.20297](https://arxiv.org/abs/2511.20297)|**[link](https://github.com/TsinghuaC3I/Awesome-Memory-for-Agents)**|\n", "2511.20290": "|**2025-11-25**|**APT-CGLP: Advanced Persistent Threat Hunting via Contrastive Graph-Language Pre-Training**|Xuebo Qiu et.al.|[2511.20290](https://arxiv.org/abs/2511.20290)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20289": "|**2025-11-25**|**Lower Bias, Higher Welfare: How Creator Competition Reshapes Bias-Variance Tradeoff in Recommendation Platforms?**|Kang Wang et.al.|[2511.20289](https://arxiv.org/abs/2511.20289)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20285": "|**2025-11-25**|**SMoG: Schema Matching on Graph**|Mingyu Jeon et.al.|[2511.20285](https://arxiv.org/abs/2511.20285)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20280": "|**2025-11-25**|**Bootstrapping Physics-Grounded Video Generation through VLM-Guided Iterative Self-Refinement**|Yang Liu et.al.|[2511.20280](https://arxiv.org/abs/2511.20280)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20278": "|**2025-11-25**|**DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion**|Yinghui Li et.al.|[2511.20278](https://arxiv.org/abs/2511.20278)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20275": "|**2025-11-25**|**HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments**|Chenhui Dong et.al.|[2511.20275](https://arxiv.org/abs/2511.20275)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20274": "|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Advik Sinha et.al.|[2511.20274](https://arxiv.org/abs/2511.20274)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20272": "|**2025-11-25**|**VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs**|Tianxiang Jiang et.al.|[2511.20272](https://arxiv.org/abs/2511.20272)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20257": "|**2025-11-25**|**Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling**|Zhiguo Zhang et.al.|[2511.20257](https://arxiv.org/abs/2511.20257)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20253": "|**2025-11-25**|**Zoo3D: Zero-Shot 3D Object Detection at Scene Level**|Andrey Lemeshko et.al.|[2511.20253](https://arxiv.org/abs/2511.20253)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20250": "|**2025-11-25**|**Uplifting Table Tennis: A Robust, Real-World Application for 3D Trajectory and Spin Estimation**|Daniel Kienzle et.al.|[2511.20250](https://arxiv.org/abs/2511.20250)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.20245": "|**2025-11-25**|**HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers**|Jawaria Maqbool et.al.|[2511.20245](https://arxiv.org/abs/2511.20245)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20236": "|**2025-11-25**|**Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints**|Szymon Bobek et.al.|[2511.20236](https://arxiv.org/abs/2511.20236)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20233": "|**2025-11-25**|**REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance**|Chuyi Kong et.al.|[2511.20233](https://arxiv.org/abs/2511.20233)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20216": "|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Haebin Seong et.al.|[2511.20216](https://arxiv.org/abs/2511.20216)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20211": "|**2025-11-25**|**OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation**|Hao Yu et.al.|[2511.20211](https://arxiv.org/abs/2511.20211)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20193": "|**2025-11-25**|**Separating the Wheat from the Chaff: Understanding (In-)Completeness of Proof Mechanisms for Separation Logic with Inductive Definitions**|Neta Elad et.al.|[2511.20193](https://arxiv.org/abs/2511.20193)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20191": "|**2025-11-25**|**A Generalized Additive Partial-Mastery Cognitive Diagnosis Model**|Camilo C\u00e1rdenas-Hurtado et.al.|[2511.20191](https://arxiv.org/abs/2511.20191)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20177": "|**2025-11-25**|**Enhancing Sequential Recommendation with World Knowledge from Large Language Models**|Tianjie Dai et.al.|[2511.20177](https://arxiv.org/abs/2511.20177)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20170": "|**2025-11-25**|**AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks**|Bruno Belucci et.al.|[2511.20170](https://arxiv.org/abs/2511.20170)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20158": "|**2025-11-25**|**Harmonious Parameter Adaptation in Continual Visual Instruction Tuning for Safety-Aligned MLLMs**|Ziqi Wang et.al.|[2511.20158](https://arxiv.org/abs/2511.20158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20156": "|**2025-11-25**|**Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving**|Bin Hu et.al.|[2511.20156](https://arxiv.org/abs/2511.20156)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21690": "|**2025-11-26**|**TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos**|Seungjae Lee et.al.|[2511.21690](https://arxiv.org/abs/2511.21690)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.21668": "|**2025-11-26**|**Through the telecom lens: Are all training samples important?**|Shruti Bothe et.al.|[2511.21668](https://arxiv.org/abs/2511.21668)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21667": "|**2025-11-26**|**Escaping the Verifier: Learning to Reason via Demonstrations**|Locke Cai et.al.|[2511.21667](https://arxiv.org/abs/2511.21667)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.21666": "|**2025-11-26**|**Uncertainty Quantification for Visual Object Pose Estimation**|Lorenzo Shaikewitz et.al.|[2511.21666](https://arxiv.org/abs/2511.21666)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21652": "|**2025-11-26**|**Continual Error Correction on Low-Resource Devices**|Kirill Paramonov et.al.|[2511.21652](https://arxiv.org/abs/2511.21652)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21631": "|**2025-11-26**|**Qwen3-VL Technical Report**|Shuai Bai et.al.|[2511.21631](https://arxiv.org/abs/2511.21631)|**[link](https://github.com/QwenLM/Qwen3-VL)**|\n", "2511.21624": "|**2025-11-26**|**TAGFN: A Text-Attributed Graph Dataset for Fake News Detection in the Age of LLMs**|Kay Liu et.al.|[2511.21624](https://arxiv.org/abs/2511.21624)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Hui Zhou et.al.|[2511.21557](https://arxiv.org/abs/2511.21557)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan et.al.|[2511.21542](https://arxiv.org/abs/2511.21542)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21531": "|**2025-11-26**|**Predictive Safety Shield for Dyna-Q Reinforcement Learning**|Jin Pin et.al.|[2511.21531](https://arxiv.org/abs/2511.21531)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21519": "|**2025-11-26**|**Self-Paced Learning for Images of Antinuclear Antibodies**|Yiyang Jiang et.al.|[2511.21519](https://arxiv.org/abs/2511.21519)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21471": "|**2025-11-26**|**SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition**|Peiran Xu et.al.|[2511.21471](https://arxiv.org/abs/2511.21471)|**[link](https://huggingface.co/datasets/XPR2004/SpatialBench)**|\n", "2511.21465": "|**2025-11-26**|**Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams**|Enes Bektas et.al.|[2511.21465](https://arxiv.org/abs/2511.21465)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21460": "|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Junjian Wang et.al.|[2511.21460](https://arxiv.org/abs/2511.21460)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.21398": "|**2025-11-26**|**Prune4Web: DOM Tree Pruning Programming for Web Agent**|Jiayuan Zhang et.al.|[2511.21398](https://arxiv.org/abs/2511.21398)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.21395": "|**2025-11-26**|**Monet: Reasoning in Latent Visual Space Beyond Images and Language**|Qixun Wang et.al.|[2511.21395](https://arxiv.org/abs/2511.21395)|**[link](https://huggingface.co/models/NOVAglow646/Monet-7B)**|\n", "2511.21389": "|**2025-11-26**|**FITRep: Attention-Guided Item Representation via MLLMs**|Guoxiao Zhang et.al.|[2511.21389](https://arxiv.org/abs/2511.21389)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.21378": "|**2025-11-26**|**Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data**|Jungi Lee et.al.|[2511.21378](https://arxiv.org/abs/2511.21378)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21369": "|**2025-11-26**|**Differentiable Physics-Neural Models enable Learning of Non-Markovian Closures for Accelerated Coarse-Grained Physics Simulations**|Tingkai Xue et.al.|[2511.21369](https://arxiv.org/abs/2511.21369)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21366": "|**2025-11-26**|**Hybrid Control for Robotic Nut Tightening Task**|Dmitri Kovalenko et.al.|[2511.21366](https://arxiv.org/abs/2511.21366)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21365": "|**2025-11-26**|**PFF-Net: Patch Feature Fitting for Point Cloud Normal Estimation**|Qing Li et.al.|[2511.21365](https://arxiv.org/abs/2511.21365)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21350": "|**2025-11-26**|**Learning Multi-Order Block Structure in Higher-Order Networks**|Kazuki Nakajima et.al.|[2511.21350](https://arxiv.org/abs/2511.21350)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21312": "|**2025-11-26**|**Neural NMPC through Signed Distance Field Encoding for Collision Avoidance**|Martin Jacquet et.al.|[2511.21312](https://arxiv.org/abs/2511.21312)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21307": "|**2025-11-26**|**HIRE: A Hybrid Learned Index for Robust and Efficient Performance under Mixed Workloads**|Xinyi Zhang et.al.|[2511.21307](https://arxiv.org/abs/2511.21307)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21300": "|**2025-11-26**|**Data-Driven Reduction of Fault Location Errors in Onshore Wind Farm Collectors**|A. J. Alves Junior et.al.|[2511.21300](https://arxiv.org/abs/2511.21300)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21264": "|**2025-11-26**|**Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation**|Iryna Hurova et.al.|[2511.21264](https://arxiv.org/abs/2511.21264)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21263": "|**2025-11-26**|**Bifurcation Logic: Separation Through Ordering**|Didier Galmiche et.al.|[2511.21263](https://arxiv.org/abs/2511.21263)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21256": "|**2025-11-26**|**LaGen: Towards Autoregressive LiDAR Scene Generation**|Sizhuo Zhou et.al.|[2511.21256](https://arxiv.org/abs/2511.21256)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.21251": "|**2025-11-26**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|Shuhan Xia et.al.|[2511.21251](https://arxiv.org/abs/2511.21251)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21194": "|**2025-11-26**|**BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data**|Selene Cerna et.al.|[2511.21194](https://arxiv.org/abs/2511.21194)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21192": "|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu et.al.|[2511.21192](https://arxiv.org/abs/2511.21192)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.21180": "|**2025-11-26**|**CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion**|Shuhan Xia et.al.|[2511.21180](https://arxiv.org/abs/2511.21180)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.21169": "|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Kaiyan Xiao et.al.|[2511.21169](https://arxiv.org/abs/2511.21169)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.21161": "|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Xu Hu et.al.|[2511.21161](https://arxiv.org/abs/2511.21161)|**[link](https://github.com/hzxie/Awesome-3D-Scene-Generation)**|\n", "2511.21149": "|**2025-11-26**|**Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning**|Guoming Huang et.al.|[2511.21149](https://arxiv.org/abs/2511.21149)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Ziyi Chen et.al.|[2511.21135](https://arxiv.org/abs/2511.21135)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21124": "|**2025-11-26**|**Moonshine.jl: a Julia package for genome-scale model-based ancestral recombination graph inference**|Patrick Fournier et.al.|[2511.21124](https://arxiv.org/abs/2511.21124)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21097": "|**2025-11-26**|**CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition**|Geetanjali Sharma et.al.|[2511.21097](https://arxiv.org/abs/2511.21097)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21091": "|**2025-11-26**|**A Network Dynamical Systems Approach to SDGs**|Wuyang Zhang et.al.|[2511.21091](https://arxiv.org/abs/2511.21091)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21044": "|**2025-11-26**|**Human-Centered Artificial Social Intelligence (HC-ASI)**|Hanxi Pan et.al.|[2511.21044](https://arxiv.org/abs/2511.21044)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21032": "|**2025-11-26**|**A Probabilistic Framework for Temporal Distribution Generalization in Industry-Scale Recommender Systems**|Yuxuan Zhu et.al.|[2511.21032](https://arxiv.org/abs/2511.21032)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21029": "|**2025-11-26**|**FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation**|Kaixing Yang et.al.|[2511.21029](https://arxiv.org/abs/2511.21029)|**[link](https://github.com/XulongT/FlowerDance)**|\n", "2511.21016": "|**2025-11-26**|**Gated KalmaNet: A Fading Memory Layer Through Test-Time Ridge Regression**|Liangzu Peng et.al.|[2511.21016](https://arxiv.org/abs/2511.21016)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21001": "|**2025-11-26**|**Semiparametric Models for Practice Effects in Longitudinal Cognitive Trajectories: Application to an Aging Cohort Study**|Y. Xu et.al.|[2511.21001](https://arxiv.org/abs/2511.21001)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.20993": "|**2025-11-26**|**Subgoal Graph-Augmented Planning for LLM-Guided Open-World Reinforcement Learning**|Shanwei Fan et.al.|[2511.20993](https://arxiv.org/abs/2511.20993)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20976": "|**2025-11-26**|**AI4X Roadmap: Artificial Intelligence for the advancement of scientific pursuit and its future directions**|Stephen G. Dale et.al.|[2511.20976](https://arxiv.org/abs/2511.20976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20965": "|**2025-11-26**|**TrafficLens: Multi-Camera Traffic Video Analysis Using LLMs**|Md Adnan Arefeen et.al.|[2511.20965](https://arxiv.org/abs/2511.20965)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20941": "|**2025-11-26**|**Fusion of classical and quantum kernels enables accurate and robust two-sample tests**|Yu Terada et.al.|[2511.20941](https://arxiv.org/abs/2511.20941)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20937": "|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Qineng Wang et.al.|[2511.20937](https://arxiv.org/abs/2511.20937)|**[link](https://huggingface.co/datasets/MLL-Lab/ENACT)**|\n", "2511.20933": "|**2025-11-25**|**Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code**|Mootez Saad et.al.|[2511.20933](https://arxiv.org/abs/2511.20933)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23476": "|**2025-11-28**|**Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction**|Bao Shu et.al.|[2511.23476](https://arxiv.org/abs/2511.23476)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.23465": "|**2025-11-28**|**SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments**|Xinyi Li et.al.|[2511.23465](https://arxiv.org/abs/2511.23465)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.23455": "|**2025-11-28**|**The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference**|Hans Gundlach et.al.|[2511.23455](https://arxiv.org/abs/2511.23455)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23450": "|**2025-11-28**|**Object-Centric Data Synthesis for Category-level Object Detection**|Vikhyat Agarwal et.al.|[2511.23450](https://arxiv.org/abs/2511.23450)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2511.23436": "|**2025-11-28**|**Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent**|Jianzhe Lin et.al.|[2511.23436](https://arxiv.org/abs/2511.23436)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23429": "|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|Junshu Tang et.al.|[2511.23429](https://arxiv.org/abs/2511.23429)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.23428": "|**2025-11-28**|**DisMo: Disentangled Motion Representations for Open-World Motion Transfer**|Thomas Ressler-Antal et.al.|[2511.23428](https://arxiv.org/abs/2511.23428)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23371": "|**2025-11-28**|**Multilayer network science: theory, methods, and applications**|Alberto Aleta et.al.|[2511.23371](https://arxiv.org/abs/2511.23371)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23355": "|**2025-11-28**|**A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors**|Vinh Chau et.al.|[2511.23355](https://arxiv.org/abs/2511.23355)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23321": "|**2025-11-28**|**Chart2Code-MoLA: Efficient Multi-Modal Code Generation via Adaptive Expert Routing**|Yifei Wang et.al.|[2511.23321](https://arxiv.org/abs/2511.23321)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23300": "|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Yara Mahmoud et.al.|[2511.23300](https://arxiv.org/abs/2511.23300)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.23276": "|**2025-11-28**|**Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting**|Joongwon Chae et.al.|[2511.23276](https://arxiv.org/abs/2511.23276)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23274": "|**2025-11-28**|**Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI**|Georgia Kanli et.al.|[2511.23274](https://arxiv.org/abs/2511.23274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23264": "|**2025-11-28**|**BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning**|Ariful Islam et.al.|[2511.23264](https://arxiv.org/abs/2511.23264)|**[link](https://github.com/RifatHossaiN47/BanglaSentNet)**|\n", "2511.23260": "|**2025-11-28**|**Time Series Forecasting via Direct Per-Step Probability Distribution Modeling**|Linghao Kong et.al.|[2511.23260](https://arxiv.org/abs/2511.23260)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.23252": "|**2025-11-28**|**One-Shot Secure Aggregation: A Hybrid Cryptographic Protocol for Private Federated Learning in IoT**|Imraul Emmaka et.al.|[2511.23252](https://arxiv.org/abs/2511.23252)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23241": "|**2025-11-28**|**Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods**|Jose Moises Araya-Martinez et.al.|[2511.23241](https://arxiv.org/abs/2511.23241)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23238": "|**2025-11-28**|**SDE-Attention: Latent Attention in SDE-RNNs for Irregularly Sampled Time Series with Missing Data**|Yuting Fang et.al.|[2511.23238](https://arxiv.org/abs/2511.23238)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.23236": "|**2025-11-28**|**Incorporating Ephemeral Traffic Waves in A Data-Driven Framework for Microsimulation in CARLA**|Alex Richardson et.al.|[2511.23236](https://arxiv.org/abs/2511.23236)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23222": "|**2025-11-28**|**DAONet-YOLOv8: An Occlusion-Aware Dual-Attention Network for Tea Leaf Pest and Disease Detection**|Yefeng Wu et.al.|[2511.23222](https://arxiv.org/abs/2511.23222)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23213": "|**2025-11-28**|**GAPS: Guiding Dynamic Android Analysis with Static Path Synthesis**|Samuele Doria et.al.|[2511.23213](https://arxiv.org/abs/2511.23213)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23191": "|**2025-11-28**|**GeoWorld: Unlocking the Potential of Geometry Models to Facilitate High-Fidelity 3D Scene Generation**|Yuhao Wan et.al.|[2511.23191](https://arxiv.org/abs/2511.23191)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23186": "|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Runyu Jiao et.al.|[2511.23186](https://arxiv.org/abs/2511.23186)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23183": "|**2025-11-28**|**Identification of Malicious Posts on the Dark Web Using Supervised Machine Learning**|Sebasti\u00e3o Alves de Jesus Filho et.al.|[2511.23183](https://arxiv.org/abs/2511.23183)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23178": "|**2025-11-28**|**HPSU: A Benchmark for Human-Level Perception in Real-World Spoken Speech Understanding**|Chen Li et.al.|[2511.23178](https://arxiv.org/abs/2511.23178)|null|\n", "2511.23177": "|**2025-11-28**|**Data-Efficient Motor Condition Monitoring with Time Series Foundation Models**|Deyu Li et.al.|[2511.23177](https://arxiv.org/abs/2511.23177)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23069": "|**2025-11-28**|**Quantifying the Spatial and Demographic Scales of Segregation**|Rohit Sahasrabuddhe et.al.|[2511.23069](https://arxiv.org/abs/2511.23069)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23062": "|**2025-11-28**|**Development of a Load Profile Generator for Non-road Mobile Machinery**|Serhiy Kapustyan et.al.|[2511.23062](https://arxiv.org/abs/2511.23062)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.23059": "|**2025-11-28**|**Conveying Imagistic Thinking in TCM Translation: A Prompt Engineering and LLM-Based Evaluation Framework**|Jiatong Han et.al.|[2511.23059](https://arxiv.org/abs/2511.23059)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23034": "|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Zuolei Li et.al.|[2511.23034](https://arxiv.org/abs/2511.23034)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22978": "|**2025-11-28**|**ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?**|Huaixiao Tou et.al.|[2511.22978](https://arxiv.org/abs/2511.22978)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22973": "|**2025-11-28**|**BlockVid: Block Diffusion for High-Quality and Consistent Minute-Long Video Generation**|Zeyu Zhang et.al.|[2511.22973](https://arxiv.org/abs/2511.22973)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22963": "|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Zhirui Liu et.al.|[2511.22963](https://arxiv.org/abs/2511.22963)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2511.22935": "|**2025-11-28**|**EnECG: Efficient Ensemble Learning for Electrocardiogram Multi-task Foundation Model**|Yuhao Xu et.al.|[2511.22935](https://arxiv.org/abs/2511.22935)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22933": "|**2025-11-28**|**RAG-Empowered LLM-Driven Dynamic Radio Resource Management in Open 6G RAN**|Onur Salan et.al.|[2511.22933](https://arxiv.org/abs/2511.22933)|null|\n", "2511.22904": "|**2025-11-28**|**Language-conditioned world model improves policy generalization by reading environmental descriptions**|Anh Nguyen et.al.|[2511.22904](https://arxiv.org/abs/2511.22904)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.22887": "|**2025-11-28**|**Modeling Chaotic Pedestrian Behavior Using Chaos Indicators and Supervised Learning**|Md. Muhtashim Shahrier et.al.|[2511.22887](https://arxiv.org/abs/2511.22887)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22880": "|**2025-11-28**|**Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems**|Shashwat Jaiswal et.al.|[2511.22880](https://arxiv.org/abs/2511.22880)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22872": "|**2025-11-28**|**FedAU2: Attribute Unlearning for User-Level Federated Recommender Systems with Adaptive and Robust Adversarial Training**|Yuyuan Li et.al.|[2511.22872](https://arxiv.org/abs/2511.22872)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22862": "|**2025-11-28**|**Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation**|Jiacheng Li et.al.|[2511.22862](https://arxiv.org/abs/2511.22862)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22849": "|**2025-11-28**|**PerfMamba: Performance Analysis and Pruning of Selective State Space Models**|Abdullah Al Asif et.al.|[2511.22849](https://arxiv.org/abs/2511.22849)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22845": "|**2025-11-28**|**Embodied Intelligent Wireless (EIW): Synesthesia of Machines Empowered Wireless Communications**|Xiang Cheng et.al.|[2511.22845](https://arxiv.org/abs/2511.22845)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22832": "|**2025-11-28**|**Structured Multi-Step Reasoning for Entity Matching Using Large Language Model**|Rohan Bopardikar et.al.|[2511.22832](https://arxiv.org/abs/2511.22832)|null|\n", "2511.22815": "|**2025-11-28**|**Captain Safari: A World Engine**|Yu-Cheng Chou et.al.|[2511.22815](https://arxiv.org/abs/2511.22815)|null|\n", "2511.22810": "|**2025-11-27**|**Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation**|Dongjae Lee et.al.|[2511.22810](https://arxiv.org/abs/2511.22810)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.22787": "|**2025-11-27**|**World in a Frame: Understanding Culture Mixing as a New Challenge for Vision-Language Models**|Eunsu Kim et.al.|[2511.22787](https://arxiv.org/abs/2511.22787)|**[link](https://huggingface.co/datasets/EunsuKim/CultureMix)**|\n", "2511.22780": "|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Amir Rasouli et.al.|[2511.22780](https://arxiv.org/abs/2511.22780)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22777": "|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Sajjad Pakdamansavoji et.al.|[2511.22777](https://arxiv.org/abs/2511.22777)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22773": "|**2025-11-27**|**CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance**|Rui Heng Yang et.al.|[2511.22773](https://arxiv.org/abs/2511.22773)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22739": "|**2025-11-27**|**All Centers Are at most a Few Tokens Apart: Knowledge Distillation with Domain Invariant Prompt Tuning**|Amir Mohammad Ezzati et.al.|[2511.22739](https://arxiv.org/abs/2511.22739)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02020": "|**2025-12-01**|**EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI**|Jianlei Chang et.al.|[2512.02020](https://arxiv.org/abs/2512.02020)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02016": "|**2025-12-01**|**Objects in Generated Videos Are Slower Than They Appear: Models Suffer Sub-Earth Gravity and Don't Know Galileo's Principle...for now**|Varun Varma Thozhiyoor et.al.|[2512.02016](https://arxiv.org/abs/2512.02016)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02013": "|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Chenyang Gu et.al.|[2512.02013](https://arxiv.org/abs/2512.02013)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2512.02011": "|**2025-12-01**|**Learning Dexterous Manipulation Skills from Imperfect Simulations**|Elvis Hsieh et.al.|[2512.02011](https://arxiv.org/abs/2512.02011)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02009": "|**2025-12-01**|**AirSim360: A Panoramic Simulation Platform within Drone View**|Xian Ge et.al.|[2512.02009](https://arxiv.org/abs/2512.02009)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01989": "|**2025-12-01**|**PAI-Bench: A Comprehensive Benchmark For Physical AI**|Fengzhe Zhou et.al.|[2512.01989](https://arxiv.org/abs/2512.01989)|**[link](https://huggingface.co/spaces/shi-labs/physical-ai-bench-leaderboard)**|\n", "2512.01987": "|**2025-12-01**|**Forecasting in Offline Reinforcement Learning for Non-stationary Environments**|Suzan Ece Ada et.al.|[2512.01987](https://arxiv.org/abs/2512.01987)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.01979": "|**2025-12-01**|**Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback**|Aiden Yiliu Li et.al.|[2512.01979](https://arxiv.org/abs/2512.01979)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01977": "|**2025-12-01**|**AI-Driven Optimization under Uncertainty for Mineral Processing Operations**|William Xu et.al.|[2512.01977](https://arxiv.org/abs/2512.01977)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01960": "|**2025-12-01**|**SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation**|Zisu Li et.al.|[2512.01960](https://arxiv.org/abs/2512.01960)|**[link](https://github.com/SeanChenxy/Hand3DResearch)**|\n", "2512.01952": "|**2025-12-01**|**GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment**|Haoyang He et.al.|[2512.01952](https://arxiv.org/abs/2512.01952)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01946": "|**2025-12-01**|**Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models**|Paul Pacaud et.al.|[2512.01946](https://arxiv.org/abs/2512.01946)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01939": "|**2025-12-01**|**An Empirical Study of Agent Developer Practices in AI Agent Frameworks**|Yanlin Wang et.al.|[2512.01939](https://arxiv.org/abs/2512.01939)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01924": "|**2025-12-01**|**Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model**|Kentaro Fujii et.al.|[2512.01924](https://arxiv.org/abs/2512.01924)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01908": "|**2025-12-01**|**SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception**|Gurmeher Khurana et.al.|[2512.01908](https://arxiv.org/abs/2512.01908)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01895": "|**2025-12-01**|**StyleYourSmile: Cross-Domain Face Retargeting Without Paired Multi-Style Data**|Avirup Dey et.al.|[2512.01895](https://arxiv.org/abs/2512.01895)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01880": "|**2025-12-01**|**Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models**|Daren Zhong et.al.|[2512.01880](https://arxiv.org/abs/2512.01880)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01878": "|**2025-12-01**|**Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning**|Gaganpreet Jhajj et.al.|[2512.01878](https://arxiv.org/abs/2512.01878)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.01856": "|**2025-12-01**|**Is Image-based Object Pose Estimation Ready to Support Grasping?**|Eric C. Joyce et.al.|[2512.01856](https://arxiv.org/abs/2512.01856)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01843": "|**2025-12-01**|**PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models**|Zeqing Wang et.al.|[2512.01843](https://arxiv.org/abs/2512.01843)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01829": "|**2025-12-01**|**Delay Tolerant Networking to Extend Connectivity in Rural Areas Using Public Transport Systems: Design And Analysis**|Salah Abdeljabar et.al.|[2512.01829](https://arxiv.org/abs/2512.01829)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01821": "|**2025-12-01**|**Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling**|Meng Cao et.al.|[2512.01821](https://arxiv.org/abs/2512.01821)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01818": "|**2025-12-01**|**Forget Less, Retain More: A Lightweight Regularizer for Rehearsal-Based Continual Learning**|Lama Alssum et.al.|[2512.01818](https://arxiv.org/abs/2512.01818)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01816": "|**2025-12-01**|**Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights**|Juanxi Tian et.al.|[2512.01816](https://arxiv.org/abs/2512.01816)|**[link](https://huggingface.co/datasets/opendatalab-raiser/Envision)**|\n", "2512.01803": "|**2025-12-01**|**Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos**|Xavier Thomas et.al.|[2512.01803](https://arxiv.org/abs/2512.01803)|**[link](https://huggingface.co/datasets/dghadiya/TAG-Bench-Video)**|\n", "2512.01801": "|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yunfei Li et.al.|[2512.01801](https://arxiv.org/abs/2512.01801)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2512.01773": "|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Chenghao Gu et.al.|[2512.01773](https://arxiv.org/abs/2512.01773)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01723": "|**2025-12-01**|**Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation**|Saba Kublashvili et.al.|[2512.01723](https://arxiv.org/abs/2512.01723)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01715": "|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Wanpeng Zhang et.al.|[2512.01715](https://arxiv.org/abs/2512.01715)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01682": "|**2025-12-01**|**Current Challenges of Symbolic Regression: Optimization, Selection, Model Simplification, and Benchmarking**|Guilherme Seidyo Imai Aldeia et.al.|[2512.01682](https://arxiv.org/abs/2512.01682)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01681": "|**2025-12-01**|**Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies**|Farzaneh Seyedshahi et.al.|[2512.01681](https://arxiv.org/abs/2512.01681)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01677": "|**2025-12-01**|**Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation**|Haodong Yan et.al.|[2512.01677](https://arxiv.org/abs/2512.01677)|**[link](https://github.com/SeanChenxy/Hand3DResearch)**|\n", "2512.01675": "|**2025-12-01**|**GRASP: Guided Residual Adapters with Sample-wise Partitioning**|Felix N\u00fctzel et.al.|[2512.01675](https://arxiv.org/abs/2512.01675)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01639": "|**2025-12-01**|**Improved Disease Outbreak Detection from Out-of-sequence measurements Using Markov-switching Fixed-lag Particle Filters**|Conor Rosato et.al.|[2512.01639](https://arxiv.org/abs/2512.01639)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01629": "|**2025-12-01**|**SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge**|Yumeng He et.al.|[2512.01629](https://arxiv.org/abs/2512.01629)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01598": "|**2025-12-01**|**A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics**|Marek Vagas et.al.|[2512.01598](https://arxiv.org/abs/2512.01598)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01572": "|**2025-12-01**|**Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade**|Letian Yi et.al.|[2512.01572](https://arxiv.org/abs/2512.01572)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Fei Liu et.al.|[2512.01550](https://arxiv.org/abs/2512.01550)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01498": "|**2025-12-01**|**Winning Solutions for the Rayan AI Contest: Compositional Retrieval, Zero-Shot Anomaly Detection, and Backdoor Detection**|Ali Nafisi et.al.|[2512.01498](https://arxiv.org/abs/2512.01498)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2512.01497": "|**2025-12-01**|**Heuristic algorithms for the stochastic critical node detection problem**|Tuguldur Bayarsaikhan et.al.|[2512.01497](https://arxiv.org/abs/2512.01497)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01482": "|**2025-12-01**|**On robotic manipulators with time-dependent inertial parameters: From physical consistency to boundedness of the mass matrix**|Tom Kaufmann et.al.|[2512.01482](https://arxiv.org/abs/2512.01482)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01481": "|**2025-12-01**|**ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling**|Qisen Wang et.al.|[2512.01481](https://arxiv.org/abs/2512.01481)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01469": "|**2025-12-01**|**Forging a Developed India: Growth Imperatives, Fiscal Sustainability, and Multilateral Partnerships for Viksit Bharat 2047**|Supriya Sanjay Nikam et.al.|[2512.01469](https://arxiv.org/abs/2512.01469)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01465": "|**2025-12-01**|**A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data**|Hongnan Si et.al.|[2512.01465](https://arxiv.org/abs/2512.01465)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01456": "|**2025-12-01**|**The dual footprint of artificial intelligence: environmental and social impacts across the globe**|Paola Tubaro et.al.|[2512.01456](https://arxiv.org/abs/2512.01456)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01451": "|**2025-12-01**|**RadioPiT: Radio Map Generation with Pixel Transformer Driven by Ultra-Sparse Real-World Data**|Zeyao Sun et.al.|[2512.01451](https://arxiv.org/abs/2512.01451)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01446": "|**2025-12-01**|**$\\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering**|Jiayi Li et.al.|[2512.01446](https://arxiv.org/abs/2512.01446)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01440": "|**2025-12-01**|**A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale**|Sylvain Mari\u00e9 et.al.|[2512.01440](https://arxiv.org/abs/2512.01440)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01439": "|**2025-12-01**|**Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech**|Bharatdeep Hazarika et.al.|[2512.01439](https://arxiv.org/abs/2512.01439)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01438": "|**2025-12-01**|**Competition among seaports through Mean Field Games and real-world data**|Charles-Albert Lehalle et.al.|[2512.01438](https://arxiv.org/abs/2512.01438)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03044": "|**2025-12-02**|**Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling**|Yueru Jia et.al.|[2512.03044](https://arxiv.org/abs/2512.03044)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03036": "|**2025-12-02**|**ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation**|Mengchen Zhang et.al.|[2512.03036](https://arxiv.org/abs/2512.03036)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03021": "|**2025-12-02**|**Semiparametric Robust Estimation of Population Location**|Ananyabrata Barua et.al.|[2512.03021](https://arxiv.org/abs/2512.03021)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03000": "|**2025-12-03**|**DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling**|Kairun Wen et.al.|[2512.03000](https://arxiv.org/abs/2512.03000)|**[link](https://huggingface.co/datasets/kairunwen/DynamicVerse)**|\n", "2512.02983": "|**2025-12-02**|**ProteinPNet: Prototypical Part Networks for Concept Learning in Spatial Proteomics**|Louis McConnell et.al.|[2512.02983](https://arxiv.org/abs/2512.02983)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02982": "|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Xiang Xu et.al.|[2512.02982](https://arxiv.org/abs/2512.02982)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.02981": "|**2025-12-02**|**InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration**|Zhongyu Yang et.al.|[2512.02981](https://arxiv.org/abs/2512.02981)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02952": "|**2025-12-02**|**Layout Anything: One Transformer for Universal Room Layout Estimation**|Md Sohag Mia et.al.|[2512.02952](https://arxiv.org/abs/2512.02952)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02951": "|**2025-12-02**|**Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger**|Nicholas Baiata et.al.|[2512.02951](https://arxiv.org/abs/2512.02951)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.02942": "|**2025-12-02**|**Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench**|Lanxiang Hu et.al.|[2512.02942](https://arxiv.org/abs/2512.02942)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02924": "|**2025-12-02**|**AutoNeural: Co-Designing Vision-Language Models for NPU Inference**|Wei Chen et.al.|[2512.02924](https://arxiv.org/abs/2512.02924)|**[link](https://huggingface.co/models/NexaAI/AutoNeural)**|\n", "2512.02912": "|**2025-12-02**|**Hypothesis Testing for Generalized Thurstone Models**|Anuran Makur et.al.|[2512.02912](https://arxiv.org/abs/2512.02912)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02861": "|**2025-12-02**|**Network Self-Configuration based on Fine-Tuned Small Language Models**|Oscar G. Lira et.al.|[2512.02861](https://arxiv.org/abs/2512.02861)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02851": "|**2025-12-02**|**SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots**|Iana Zhura et.al.|[2512.02851](https://arxiv.org/abs/2512.02851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02844": "|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Xinzheng Wu et.al.|[2512.02844](https://arxiv.org/abs/2512.02844)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02841": "|**2025-12-02**|**Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages**|Lechen Zhang et.al.|[2512.02841](https://arxiv.org/abs/2512.02841)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02838": "|**2025-12-02**|**Experimental Blueprint for Distinguishing Decoherence from Objective Collapse**|Ridha Horchani et.al.|[2512.02838](https://arxiv.org/abs/2512.02838)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02824": "|**2025-12-02**|**Learning Science and the Illusion of Understanding: Exploring the Effects of Integrating Learning Tasks after Explainer Videos**|Madeleine H\u00f6rnlein et.al.|[2512.02824](https://arxiv.org/abs/2512.02824)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02820": "|**2025-12-02**|**Q-triplet characterization of atmospheric time series at Antofagasta: A missing values problem**|Hishan Farf\u00e1n-Bachiloglu et.al.|[2512.02820](https://arxiv.org/abs/2512.02820)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.02787": "|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng et.al.|[2512.02787](https://arxiv.org/abs/2512.02787)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02772": "|**2025-12-02**|**Towards Unification of Hallucination Detection and Fact Verification for Large Language Models**|Weihang Su et.al.|[2512.02772](https://arxiv.org/abs/2512.02772)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02768": "|**2025-12-02**|**Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements**|Hefei Gao et.al.|[2512.02768](https://arxiv.org/abs/2512.02768)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02743": "|**2025-12-02**|**Reasoning-Aware Multimodal Fusion for Hateful Video Detection**|Shuonan Yang et.al.|[2512.02743](https://arxiv.org/abs/2512.02743)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2512.02737": "|**2025-12-02**|**Beyond Paired Data: Self-Supervised UAV Geo-Localization from Reference Imagery Alone**|Tristan Amadei et.al.|[2512.02737](https://arxiv.org/abs/2512.02737)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02726": "|**2025-12-02**|**AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping**|Md Abdul Kadir et.al.|[2512.02726](https://arxiv.org/abs/2512.02726)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02711": "|**2025-12-02**|**CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer**|Lavish Bansal et.al.|[2512.02711](https://arxiv.org/abs/2512.02711)|**[link](https://huggingface.co/models/repelloai/CREST-Base)**|\n", "2512.02710": "|**2025-12-02**|**Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation**|Yuan Wang et.al.|[2512.02710](https://arxiv.org/abs/2512.02710)|**[link](https://github.com/mk-runner/Awesome-Radiology-Report-Generation)**|\n", "2512.02705": "|**2025-12-02**|**FGC-Comp: Adaptive Neighbor-Grouped Attribute Completion for Graph-based Anomaly Detection**|Junpeng Wu et.al.|[2512.02705](https://arxiv.org/abs/2512.02705)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2512.02696": "|**2025-12-02**|**ALDI-ray: Adapting the ALDI Framework for Security X-ray Object Detection**|Omid Reza Heidari et.al.|[2512.02696](https://arxiv.org/abs/2512.02696)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02686": "|**2025-12-02**|**ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data**|Yuxing Liu et.al.|[2512.02686](https://arxiv.org/abs/2512.02686)|null|\n", "2512.02685": "|**2025-12-02**|**Unsupervised Structural Scene Decomposition via Foreground-Aware Slot Attention with Pseudo-Mask Guidance**|Huankun Sheng et.al.|[2512.02685](https://arxiv.org/abs/2512.02685)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02657": "|**2025-12-02**|**Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models**|Naveen George et.al.|[2512.02657](https://arxiv.org/abs/2512.02657)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02654": "|**2025-12-02**|**Cybersecurity AI: The World's Top AI Agent for Security Capture-the-Flag (CTF)**|V\u00edctor Mayoral-Vilches et.al.|[2512.02654](https://arxiv.org/abs/2512.02654)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02624": "|**2025-12-02**|**PPTBench: Towards Holistic Evaluation of Large Language Models for PowerPoint Layout and Design Understanding**|Zheng Huang et.al.|[2512.02624](https://arxiv.org/abs/2512.02624)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02609": "|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Shengkai Wu et.al.|[2512.02609](https://arxiv.org/abs/2512.02609)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2512.02605": "|**2025-12-02**|**IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai**|Pengju Lu et.al.|[2512.02605](https://arxiv.org/abs/2512.02605)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02563": "|**2025-12-02**|**Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach**|Xiaotong Zhao et.al.|[2512.02563](https://arxiv.org/abs/2512.02563)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02552": "|**2025-12-02**|**What Signals Really Matter for Misinformation Tasks? Evaluating Fake-News Detection and Virality Prediction under Real-World Constraints**|Francesco Paolo Savatteri et.al.|[2512.02552](https://arxiv.org/abs/2512.02552)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02543": "|**2025-12-02**|**In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs**|Vishnu Sarukkai et.al.|[2512.02543](https://arxiv.org/abs/2512.02543)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02533": "|**2025-12-02**|**PopSim: Social Network Simulation for Social Media Popularity Prediction**|Yijun Liu et.al.|[2512.02533](https://arxiv.org/abs/2512.02533)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02528": "|**2025-12-02**|**Assessment of Simulation-based Inference Methods for Stochastic Compartmental Models**|Vincent Wieland et.al.|[2512.02528](https://arxiv.org/abs/2512.02528)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02519": "|**2025-12-02**|**Mean First Passage Time of the Symmetric Noisy Voter Model with Arbitrary Initial and Boundary Conditions**|Rytis Kazakevi\u010dius et.al.|[2512.02519](https://arxiv.org/abs/2512.02519)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02515": "|**2025-12-02**|**VibOmni: Towards Scalable Bone-conduction Speech Enhancement on Earables**|Lixing He et.al.|[2512.02515](https://arxiv.org/abs/2512.02515)|**[link](https://github.com/liutaocode/TTS-arxiv-daily)**|\n", "2512.02502": "|**2025-12-02**|**AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations**|Luyao Niu et.al.|[2512.02502](https://arxiv.org/abs/2512.02502)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02498": "|**2025-12-02**|**dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model**|Yumeng Li et.al.|[2512.02498](https://arxiv.org/abs/2512.02498)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02485": "|**2025-12-02**|**UCAgents: Unidirectional Convergence for Visual Evidence Anchored Multi-Agent Medical Decision-Making**|Qianhan Feng et.al.|[2512.02485](https://arxiv.org/abs/2512.02485)|**[link](https://github.com/AgenticHealthAI/Awesome-AI-Agents-for-Healthcare)**|\n", "2512.02483": "|**2025-12-02**|**Identifying preferred routes of sharing information on social networks**|Rozhin Mohammadikian et.al.|[2512.02483](https://arxiv.org/abs/2512.02483)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02473": "|**2025-12-02**|**WorldPack: Compressed Memory Improves Spatial Consistency in Video World Modeling**|Yuta Oshima et.al.|[2512.02473](https://arxiv.org/abs/2512.02473)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.02471": "|**2025-12-02**|**scCluBench: Comprehensive Benchmarking of Clustering Algorithms for Single-Cell RNA Sequencing**|Ping Xu et.al.|[2512.02471](https://arxiv.org/abs/2512.02471)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02468": "|**2025-12-02**|**Quantum Optimization in Wireless Communication Systems: Principles and Applications**|Ioannis Krikidis et.al.|[2512.02468](https://arxiv.org/abs/2512.02468)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04085": "|**2025-12-03**|**Unique Lives, Shared World: Learning from Single-Life Videos**|Tengda Han et.al.|[2512.04085](https://arxiv.org/abs/2512.04085)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04069": "|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Siyi Chen et.al.|[2512.04069](https://arxiv.org/abs/2512.04069)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2512.04040": "|**2025-12-03**|**RELIC: Interactive Video World Model with Long-Horizon Memory**|Yicong Hong et.al.|[2512.04040](https://arxiv.org/abs/2512.04040)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.04039": "|**2025-12-03**|**Fast & Efficient Normalizing Flows and Applications of Image Generative Models**|Sandeep Nagar et.al.|[2512.04039](https://arxiv.org/abs/2512.04039)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04007": "|**2025-12-03**|**On the Temporality for Sketch Representation Learning**|Marcelo Isaias de Moraes Junior et.al.|[2512.04007](https://arxiv.org/abs/2512.04007)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03992": "|**2025-12-03**|**DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation**|Zexin Lin et.al.|[2512.03992](https://arxiv.org/abs/2512.03992)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03981": "|**2025-12-03**|**DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment**|Sheng-Hao Liao et.al.|[2512.03981](https://arxiv.org/abs/2512.03981)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2512.03967": "|**2025-12-03**|**Technical Report on Text Dataset Distillation**|Keith Ando Ogawa et.al.|[2512.03967](https://arxiv.org/abs/2512.03967)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03937": "|**2025-12-03**|**DSP: A Statistically-Principled Structural Polarization Measure**|Giulia Preti et.al.|[2512.03937](https://arxiv.org/abs/2512.03937)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03932": "|**2025-12-03**|**Beyond the Ground Truth: Enhanced Supervision for Image Restoration**|Donghun Ryou et.al.|[2512.03932](https://arxiv.org/abs/2512.03932)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03874": "|**2025-12-03**|**OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance**|Lei Zhang et.al.|[2512.03874](https://arxiv.org/abs/2512.03874)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03847": "|**2025-12-03**|**DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training**|Dingwei Zhu et.al.|[2512.03847](https://arxiv.org/abs/2512.03847)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03838": "|**2025-12-03**|**Training and Evaluation of Guideline-Based Medical Reasoning in LLMs**|Michael Staniek et.al.|[2512.03838](https://arxiv.org/abs/2512.03838)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.03790": "|**2025-12-03**|**ExOAR: Expert-Guided Object and Activity Recognition from Textual Data**|Iris Beerepoot et.al.|[2512.03790](https://arxiv.org/abs/2512.03790)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03775": "|**2025-12-03**|**\"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale**|Biwei Yan et.al.|[2512.03775](https://arxiv.org/abs/2512.03775)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03746": "|**2025-12-03**|**Thinking with Programming Vision: Towards a Unified View for Thinking with Images**|Zirun Guo et.al.|[2512.03746](https://arxiv.org/abs/2512.03746)|**[link](https://github.com/ByteDance-BandAI/CodeVision)**|\n", "2512.03743": "|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Kehlani Fay et.al.|[2512.03743](https://arxiv.org/abs/2512.03743)|**[link](https://github.com/Yuxing-Wang-THU/SurveyBrainBody)**|\n", "2512.03737": "|**2025-12-03**|**AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation**|Chuyue Wang et.al.|[2512.03737](https://arxiv.org/abs/2512.03737)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03724": "|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Ziwen Li et.al.|[2512.03724](https://arxiv.org/abs/2512.03724)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03684": "|**2025-12-03**|**A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection**|Shahid Ansari et.al.|[2512.03684](https://arxiv.org/abs/2512.03684)|null|\n", "2512.03678": "|**2025-12-03**|**Feature-aware Modulation for Learning from Temporal Tabular Data**|Hao-Run Cai et.al.|[2512.03678](https://arxiv.org/abs/2512.03678)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03641": "|**2025-12-03**|**A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception**|B. R. Turner et.al.|[2512.03641](https://arxiv.org/abs/2512.03641)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03607": "|**2025-12-03**|**DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization**|Yusen Wu et.al.|[2512.03607](https://arxiv.org/abs/2512.03607)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03574": "|**2025-12-03**|**Global-Local Aware Scene Text Editing**|Fuxiang Yang et.al.|[2512.03574](https://arxiv.org/abs/2512.03574)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03558": "|**2025-12-03**|**CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding**|Huy Quang Ung et.al.|[2512.03558](https://arxiv.org/abs/2512.03558)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03556": "|**2025-12-03**|**RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL**|Yinzhou Tang et.al.|[2512.03556](https://arxiv.org/abs/2512.03556)|null|\n", "2512.03543": "|**2025-12-03**|**Parsimonious Factor Models for Asymmetric Dependence in Multivariate Extremes**|Pavel Krupskii et.al.|[2512.03543](https://arxiv.org/abs/2512.03543)|null|\n", "2512.03538": "|**2025-12-03**|**AdaPower: Specializing World Foundation Models for Predictive Manipulation**|Yuhang Huang et.al.|[2512.03538](https://arxiv.org/abs/2512.03538)|null|\n", "2512.03528": "|**2025-12-03**|**Multi-Agent Reinforcement Learning with Communication-Constrained Priors**|Guang Yang et.al.|[2512.03528](https://arxiv.org/abs/2512.03528)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03514": "|**2025-12-03**|**M3DR: Towards Universal Multilingual Multimodal Document Retrieval**|Adithya S Kolavi et.al.|[2512.03514](https://arxiv.org/abs/2512.03514)|**[link](https://huggingface.co/models/Cognitive-Lab/NetraEmbed)**|\n", "2512.03510": "|**2025-12-03**|**CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving**|Zhijian Qiao et.al.|[2512.03510](https://arxiv.org/abs/2512.03510)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03491": "|**2025-12-03**|**Modal Logical Neural Networks**|Antonin Sulc et.al.|[2512.03491](https://arxiv.org/abs/2512.03491)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03479": "|**2025-12-03**|**Towards Object-centric Understanding for Instructional Videos**|Wenliang Guo et.al.|[2512.03479](https://arxiv.org/abs/2512.03479)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03471": "|**2025-12-03**|**SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening**|Ian Henriques et.al.|[2512.03471](https://arxiv.org/abs/2512.03471)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03467": "|**2025-12-03**|**Bayesian Event-Based Model for Disease Subtype and Stage Inference**|Hongtao Hao et.al.|[2512.03467](https://arxiv.org/abs/2512.03467)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03460": "|**2025-12-03**|**Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study**|Johnny Peng et.al.|[2512.03460](https://arxiv.org/abs/2512.03460)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03454": "|**2025-12-03**|**Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles**|Haicheng Liao et.al.|[2512.03454](https://arxiv.org/abs/2512.03454)|null|\n", "2512.03444": "|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Davood Soleymanzadeh et.al.|[2512.03444](https://arxiv.org/abs/2512.03444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03429": "|**2025-12-03**|**World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations**|Raul Steinmetz et.al.|[2512.03429](https://arxiv.org/abs/2512.03429)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03428": "|**2025-12-03**|**GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test**|Ziyi Ding et.al.|[2512.03428](https://arxiv.org/abs/2512.03428)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03422": "|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Tianchen Deng et.al.|[2512.03422](https://arxiv.org/abs/2512.03422)|**[link](https://github.com/3D-Vision-World/awesome-NeRF-and-3DGS-SLAM)**|\n", "2512.03413": "|**2025-12-03**|**BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents**|Shu Wang et.al.|[2512.03413](https://arxiv.org/abs/2512.03413)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03400": "|**2025-12-03**|**Better World Models Can Lead to Better Post-Training Performance**|Prakhar Gupta et.al.|[2512.03400](https://arxiv.org/abs/2512.03400)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.03359": "|**2025-12-03**|**A Hybrid Deep Learning Framework with Explainable AI for Lung Cancer Classification with DenseNet169 and SVM**|Md Rashidul Islam et.al.|[2512.03359](https://arxiv.org/abs/2512.03359)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03350": "|**2025-12-03**|**SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation**|Yu Yuan et.al.|[2512.03350](https://arxiv.org/abs/2512.03350)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.03347": "|**2025-12-03**|**GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation**|William van den Bogert et.al.|[2512.03347](https://arxiv.org/abs/2512.03347)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03317": "|**2025-12-03**|**NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction**|Thomas Monninger et.al.|[2512.03317](https://arxiv.org/abs/2512.03317)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03308": "|**2025-12-02**|**Roman coronagraph simulations of exozodi observations in the presence of wavefront errors**|Jorge Llop-Sayson et.al.|[2512.03308](https://arxiv.org/abs/2512.03308)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03300": "|**2025-12-02**|**HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction**|Pengfei Hu et.al.|[2512.03300](https://arxiv.org/abs/2512.03300)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2512.03296": "|**2025-12-02**|**Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis**|Hsiao-Ying Lu et.al.|[2512.03296](https://arxiv.org/abs/2512.03296)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05115": "|**2025-12-04**|**Light-X: Generative 4D Video Rendering with Camera and Illumination Control**|Tianqi Liu et.al.|[2512.05115](https://arxiv.org/abs/2512.05115)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu et.al.|[2512.05107](https://arxiv.org/abs/2512.05107)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05103": "|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Xiaochuang Han et.al.|[2512.05103](https://arxiv.org/abs/2512.05103)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05089": "|**2025-12-04**|**The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception**|Eduardo Di Santi et.al.|[2512.05089](https://arxiv.org/abs/2512.05089)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05079": "|**2025-12-04**|**Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints**|Minghan Zhu et.al.|[2512.05079](https://arxiv.org/abs/2512.05079)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05076": "|**2025-12-04**|**BulletTime: Decoupled Control of Time and Camera Pose for Video Generation**|Yiming Wang et.al.|[2512.05076](https://arxiv.org/abs/2512.05076)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05066": "|**2025-12-04**|**Multi-LLM Collaboration for Medication Recommendation**|Huascar Sanchez et.al.|[2512.05066](https://arxiv.org/abs/2512.05066)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05049": "|**2025-12-04**|**QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory**|Yu-Chao Hsu et.al.|[2512.05049](https://arxiv.org/abs/2512.05049)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2512.05045": "|**2025-12-04**|**On random matrix statistics of 3d gravity**|Daniel L. Jafferis et.al.|[2512.05045](https://arxiv.org/abs/2512.05045)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04988": "|**2025-12-04**|**Strategic Self-Improvement for Competitive Agents in AI Labour Markets**|Christopher Chiu et.al.|[2512.04988](https://arxiv.org/abs/2512.04988)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04987": "|**2025-12-04**|**Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction**|Nex-AGI Team et.al.|[2512.04987](https://arxiv.org/abs/2512.04987)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04976": "|**2025-12-04**|**Multipole decomposition of the gravitational field of a point mass at the black hole horizon**|Jo\u00e3o P. B. Brito et.al.|[2512.04976](https://arxiv.org/abs/2512.04976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04969": "|**2025-12-04**|**Rethinking the Use of Vision Transformers for AI-Generated Image Detection**|NaHyeon Park et.al.|[2512.04969](https://arxiv.org/abs/2512.04969)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04960": "|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Jonne Van Haastregt et.al.|[2512.04960](https://arxiv.org/abs/2512.04960)|null|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Yicheng Liu et.al.|[2512.04952](https://arxiv.org/abs/2512.04952)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04945": "|**2025-12-04**|**TripleC Learning and Lightweight Speech Enhancement for Multi-Condition Target Speech Extraction**|Ziling Huang et.al.|[2512.04945](https://arxiv.org/abs/2512.04945)|null|\n", "2512.04885": "|**2025-12-04**|**Stability-Guaranteed Dual Kalman Filtering for Electrochemical Battery State Estimation**|Feng Guo et.al.|[2512.04885](https://arxiv.org/abs/2512.04885)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04884": "|**2025-12-04**|**Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation**|Tim Engelbracht et.al.|[2512.04884](https://arxiv.org/abs/2512.04884)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04883": "|**2025-12-04**|**SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms**|Jiawen Wen et.al.|[2512.04883](https://arxiv.org/abs/2512.04883)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04847": "|**2025-12-04**|**Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding**|Tsai-Ning Wang et.al.|[2512.04847](https://arxiv.org/abs/2512.04847)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04837": "|**2025-12-04**|**A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World**|Jikang Cheng et.al.|[2512.04837](https://arxiv.org/abs/2512.04837)|**[link](https://github.com/qiqitao77/Awesome-Comprehensive-Deepfake-Detection)**|\n", "2512.04831": "|**2025-12-04**|**Clustering country-level all-cause mortality data: a review**|Pedro Menezes de Araujo et.al.|[2512.04831](https://arxiv.org/abs/2512.04831)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04813": "|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Huanqian Wang et.al.|[2512.04813](https://arxiv.org/abs/2512.04813)|**[link](https://huggingface.co/datasets/BAAI/MOVE)**|\n", "2512.04800": "|**2025-12-04**|**Time-periodic solutions to an energy balance model coupled with an active fluid under arbitrary large forces**|Gianmarco Del Sarto et.al.|[2512.04800](https://arxiv.org/abs/2512.04800)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04797": "|**2025-12-04**|**SIMA 2: A Generalist Embodied Agent for Virtual Worlds**|SIMA team et.al.|[2512.04797](https://arxiv.org/abs/2512.04797)|null|\n", "2512.04793": "|**2025-12-04**|**YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases**|Gongyu Chen et.al.|[2512.04793](https://arxiv.org/abs/2512.04793)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04753": "|**2025-12-04**|**EtCon: Edit-then-Consolidate for Reliable Knowledge Editing**|Ruilin Li et.al.|[2512.04753](https://arxiv.org/abs/2512.04753)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Yihong Tang et.al.|[2512.04733](https://arxiv.org/abs/2512.04733)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04731": "|**2025-12-04**|**Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting**|Jian Tang et.al.|[2512.04731](https://arxiv.org/abs/2512.04731)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2512.04699": "|**2025-12-04**|**OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution**|Xinning Chai et.al.|[2512.04699](https://arxiv.org/abs/2512.04699)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang et.al.|[2512.04686](https://arxiv.org/abs/2512.04686)|**[link](https://huggingface.co/models/WangYipu2002/CroPond-3B)**|\n", "2512.04678": "|**2025-12-04**|**Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation**|Yunhong Lu et.al.|[2512.04678](https://arxiv.org/abs/2512.04678)|**[link](https://huggingface.co/models/JaydenLu666/Reward-Forcing-T2V-1.3B)**|\n", "2512.04617": "|**2025-12-04**|**Score Matching for Estimating Finite Point Processes**|Haoqun Cao et.al.|[2512.04617](https://arxiv.org/abs/2512.04617)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04596": "|**2025-12-04**|**QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction**|Guanchen Du et.al.|[2512.04596](https://arxiv.org/abs/2512.04596)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.04585": "|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Jingjing Li et.al.|[2512.04585](https://arxiv.org/abs/2512.04585)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2512.04580": "|**2025-12-04**|**A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution**|Huifeng Zhu et.al.|[2512.04580](https://arxiv.org/abs/2512.04580)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04579": "|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Hannes Homburger et.al.|[2512.04579](https://arxiv.org/abs/2512.04579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04571": "|**2025-12-04**|**Temp-SCONE: A Novel Out-of-Distribution Detection and Domain Generalization Framework for Wild Data with Temporal Shift**|Aditi Naiknaware et.al.|[2512.04571](https://arxiv.org/abs/2512.04571)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang et.al.|[2512.04537](https://arxiv.org/abs/2512.04537)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04535": "|**2025-12-04**|**GTM: Simulating the World of Tools for AI Agents**|Zhenzhen Ren et.al.|[2512.04535](https://arxiv.org/abs/2512.04535)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04530": "|**2025-12-04**|**Explainable Graph Representation Learning via Graph Pattern Analysis**|Xudong Wang et.al.|[2512.04530](https://arxiv.org/abs/2512.04530)|**[link](https://github.com/flyingdoog/awesome-graph-explainability-papers)**|\n", "2512.04528": "|**2025-12-04**|**Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification**|Chentao Shen et.al.|[2512.04528](https://arxiv.org/abs/2512.04528)|**[link](https://github.com/tomatoma00/Auto3R)**|\n", "2512.04515": "|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Liuzhou Zhang et.al.|[2512.04515](https://arxiv.org/abs/2512.04515)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04513": "|**2025-12-04**|**BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models**|Yu-Wei Zhan et.al.|[2512.04513](https://arxiv.org/abs/2512.04513)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.04480": "|**2025-12-04**|**AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions**|Pedro Passos et.al.|[2512.04480](https://arxiv.org/abs/2512.04480)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04474": "|**2025-12-04**|**LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models**|Jiaqi Sun et.al.|[2512.04474](https://arxiv.org/abs/2512.04474)|**[link](https://github.com/codefuse-ai/Awesome-Code-LLM)**|\n", "2512.04459": "|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Yingzi Ma et.al.|[2512.04459](https://arxiv.org/abs/2512.04459)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04456": "|**2025-12-04**|**GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis**|Changjin Kim et.al.|[2512.04456](https://arxiv.org/abs/2512.04456)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04451": "|**2025-12-04**|**StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios**|Yifei Wang et.al.|[2512.04451](https://arxiv.org/abs/2512.04451)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04446": "|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Chang Liu et.al.|[2512.04446](https://arxiv.org/abs/2512.04446)|null|\n", "2512.05964": "|**2025-12-05**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Kevin Black et.al.|[2512.05964](https://arxiv.org/abs/2512.05964)|**[link](https://github.com/Physical-Intelligence/real-time-chunking-kinetix)**|\n", "2512.05960": "|**2025-12-05**|**AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement**|Munsif Ali et.al.|[2512.05960](https://arxiv.org/abs/2512.05960)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05959": "|**2025-12-05**|**M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG**|David Anugraha et.al.|[2512.05959](https://arxiv.org/abs/2512.05959)|null|\n", "2512.05955": "|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Haowen Liu et.al.|[2512.05955](https://arxiv.org/abs/2512.05955)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05950": "|**2025-12-05**|**Impugan: Learning Conditional Generative Models for Robust Data Imputation**|Zalish Mahmud et.al.|[2512.05950](https://arxiv.org/abs/2512.05950)|null|\n", "2512.05940": "|**2025-12-05**|**Designing an Optimal Sensor Network via Minimizing Information Loss**|Daniel Waxman et.al.|[2512.05940](https://arxiv.org/abs/2512.05940)|null|\n", "2512.05937": "|**2025-12-05**|**Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception**|Anne Sielemann et.al.|[2512.05937](https://arxiv.org/abs/2512.05937)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05936": "|**2025-12-05**|**Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition**|Anne Sielemann et.al.|[2512.05936](https://arxiv.org/abs/2512.05936)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05933": "|**2025-12-05**|**Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech**|Xuanru Zhou et.al.|[2512.05933](https://arxiv.org/abs/2512.05933)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.05931": "|**2025-12-05**|**On the Bayes Inconsistency of Disagreement Discrepancy Surrogates**|Neil G. Marchant et.al.|[2512.05931](https://arxiv.org/abs/2512.05931)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2512.05927": "|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Zhiting Mei et.al.|[2512.05927](https://arxiv.org/abs/2512.05927)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.05907": "|**2025-12-05**|**From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation**|Abrar Hossain Mufakir Qamar Ansari Haziq Jeelani Monia Digra Fayeq Jeelani Syed et.al.|[2512.05907](https://arxiv.org/abs/2512.05907)|**[link](https://github.com/yanghlll/ArxivDaily-Haolin)**|\n", "2512.05899": "|**2025-12-05**|**Euclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data**|Euclid Collaboration et.al.|[2512.05899](https://arxiv.org/abs/2512.05899)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05893": "|**2025-12-05**|**NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process**|Neha Gupta et.al.|[2512.05893](https://arxiv.org/abs/2512.05893)|**[link](https://github.com/polyidoit/Arxiv-TQFT)**|\n", "2512.05889": "|**2025-12-05**|**The Effective Reproduction Number in the Kermack-McKendrick model with age of infection and reinfection**|Jiayi Li et.al.|[2512.05889](https://arxiv.org/abs/2512.05889)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05833": "|**2025-12-05**|**Vague Knowledge: Information without Transitivity and Partitions**|Kerry Xiao et.al.|[2512.05833](https://arxiv.org/abs/2512.05833)|null|\n", "2512.05809": "|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Saurav Jha et.al.|[2512.05809](https://arxiv.org/abs/2512.05809)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.05803": "|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Blanca Inigo et.al.|[2512.05803](https://arxiv.org/abs/2512.05803)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05764": "|**2025-12-05**|**Towards agent-based-model informed neural networks**|Nino Antulov-Fantulin et.al.|[2512.05764](https://arxiv.org/abs/2512.05764)|**[link](https://github.com/Aaron617/agent-arXiv-daily)**|\n", "2512.05721": "|**2025-12-05**|**BERTO: an Adaptive BERT-based Network Time Series Predictor with Operator Preferences in Natural Language**|Nitin Priyadarshini Shankar et.al.|[2512.05721](https://arxiv.org/abs/2512.05721)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05693": "|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Zhiying Du et.al.|[2512.05693](https://arxiv.org/abs/2512.05693)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05682": "|**2025-12-05**|**Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees**|Yiming Shu et.al.|[2512.05682](https://arxiv.org/abs/2512.05682)|**[link](https://github.com/wonderNefelibata/Awesome-LRM-Safety)**|\n", "2512.05677": "|**2025-12-05**|**Empirical Decision Theory**|Christoph Jansen et.al.|[2512.05677](https://arxiv.org/abs/2512.05677)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05675": "|**2025-12-05**|**Quantification of Errors of the Performance Estimators in the Linear-Quantized Precoding Models for Massive MIMO Systems**|Jie Zhang et.al.|[2512.05675](https://arxiv.org/abs/2512.05675)|**[link](https://github.com/polyidoit/Arxiv-Quantum)**|\n", "2512.05649": "|**2025-12-05**|**Physics-Guided Surrogate Modeling for Machine Learning-Driven DLD Design Optimization**|Khayrul Islam et.al.|[2512.05649](https://arxiv.org/abs/2512.05649)|**[link](https://github.com/Khayrulbuet13/dldml)**|\n", "2512.05599": "|**2025-12-05**|**An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation**|Panagiotis Giannikos et.al.|[2512.05599](https://arxiv.org/abs/2512.05599)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2512.05590": "|**2025-12-05**|**General and Domain-Specific Zero-shot Detection of Generated Images via Conditional Likelihood**|Roy Betser et.al.|[2512.05590](https://arxiv.org/abs/2512.05590)|null|\n", "2512.05585": "|**2025-12-05**|**Opportunities for Hybrid Modeling Approaches in Energy Systems optimization**|Mohamed Tahar Mabrouk et.al.|[2512.05585](https://arxiv.org/abs/2512.05585)|null|\n", "2512.05578": "|**2025-12-05**|**A Hyperspectral Imaging Guided Robotic Grasping System**|Zheng Sun et.al.|[2512.05578](https://arxiv.org/abs/2512.05578)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.05564": "|**2025-12-05**|**ProPhy: Progressive Physical Alignment for Dynamic World Simulation**|Zijun Wang et.al.|[2512.05564](https://arxiv.org/abs/2512.05564)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.05533": "|**2025-12-05**|**From Challenge to Change: Design Principles for AI Transformations**|Theocharis Tavantzis et.al.|[2512.05533](https://arxiv.org/abs/2512.05533)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05528": "|**2025-12-05**|**Decoding Selective Auditory Attention to Musical Elements in Ecologically Valid Music Listening**|Taketo Akama et.al.|[2512.05528](https://arxiv.org/abs/2512.05528)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05502": "|**2025-12-05**|**GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop**|Omid Bazgir et.al.|[2512.05502](https://arxiv.org/abs/2512.05502)|null|\n", "2512.05486": "|**2025-12-05**|**A new class of general linear method with inherent quadratic stability for solving stiff differential systems**|Sakshi Gautam et.al.|[2512.05486](https://arxiv.org/abs/2512.05486)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05469": "|**2025-12-05**|**How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data**|Zubair Ahmed Mohammad et.al.|[2512.05469](https://arxiv.org/abs/2512.05469)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05446": "|**2025-12-05**|**TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression**|Cheng-Yuan Ho et.al.|[2512.05446](https://arxiv.org/abs/2512.05446)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05428": "|**2025-12-05**|**Bita: A Conversational Assistant for Fairness Testing**|Keeryn Johnson et.al.|[2512.05428](https://arxiv.org/abs/2512.05428)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05399": "|**2025-12-05**|**Featurized-Decomposition Join: Low-Cost Semantic Joins with Guarantees**|Sepanta Zeighami et.al.|[2512.05399](https://arxiv.org/abs/2512.05399)|null|\n", "2512.05398": "|**2025-12-05**|**The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos**|Zhuoyuan Wu et.al.|[2512.05398](https://arxiv.org/abs/2512.05398)|null|\n", "2512.05361": "|**2025-12-05**|**FieldSeer I: Physics-Guided World Models for Long-Horizon Electromagnetic Dynamics under Partial Observability**|Ziheng Guo et.al.|[2512.05361](https://arxiv.org/abs/2512.05361)|null|\n", "2512.05332": "|**2025-12-05**|**Elevation- and Tilt-Aware Shadow Fading Correlation Modeling for UAV Communications**|Mushfiqur Rahman et.al.|[2512.05332](https://arxiv.org/abs/2512.05332)|null|\n", "2512.05329": "|**2025-12-05**|**CATNUS: Coordinate-Aware Thalamic Nuclei Segmentation Using T1-Weighted MRI**|Anqi Feng et.al.|[2512.05329](https://arxiv.org/abs/2512.05329)|**[link](https://github.com/liutaocode/Video-Generation-arxiv-daily)**|\n", "2512.05303": "|**2025-12-04**|**Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite**|Christian Westerdahl et.al.|[2512.05303](https://arxiv.org/abs/2512.05303)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05292": "|**2025-12-08**|**Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture**|Fan Zhang et.al.|[2512.05292](https://arxiv.org/abs/2512.05292)|null|\n", "2512.05288": "|**2025-12-04**|**Beyond Detection: A Comprehensive Benchmark and Study on Representation Learning for Fine-Grained Webshell Family Classification**|Feijiang Han et.al.|[2512.05288](https://arxiv.org/abs/2512.05288)|**[link](https://github.com/pstAmbition/DailyArXiv)**|\n", "2512.05272": "|**2025-12-04**|**Inferring Compositional 4D Scenes without Ever Seeing One**|Ahmet Berke Gokmen et.al.|[2512.05272](https://arxiv.org/abs/2512.05272)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05268": "|**2025-12-04**|**CARD: Correlation Aware Restoration with Diffusion**|Niki Nezakati et.al.|[2512.05268](https://arxiv.org/abs/2512.05268)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|\n", "2512.05254": "|**2025-12-04**|**When unlearning is free: leveraging low influence points to reduce computational costs**|Anat Kleiman et.al.|[2512.05254](https://arxiv.org/abs/2512.05254)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05242": "|**2025-12-04**|**Learning to Code with Context: A Study-Based Approach**|Uwe M. Borghoff et.al.|[2512.05242](https://arxiv.org/abs/2512.05242)|**[link](https://github.com/hhhh1138/my_arxiv_daily)**|\n", "2512.05226": "|**2025-12-04**|**Variance Matters: Improving Domain Adaptation via Stratified Sampling**|Andrea Napoli et.al.|[2512.05226](https://arxiv.org/abs/2512.05226)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.04441": "|**2025-12-08**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Bin Sun et.al.|[2512.04441](https://arxiv.org/abs/2512.04441)|null|\n", "2512.04399": "|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Haoqi Han et.al.|[2512.04399](https://arxiv.org/abs/2512.04399)|null|\n", "2512.04341": "|**2025-12-04**|**Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism**|Tianwei Ni et.al.|[2512.04341](https://arxiv.org/abs/2512.04341)|null|\n", "2512.04308": "|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Lei Zhang et.al.|[2512.04308](https://arxiv.org/abs/2512.04308)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04296": "|**2025-12-03**|**GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers**|Malyaban Bal et.al.|[2512.04296](https://arxiv.org/abs/2512.04296)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04279": "|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Feeza Khan Khanzada et.al.|[2512.04279](https://arxiv.org/abs/2512.04279)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04231": "|**2025-12-03**|**CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding**|Zhou Chen et.al.|[2512.04231](https://arxiv.org/abs/2512.04231)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02457": "|**2025-12-03**|**Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation**|Jianzong Wu et.al.|[2512.02457](https://arxiv.org/abs/2512.02457)|**[link](https://huggingface.co/datasets/jianzongwu/ALT-Merge)**|\n", "2512.02419": "|**2025-12-02**|**The brain-AI convergence: Predictive and generative world models for general-purpose computation**|Shogo Ohmae et.al.|[2512.02419](https://arxiv.org/abs/2512.02419)|null|\n", "2512.02417": "|**2025-12-02**|**Vehicle Dynamics Embedded World Models for Autonomous Driving**|Huiqian Li et.al.|[2512.02417](https://arxiv.org/abs/2512.02417)|null|\n", "2512.07821": "|**2025-12-08**|**WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling**|Shaoheng Fang et.al.|[2512.07821](https://arxiv.org/abs/2512.07821)|**[link](https://github.com/yanghlll/ArxivDaily-Haolin)**|\n", "2512.07777": "|**2025-12-08**|**Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?**|Karin de Langis et.al.|[2512.07777](https://arxiv.org/abs/2512.07777)|null|\n", "2512.07733": "|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Meng Cao et.al.|[2512.07733](https://arxiv.org/abs/2512.07733)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.07582": "|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Guangyan Chen et.al.|[2512.07582](https://arxiv.org/abs/2512.07582)|null|\n", "2512.07472": "|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Siyu Xu et.al.|[2512.07472](https://arxiv.org/abs/2512.07472)|null|\n", "2512.07437": "|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Chenwei Shi et.al.|[2512.07437](https://arxiv.org/abs/2512.07437)|null|\n", "2512.07394": "|**2025-12-08**|**Reconstructing Objects along Hand Interaction Timelines in Egocentric Video**|Zhifan Zhu et.al.|[2512.07394](https://arxiv.org/abs/2512.07394)|null|\n", "2512.07359": "|**2025-12-08**|**Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin**|Bin Zhao et.al.|[2512.07359](https://arxiv.org/abs/2512.07359)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Cheng Zhang et.al.|[2512.07237](https://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.07215": "|**2025-12-08**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Md Selim Sarowar et.al.|[2512.07215](https://arxiv.org/abs/2512.07215)|**[link](https://github.com/suruoxi/WorldModel-VLA-arxiv-daily)**|\n", "2512.07186": "|**2025-12-08**|**START: Spatial and Textual Learning for Chart Understanding**|Zhuoming Liu et.al.|[2512.07186](https://arxiv.org/abs/2512.07186)|null|\n", "2512.07032": "|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Runcong Wang et.al.|[2512.07032](https://arxiv.org/abs/2512.07032)|null|\n", "2512.06983": "|**2025-12-07**|**On Memory: A comparison of memory mechanisms in world models**|Eli J. Laird et.al.|[2512.06983](https://arxiv.org/abs/2512.06983)|null|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Yichao Shen et.al.|[2512.06963](https://arxiv.org/abs/2512.06963)|null|\n", "2512.06865": "|**2025-12-07**|**Spatial Retrieval Augmented Autonomous Driving**|Xiaosong Jia et.al.|[2512.06865](https://arxiv.org/abs/2512.06865)|**[link](https://huggingface.co/datasets/SpatialRetrievalAD/nuScenes-Geography-Data)**|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Ruicheng Zhang et.al.|[2512.06628](https://arxiv.org/abs/2512.06628)|null|\n", "2512.06563": "|**2025-12-06**|**Deep Manifold Part 2: Neural Network Mathematics**|Max Y. Ma et.al.|[2512.06563](https://arxiv.org/abs/2512.06563)|null|\n", "2512.06524": "|**2025-12-06**|**TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping**|Saekwang Nam et.al.|[2512.06524](https://arxiv.org/abs/2512.06524)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2512.06517": "|**2025-12-06**|**Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments**|Shifa Sulaiman et.al.|[2512.06517](https://arxiv.org/abs/2512.06517)|**[link](https://github.com/Lionelsy/RSS)**|\n", "2512.06038": "|**2025-12-04**|**Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction**|Kelsey Fontenot et.al.|[2512.06038](https://arxiv.org/abs/2512.06038)|null|\n"}, "Vision Language Action Model": {"2508.15201": "|**2025-11-13**|**Survey of Vision-Language-Action Models for Embodied Manipulation**|Haoran Li et.al.|[2508.15201](https://arxiv.org/abs/2508.15201)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.13446": "|**2025-08-19**|**CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models**|Catherine Glossop et.al.|[2508.13446](https://arxiv.org/abs/2508.13446)|**[link](https://huggingface.co/datasets/catglossop/CAST-dataset)**|\n", "2508.13073": "|**2025-09-01**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Rui Shao et.al.|[2508.13073](https://arxiv.org/abs/2508.13073)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.10333": "|**2025-08-14**|**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**|Wenxuan Song et.al.|[2508.10333](https://arxiv.org/abs/2508.10333)|**[link](https://huggingface.co/models/zzyzyzy/ReconVLA)**|\n", "2508.09071": "|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Lin Sun et.al.|[2508.09071](https://arxiv.org/abs/2508.09071)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.09032": "|**2025-08-12**|**Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding**|Maxim A. Patratskiy et.al.|[2508.09032](https://arxiv.org/abs/2508.09032)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2508.08189": "|**2025-08-14**|**Reinforcement Learning in Vision: A Survey**|Weijia Wu et.al.|[2508.08189](https://arxiv.org/abs/2508.08189)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2508.07770": "|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.07650": "|**2025-08-23**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Helong Huang et.al.|[2508.07650](https://arxiv.org/abs/2508.07650)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05342": "|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Shunlei Li et.al.|[2508.05342](https://arxiv.org/abs/2508.05342)|**[link](https://github.com/ChocoWu/Awesome-Scene-Graph-Generation)**|\n", "2508.05294": "|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06553": "|**2025-08-06**|**Static and Plugged: Make Embodied Evaluation Simple**|Jiahao Xiao et.al.|[2508.06553](https://arxiv.org/abs/2508.06553)|**[link](https://huggingface.co/datasets/xiaojiahao/StaticEmbodiedBench)**|\n", "2508.06547": "|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Heran Wu et.al.|[2508.06547](https://arxiv.org/abs/2508.06547)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02219": "|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|**[link](https://github.com/OpenHelix-Team/Awesome-VLA-RL)**|\n", "2508.02062": "|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2508.00097": "|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Zhigen Zhao et.al.|[2508.00097](https://arxiv.org/abs/2508.00097)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.23682": "|**2025-09-25**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Xiaoyu Chen et.al.|[2507.23682](https://arxiv.org/abs/2507.23682)|**[link](https://huggingface.co/models/microsoft/villa-x)**|\n", "2507.22424": "|**2025-09-20**|**Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance**|Songsheng Wang et.al.|[2507.22424](https://arxiv.org/abs/2507.22424)|**[link](https://github.com/hemingkx/SpeculativeDecodingPapers)**|\n", "2507.17383": "|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Thomas P Zollo et.al.|[2507.17383](https://arxiv.org/abs/2507.17383)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|\n", "2507.17294": "|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al.|[2507.17294](https://arxiv.org/abs/2507.17294)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.15597": "|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Hao Luo et.al.|[2507.15597](https://arxiv.org/abs/2507.15597)|**[link](https://huggingface.co/models/BeingBeyond/Being-H0)**|\n", "2507.14049": "|**2025-07-21**|**EdgeVLA: Efficient Vision-Language-Action Models**|Pawe\u0142 Budzianowski et.al.|[2507.14049](https://arxiv.org/abs/2507.14049)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2507.12440": "|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Ruihan Yang et.al.|[2507.12440](https://arxiv.org/abs/2507.12440)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.10672": "|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Muhayy Ud Din et.al.|[2507.10672](https://arxiv.org/abs/2507.10672)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2507.09160": "|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Jialei Huang et.al.|[2507.09160](https://arxiv.org/abs/2507.09160)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.06484": "|**2025-08-19**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Fan-Yun Sun et.al.|[2507.06484](https://arxiv.org/abs/2507.06484)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|\n", "2507.05227": "|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Qucheng Peng et.al.|[2507.05227](https://arxiv.org/abs/2507.05227)|**[link](https://github.com/runjtu/awesome-and-novel-works-in-slam)**|\n", "2507.04447": "|**2025-08-26**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Wenyao Zhang et.al.|[2507.04447](https://arxiv.org/abs/2507.04447)|**[link](https://huggingface.co/models/WenyaoZhang/DreamVLA)**|\n", "2507.01925": "|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yifan Zhong et.al.|[2507.01925](https://arxiv.org/abs/2507.01925)|**[link](https://github.com/TianxingChen/Embodied-AI-Guide)**|\n", "2507.01843": "|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Dmytro Kuzmenko et.al.|[2507.01843](https://arxiv.org/abs/2507.01843)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2507.01424": "|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Zhenyang Liu et.al.|[2507.01424](https://arxiv.org/abs/2507.01424)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|\n", "2507.01016": "|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Yating Wang et.al.|[2507.01016](https://arxiv.org/abs/2507.01016)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.00416": "|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Tao Lin et.al.|[2507.00416](https://arxiv.org/abs/2507.00416)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2506.24044": "|**2025-06-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Sicong Jiang et.al.|[2506.24044](https://arxiv.org/abs/2506.24044)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2506.19850": "|**2025-06-25**|**Unified Vision-Language-Action Model**|Yuqi Wang et.al.|[2506.19850](https://arxiv.org/abs/2506.19850)|**[link](https://huggingface.co/models/Yuqi1997/UniVLA)**|\n", "2506.17811": "|**2025-07-07**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Jacky Kwok et.al.|[2506.17811](https://arxiv.org/abs/2506.17811)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.17639": "|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Yuxuan Chen et.al.|[2506.17639](https://arxiv.org/abs/2506.17639)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2506.17561": "|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Chongkai Gao et.al.|[2506.17561](https://arxiv.org/abs/2506.17561)|**[link](https://huggingface.co/models/Linslab/VLA-OS)**|\n", "2506.16211": "|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Puhao Li et.al.|[2506.16211](https://arxiv.org/abs/2506.16211)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2506.14317": "|**2025-09-04**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Zeyuan Chen et.al.|[2506.14317](https://arxiv.org/abs/2506.14317)|**[link](https://github.com/YanjieZe/3D-Diffusion-Policy)**|\n", "2506.13757": "|**2025-11-07**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Zewei Zhou et.al.|[2506.13757](https://arxiv.org/abs/2506.13757)|**[link](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)**|\n", "2506.13725": "|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Wenxuan Song et.al.|[2506.13725](https://arxiv.org/abs/2506.13725)|**[link](https://huggingface.co/models/chenpyyy/openvla-ac)**|\n", "2506.13456": "|**2025-06-16**|**Block-wise Adaptive Caching for Accelerating Diffusion Policy**|Kangye Ji et.al.|[2506.13456](https://arxiv.org/abs/2506.13456)|**[link](https://github.com/xlite-dev/Awesome-DiT-Inference)**|\n", "2506.13045": "|**2025-08-24**|**Continual Learning for Generative AI: From LLMs to MLLMs and Beyond**|Haiyang Guo et.al.|[2506.13045](https://arxiv.org/abs/2506.13045)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2506.10826": "|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Wenxuan Song et.al.|[2506.10826](https://arxiv.org/abs/2506.10826)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2506.10100": "|**2025-06-13**|**EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models**|Yantai Yang et.al.|[2506.10100](https://arxiv.org/abs/2506.10100)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.09937": "|**2025-06-11**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Qiao Gu et.al.|[2506.09937](https://arxiv.org/abs/2506.09937)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2506.09930": "|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Irving Fang et.al.|[2506.09930](https://arxiv.org/abs/2506.09930)|**[link](https://huggingface.co/models/IPEC-COMMUNITY/spatialvla-4b-224-sft-bridge)**|\n", "2506.09172": "|**2025-06-17**|**An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Pranav Guruprasad et.al.|[2506.09172](https://arxiv.org/abs/2506.09172)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.08440": "|**2025-06-11**|**TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization**|Zengjue Chen et.al.|[2506.08440](https://arxiv.org/abs/2506.08440)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.16292": "|**2025-08-22**|**Do What? Teaching Vision-Language-Action Models to Reject the Impossible**|Wen-Han Hsieh et.al.|[2508.16292](https://arxiv.org/abs/2508.16292)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19236": "|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Hao Shi et.al.|[2508.19236](https://arxiv.org/abs/2508.19236)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19958": "|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Yiguo Fan et.al.|[2508.19958](https://arxiv.org/abs/2508.19958)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.19257": "|**2025-08-15**|**TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models**|Chenghao Liu et.al.|[2508.19257](https://arxiv.org/abs/2508.19257)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.21046": "|**2025-10-02**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Wei Li et.al.|[2508.21046](https://arxiv.org/abs/2508.21046)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.02055": "|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Yang Zhang et.al.|[2509.02055](https://arxiv.org/abs/2509.02055)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00328": "|**2025-08-30**|**Mechanistic interpretability for steering vision-language-action models**|Bear H\u00e4on et.al.|[2509.00328](https://arxiv.org/abs/2509.00328)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.06951": "|**2025-09-10**|**F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions**|Qi Lv et.al.|[2509.06951](https://arxiv.org/abs/2509.06951)|**[link](https://huggingface.co/models/InternRobotics/F1-VLA)**|\n", "2509.06932": "|**2025-09-11**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Yuqing Wen et.al.|[2509.06932](https://arxiv.org/abs/2509.06932)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.06819": "|**2025-09-08**|**CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation**|Daniel San Jos\u00e9 Pro et.al.|[2509.06819](https://arxiv.org/abs/2509.06819)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.05614": "|**2025-09-06**|**SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning**|Hanzhen Wang et.al.|[2509.05614](https://arxiv.org/abs/2509.05614)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.05578": "|**2025-09-06**|**OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision**|Ruixun Liu et.al.|[2509.05578](https://arxiv.org/abs/2509.05578)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.07962": "|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Zongzheng Zhang et.al.|[2509.07962](https://arxiv.org/abs/2509.07962)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.09372": "|**2025-09-22**|**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**|Yihao Wang et.al.|[2509.09372](https://arxiv.org/abs/2509.09372)|**[link](https://huggingface.co/models/VLA-Adapter/LIBERO-Long)**|\n", "2509.09090": "|**2025-09-11**|**SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models**|Hengyu Fang et.al.|[2509.09090](https://arxiv.org/abs/2509.09090)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11480": "|**2025-09-15**|**Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs**|Amir Taherin et.al.|[2509.11480](https://arxiv.org/abs/2509.11480)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.11417": "|**2025-09-18**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Shresth Grover et.al.|[2509.11417](https://arxiv.org/abs/2509.11417)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12594": "|**2025-09-21**|**The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning**|Titong Jiang et.al.|[2509.12594](https://arxiv.org/abs/2509.12594)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Ran Yang et.al.|[2509.14138](https://arxiv.org/abs/2509.14138)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14117": "|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Ali Abouzeid et.al.|[2509.14117](https://arxiv.org/abs/2509.14117)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11839": "|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Jiacheng Liu et.al.|[2509.11839](https://arxiv.org/abs/2509.11839)|**[link](https://huggingface.co/models/l2aggle/PPTmodel4UnitreeG1)**|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Tobias J\u00fclg et.al.|[2509.14932](https://arxiv.org/abs/2509.14932)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2509.14889": "|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Nan Sun et.al.|[2509.14889](https://arxiv.org/abs/2509.14889)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Hanqing Liu et.al.|[2509.18953](https://arxiv.org/abs/2509.18953)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Pengxiang Li et.al.|[2509.20109](https://arxiv.org/abs/2509.20109)|**[link](https://github.com/VILA-Lab/Awesome-DLMs)**|\n", "2509.19870": "|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Xin Wang et.al.|[2509.19870](https://arxiv.org/abs/2509.19870)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin et.al.|[2509.19571](https://arxiv.org/abs/2509.19571)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19480": "|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Noriaki Hirose et.al.|[2509.19480](https://arxiv.org/abs/2509.19480)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21243": "|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Jiyeon Koo et.al.|[2509.21243](https://arxiv.org/abs/2509.21243)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo et.al.|[2509.22643](https://arxiv.org/abs/2509.22643)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei et.al.|[2509.22093](https://arxiv.org/abs/2509.22093)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21986": "|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Tomoya Yoshida et.al.|[2509.21986](https://arxiv.org/abs/2509.21986)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25032": "|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Ryosuke Takanami et.al.|[2509.25032](https://arxiv.org/abs/2509.25032)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus et.al.|[2509.24768](https://arxiv.org/abs/2509.24768)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari et.al.|[2509.24559](https://arxiv.org/abs/2509.24559)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23931": "|**2025-10-05**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Hanshi Wang et.al.|[2509.23931](https://arxiv.org/abs/2509.23931)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian et.al.|[2509.23823](https://arxiv.org/abs/2509.23823)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas et.al.|[2509.23655](https://arxiv.org/abs/2509.23655)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.23121": "|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Shuai Li et.al.|[2509.23121](https://arxiv.org/abs/2509.23121)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu et.al.|[2509.26642](https://arxiv.org/abs/2509.26642)|**[link](https://huggingface.co/models/miniFranka/MLA_pretrain)**|\n", "2509.25966": "|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Peilong Han et.al.|[2509.25966](https://arxiv.org/abs/2509.25966)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25681": "|**2025-10-01**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Junjie Wen et.al.|[2509.25681](https://arxiv.org/abs/2509.25681)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2510.01711": "|**2025-10-13**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim et.al.|[2510.01711](https://arxiv.org/abs/2510.01711)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01642": "|**2025-10-27**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin et.al.|[2510.01642](https://arxiv.org/abs/2510.01642)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.01623": "|**2025-10-03**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Angen Ye et.al.|[2510.01623](https://arxiv.org/abs/2510.01623)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01389": "|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Ulas Berk Karli et.al.|[2510.01389](https://arxiv.org/abs/2510.01389)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00695": "|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo et.al.|[2510.00695](https://arxiv.org/abs/2510.00695)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00600": "|**2025-10-02**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia et.al.|[2510.00600](https://arxiv.org/abs/2510.00600)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.00037": "|**2025-10-15**|**On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations**|Jianing Guo et.al.|[2510.00037](https://arxiv.org/abs/2510.00037)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2510.04898": "|**2025-10-07**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Zheng Xiong et.al.|[2510.04898](https://arxiv.org/abs/2510.04898)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang et.al.|[2510.04246](https://arxiv.org/abs/2510.04246)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03827": "|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Xueyang Zhou et.al.|[2510.03827](https://arxiv.org/abs/2510.03827)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05681": "|**2025-10-07**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Suhyeok Jang et.al.|[2510.05681](https://arxiv.org/abs/2510.05681)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.07077": "|**2025-10-09**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka et.al.|[2510.07077](https://arxiv.org/abs/2510.07077)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2510.07730": "|**2025-10-09**|**DEAS: DEtached value learning with Action Sequence for Scalable Offline RL**|Changyeon Kim et.al.|[2510.07730](https://arxiv.org/abs/2510.07730)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09269": "|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Zirun Zhou et.al.|[2510.09269](https://arxiv.org/abs/2510.09269)|**[link](https://huggingface.co/datasets/ZZR42/BadLIBERO)**|\n", "2510.11027": "|**2025-10-14**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang et.al.|[2510.11027](https://arxiv.org/abs/2510.11027)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.10975": "|**2025-10-14**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Mingtong Dai et.al.|[2510.10975](https://arxiv.org/abs/2510.10975)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10932": "|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Zonghuan Xu et.al.|[2510.10932](https://arxiv.org/abs/2510.10932)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Jinliang Zheng et.al.|[2510.10274](https://arxiv.org/abs/2510.10274)|**[link](https://huggingface.co/models/2toINF/X-VLA-WidowX)**|\n", "2510.09976": "|**2025-10-11**|**Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models**|Mingyang Lyu et.al.|[2510.09976](https://arxiv.org/abs/2510.09976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12276": "|**2025-10-17**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li et.al.|[2510.12276](https://arxiv.org/abs/2510.12276)|**[link](https://huggingface.co/models/haofuly/spatial-forcing-7b-finetuned-libero-spatial)**|\n", "2510.13626": "|**2025-10-24**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei et.al.|[2510.13626](https://arxiv.org/abs/2510.13626)|**[link](https://huggingface.co/models/Sylvest/openvla-7b-oft-finetuned-libero-plus-mixdata)**|\n", "2510.13375": "|**2025-10-16**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Tianyuan Yuan et.al.|[2510.13375](https://arxiv.org/abs/2510.13375)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Haochuan Xu et.al.|[2510.13237](https://arxiv.org/abs/2510.13237)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal et.al.|[2510.13054](https://arxiv.org/abs/2510.13054)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.14902": "|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Han Zhao et.al.|[2510.14902](https://arxiv.org/abs/2510.14902)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14836": "|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Yixuan Li et.al.|[2510.14836](https://arxiv.org/abs/2510.14836)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15446": "|**2025-10-17**|**VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving**|Ziang Guo et.al.|[2510.15446](https://arxiv.org/abs/2510.15446)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Yuquan Xue et.al.|[2510.17640](https://arxiv.org/abs/2510.17640)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17439": "|**2025-10-21**|**From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors**|Zhengshen Zhang et.al.|[2510.17439](https://arxiv.org/abs/2510.17439)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.17369": "|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Haochen Su et.al.|[2510.17369](https://arxiv.org/abs/2510.17369)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17111": "|**2025-10-23**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan et.al.|[2510.17111](https://arxiv.org/abs/2510.17111)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ruihan Zhao et.al.|[2510.16617](https://arxiv.org/abs/2510.16617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16281": "|**2025-10-18**|**Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification**|Yilin Wu et.al.|[2510.16281](https://arxiv.org/abs/2510.16281)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16240": "|**2025-11-03**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden et.al.|[2510.16240](https://arxiv.org/abs/2510.16240)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang et.al.|[2510.18337](https://arxiv.org/abs/2510.18337)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19752": "|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Ameesh Shah et.al.|[2510.19752](https://arxiv.org/abs/2510.19752)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team et.al.|[2510.19430](https://arxiv.org/abs/2510.19430)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Mateo Guaman Castro et.al.|[2510.20818](https://arxiv.org/abs/2510.20818)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Qixiu Li et.al.|[2510.21571](https://arxiv.org/abs/2510.21571)|**[link](https://github.com/SeanChenxy/Hand3DResearch)**|\n", "2510.23576": "|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|Anqi Li et.al.|[2510.23576](https://arxiv.org/abs/2510.23576)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24161": "|**2025-10-28**|**BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Wentao Tan et.al.|[2510.24161](https://arxiv.org/abs/2510.24161)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25713": "|**2025-10-29**|**Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models**|Boshi An et.al.|[2510.25713](https://arxiv.org/abs/2510.25713)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24795": "|**2025-10-30**|**A Survey on Efficient Vision-Language-Action Models**|Zhaoshu Yu et.al.|[2510.24795](https://arxiv.org/abs/2510.24795)|**[link](https://github.com/zchoi/Awesome-Embodied-Robotics-and-Agent)**|\n", "2510.25889": "|**2025-10-29**|**$\u03c0_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Kang Chen et.al.|[2510.25889](https://arxiv.org/abs/2510.25889)|**[link](https://huggingface.co/models/RLinf/RLinf-Pi05-SFT)**|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|John Won et.al.|[2510.27607](https://arxiv.org/abs/2510.27607)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|Yanjie Ze et.al.|[2511.02832](https://arxiv.org/abs/2511.02832)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.02776": "|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Shichao Fan et.al.|[2511.02776](https://arxiv.org/abs/2511.02776)|**[link](https://github.com/chenin-wang/awesome_ai_paper)**|\n", "2511.01718": "|**2025-11-03**|**Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process**|Jiayi Chen et.al.|[2511.01718](https://arxiv.org/abs/2511.01718)|**[link](https://huggingface.co/models/chenpyyy/UD-VLA_CALVIN_ABCD_D)**|\n", "2511.01571": "|**2025-11-03**|**PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model**|Wenqi Liang et.al.|[2511.01571](https://arxiv.org/abs/2511.01571)|null|\n", "2511.01331": "|**2025-12-01**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Hongyin Zhang et.al.|[2511.01331](https://arxiv.org/abs/2511.01331)|null|\n", "2511.01224": "|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Chengmeng Li et.al.|[2511.01224](https://arxiv.org/abs/2511.01224)|null|\n", "2511.01210": "|**2025-11-06**|**OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation**|Heyu Guo et.al.|[2511.01210](https://arxiv.org/abs/2511.01210)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2511.00091": "|**2025-10-30**|**Self-Improving Vision-Language-Action Models with Data Generation via Residual RL**|Wenli Xiao et.al.|[2511.00091](https://arxiv.org/abs/2511.00091)|**[link](https://github.com/KevinGuo07/RoboMani-PaperList)**|\n", "2511.00088": "|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|NVIDIA et.al.|[2511.00088](https://arxiv.org/abs/2511.00088)|**[link](https://huggingface.co/models/nvidia/Alpamayo-R1-10B)**|\n", "2511.04555": "|**2025-12-05**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Tao Lin et.al.|[2511.04555](https://arxiv.org/abs/2511.04555)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2511.05491": "|**2025-11-07**|**Visual Spatial Tuning**|Rui Yang et.al.|[2511.05491](https://arxiv.org/abs/2511.05491)|**[link](https://huggingface.co/models/rayruiyang/VST-3B-RL)**|\n", "2511.05397": "|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samarth Chopra et.al.|[2511.05397](https://arxiv.org/abs/2511.05397)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05275": "|**2025-11-07**|**TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models**|Hokyun Im et.al.|[2511.05275](https://arxiv.org/abs/2511.05275)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2511.06202": "|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Shahram Najam Syed et.al.|[2511.06202](https://arxiv.org/abs/2511.06202)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.05936": "|**2025-11-08**|**10 Open Challenges Steering the Future of Vision-Language-Action Models**|Soujanya Poria et.al.|[2511.05936](https://arxiv.org/abs/2511.05936)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2506.05667": "|**2025-09-29**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Yuhan Hao et.al.|[2506.05667](https://arxiv.org/abs/2506.05667)|**[link](https://github.com/patrick-llgc/Learning-Deep-Learning)**|\n", "2403.09631": "|**2024-03-15**|**3D-VLA: A 3D Vision-Language-Action Generative World Model**|Haoyu Zhen et.al.|[2403.09631](https://arxiv.org/abs/2403.09631)|**[link](https://github.com/showlab/Awesome-Video-Diffusion)**|\n", "2503.10631": "|**2025-06-24**|**HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model**|Jiaming Liu et.al.|[2503.10631](https://arxiv.org/abs/2503.10631)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.02917": "|**2025-08-06**|**Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces**|Vebj\u00f8rn Haug K\u00e5sene et.al.|[2508.02917](https://arxiv.org/abs/2508.02917)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.21586": "|**2025-08-08**|**Can Vision Language Models Understand Mimed Actions?**|Hyundong Cho et.al.|[2506.21586](https://arxiv.org/abs/2506.21586)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2411.17465": "|**2024-11-27**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465](https://arxiv.org/abs/2411.17465)|**[link](https://huggingface.co/spaces/showlab/ShowUI)**|\n", "2411.19650": "|**2024-12-02**|**CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation**|Qixiu Li et.al.|[2411.19650](https://arxiv.org/abs/2411.19650)|**[link](https://huggingface.co/models/CogACT/CogACT-Base)**|\n", "2502.19645": "|**2025-04-29**|**Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success**|Moo Jin Kim et.al.|[2502.19645](https://arxiv.org/abs/2502.19645)|**[link](https://huggingface.co/models/moojink/openvla-7b-oft-finetuned-libero-spatial)**|\n", "2505.16278": "|**2025-05-23**|**DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**|Zhenjie Yang et.al.|[2505.16278](https://arxiv.org/abs/2505.16278)|**[link](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)**|\n", "2406.04339": "|**2024-12-17**|**RoboMamba: Efficient Vision-Language-Action Model for Robotic Reasoning and Manipulation**|Jiaming Liu et.al.|[2406.04339](https://arxiv.org/abs/2406.04339)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|\n", "2502.06851": "|**2025-06-03**|**Survey on Vision-Language-Action Models**|Adilzhan Adilkhanov et.al.|[2502.06851](https://arxiv.org/abs/2502.06851)|**[link](https://github.com/TianxingChen/Embodied-AI-Guide)**|\n", "2505.05540": "|**2025-06-18**|**Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments**|Pranav Guruprasad et.al.|[2505.05540](https://arxiv.org/abs/2505.05540)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2412.04453": "|**2025-02-18**|**NaVILA: Legged Robot Vision-Language-Action Model for Navigation**|An-Chieh Cheng et.al.|[2412.04453](https://arxiv.org/abs/2412.04453)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2407.14834": "|**2024-07-23**|**Can VLMs be used on videos for action recognition? LLMs are Visual Reasoning Coordinators**|Harsh Lunia et.al.|[2407.14834](https://arxiv.org/abs/2407.14834)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2503.22020": "|**2025-03-31**|**CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models**|Qingqing Zhao et.al.|[2503.22020](https://arxiv.org/abs/2503.22020)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2505.04769": "|**2025-05-09**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Ranjan Sapkota et.al.|[2505.04769](https://arxiv.org/abs/2505.04769)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.09607": "|**2025-10-20**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong et.al.|[2510.09607](https://arxiv.org/abs/2510.09607)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2405.17418": "|**2025-03-20**|**A Self-Correcting Vision-Language-Action Model for Fast and Slow System Manipulation**|Chenxuan Li et.al.|[2405.17418](https://arxiv.org/abs/2405.17418)|**[link](https://github.com/AoqunJin/Awesome-VLA-Post-Training)**|\n", "2411.05821": "|**2024-12-10**|**Benchmarking Vision, Language, & Action Models on Robotic Learning Tasks**|Pranav Guruprasad et.al.|[2411.05821](https://arxiv.org/abs/2411.05821)|**[link](https://github.com/alopatenko/LLMEvaluation)**|\n", "2503.23463": "|**2025-04-01**|**OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model**|Xingcheng Zhou et.al.|[2503.23463](https://arxiv.org/abs/2503.23463)|**[link](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)**|\n", "1911.12377": "|**2021-08-02**|**Multimodal Attention Networks for Low-Level Vision-and-Language Navigation**|Federico Landi et.al.|[1911.12377](https://arxiv.org/abs/1911.12377)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.05695": "|**2025-09-09**|**Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization**|Jingwei Peng et.al.|[2509.05695](https://arxiv.org/abs/2509.05695)|null|\n", "2505.01713": "|**2025-05-06**|**Vision and Intention Boost Large Language Model in Long-Term Action Anticipation**|Congqi Cao et.al.|[2505.01713](https://arxiv.org/abs/2505.01713)|null|\n", "2302.12610": "|**2024-11-01**|**A Joint Modeling of Vision-Language-Action for Target-oriented Grasping in Clutter**|Kechun Xu et.al.|[2302.12610](https://arxiv.org/abs/2302.12610)|**[link](https://github.com/rhett-chen/Robotic-grasping-papers)**|\n", "2503.03734": "|**2025-03-27**|**OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction**|Huang Huang et.al.|[2503.03734](https://arxiv.org/abs/2503.03734)|**[link](https://huggingface.co/datasets/mlfu7/pi0_conversion)**|\n", "2406.07549": "|**2024-06-14**|**A3VLM: Actionable Articulation-Aware Vision Language Model**|Siyuan Huang et.al.|[2406.07549](https://arxiv.org/abs/2406.07549)|**[link](https://github.com/GT-RIPL/Awesome-LLM-Robotics)**|\n", "2307.15818": "|**2023-08-01**|**RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control**|Anthony Brohan et.al.|[2307.15818](https://arxiv.org/abs/2307.15818)|**[link](https://github.com/GT-RIPL/Awesome-LLM-Robotics)**|\n", "2510.23190": "|**2025-10-28**|**Evaluation of Vision-LLMs in Surveillance Video**|Pascal Benschop et.al.|[2510.23190](https://arxiv.org/abs/2510.23190)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2506.00411": "|**2025-06-03**|**LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks**|Yi Yang et.al.|[2506.00411](https://arxiv.org/abs/2506.00411)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2504.10458": "|**2025-10-02**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Run Luo et.al.|[2504.10458](https://arxiv.org/abs/2504.10458)|**[link](https://huggingface.co/models/ritzzai/GUI-R1)**|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel et.al.|[2511.10615](https://arxiv.org/abs/2511.10615)|null|\n", "2511.10560": "|**2025-11-14**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer**|Haosong Peng et.al.|[2511.10560](https://arxiv.org/abs/2511.10560)|**[link](https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence)**|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Wei Li et.al.|[2511.10518](https://arxiv.org/abs/2511.10518)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10254": "|**2025-11-13**|**Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis**|Jiulong Wu et.al.|[2511.10254](https://arxiv.org/abs/2511.10254)|**[link](https://huggingface.co/datasets/QBiscuits/FEA-20K)**|\n", "2511.10091": "|**2025-11-13**|**SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition**|Qilang Ye et.al.|[2511.10091](https://arxiv.org/abs/2511.10091)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10008": "|**2025-11-13**|**Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks**|Xuancun Lu et.al.|[2511.10008](https://arxiv.org/abs/2511.10008)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09958": "|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Xiangyi Wei et.al.|[2511.09958](https://arxiv.org/abs/2511.09958)|null|\n", "2511.09516": "|**2025-11-12**|**MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation**|Runhao Li et.al.|[2511.09516](https://arxiv.org/abs/2511.09516)|**[link](https://github.com/avanturist322/awesome-memory-vla)**|\n", "2511.09515": "|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Fangqi Zhu et.al.|[2511.09515](https://arxiv.org/abs/2511.09515)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.08942": "|**2025-11-12**|**Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning**|Mobin Habibpour et.al.|[2511.08942](https://arxiv.org/abs/2511.08942)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08892": "|**2025-11-12**|**Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds**|Weihao Tan et.al.|[2511.08892](https://arxiv.org/abs/2511.08892)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.07820": "|**2025-11-11**|**SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control**|Zhengyi Luo et.al.|[2511.07820](https://arxiv.org/abs/2511.07820)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.07732": "|**2025-11-11**|**ViPRA: Video Prediction for Robot Actions**|Sandeep Routray et.al.|[2511.07732](https://arxiv.org/abs/2511.07732)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.07727": "|**2025-11-11**|**LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models**|Xiaohan Zhang et.al.|[2511.07727](https://arxiv.org/abs/2511.07727)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.06619": "|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Chuheng Zhang et.al.|[2511.06619](https://arxiv.org/abs/2511.06619)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.06182": "|**2025-11-09**|**OpenVLN: Open-world aerial Vision-Language Navigation**|Peican Lin et.al.|[2511.06182](https://arxiv.org/abs/2511.06182)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05923": "|**2025-11-19**|**Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation**|Qiming Li et.al.|[2511.05923](https://arxiv.org/abs/2511.05923)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.04976": "|**2025-11-07**|**iFlyBot-VLM Technical Report**|Xin Nie et.al.|[2511.04976](https://arxiv.org/abs/2511.04976)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.04664": "|**2025-11-06**|**SAFe-Copilot: Unified Shared Autonomy Framework**|Phat Nguyen et.al.|[2511.04664](https://arxiv.org/abs/2511.04664)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.04479": "|**2025-11-07**|**ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai**|Surapon Nonesung et.al.|[2511.04479](https://arxiv.org/abs/2511.04479)|**[link](https://huggingface.co/spaces/trapezius60/ocr_typhoon)**|\n", "2511.04357": "|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Ma\u00eblic Neau et.al.|[2511.04357](https://arxiv.org/abs/2511.04357)|**[link](https://github.com/ChocoWu/Awesome-Scene-Graph-Generation)**|\n", "2511.04307": "|**2025-11-10**|**GUI-360$^\\circ$: A Comprehensive Dataset and Benchmark for Computer-Using Agents**|Jian Mu et.al.|[2511.04307](https://arxiv.org/abs/2511.04307)|**[link](https://huggingface.co/datasets/vyokky/GUI-360)**|\n", "2511.03725": "|**2025-11-05**|**Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition**|Jongseo Lee et.al.|[2511.03725](https://arxiv.org/abs/2511.03725)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03400": "|**2025-11-14**|**GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement**|Minquan Gao et.al.|[2511.03400](https://arxiv.org/abs/2511.03400)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.03332": "|**2025-11-05**|**Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge**|Yi Yang et.al.|[2511.03332](https://arxiv.org/abs/2511.03332)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.02778": "|**2025-11-04**|**VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation**|Kevin Qinghong Lin et.al.|[2511.02778](https://arxiv.org/abs/2511.02778)|**[link](https://huggingface.co/spaces/CSU-JPG/VCode)**|\n", "2511.02427": "|**2025-11-04**|**From the Laboratory to Real-World Application: Evaluating Zero-Shot Scene Interpretation on Edge Devices for Mobile Robotics**|Nicolas Schuler et.al.|[2511.02427](https://arxiv.org/abs/2511.02427)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.02239": "|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Youngjin Hong et.al.|[2511.02239](https://arxiv.org/abs/2511.02239)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.01472": "|**2025-11-03**|**AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models**|Sarthak Mishra et.al.|[2511.01472](https://arxiv.org/abs/2511.01472)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05553": "|**2025-11-03**|**EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning**|Xinyan Cai et.al.|[2511.05553](https://arxiv.org/abs/2511.05553)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00945": "|**2025-11-02**|**\"Less is More\": Reducing Cognitive Load and Task Drift in Real-Time Multimodal Assistive Agents for the Visually Impaired**|Yi Zhao et.al.|[2511.00945](https://arxiv.org/abs/2511.00945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00933": "|**2025-11-02**|**Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation**|Xiangyu Shi et.al.|[2511.00933](https://arxiv.org/abs/2511.00933)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.00917": "|**2025-11-02**|**Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots**|Junyao Shi et.al.|[2511.00917](https://arxiv.org/abs/2511.00917)|**[link](https://github.com/wadeKeith/Awesome-Embodied-AI)**|\n", "2511.01914": "|**2025-11-01**|**iFlyBot-VLA Technical Report**|Yuan Zhang et.al.|[2511.01914](https://arxiv.org/abs/2511.01914)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.27623": "|**2025-10-31**|**Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning**|Qiusi Zhan et.al.|[2510.27623](https://arxiv.org/abs/2510.27623)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.00139": "|**2025-10-31**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Yu Cui et.al.|[2511.00139](https://arxiv.org/abs/2511.00139)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11478": "|**2025-11-18**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Nhat Chung et.al.|[2511.11478](https://arxiv.org/abs/2511.11478)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11301": "|**2025-11-14**|**EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment**|Ruoxi Cheng et.al.|[2511.11301](https://arxiv.org/abs/2511.11301)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Yihao Zhang et.al.|[2511.11298](https://arxiv.org/abs/2511.11298)|null|\n", "2511.11052": "|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Jinxuan Zhu et.al.|[2511.11052](https://arxiv.org/abs/2511.11052)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10948": "|**2025-11-14**|**DEFT-LLM: Disentangled Expert Feature Tuning for Micro-Expression Recognition**|Ren Zhang et.al.|[2511.10948](https://arxiv.org/abs/2511.10948)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.12937": "|**2025-11-24**|**Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models**|Guoyan Wang et.al.|[2511.12937](https://arxiv.org/abs/2511.12937)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.12878": "|**2025-11-18**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Junyi Ma et.al.|[2511.12878](https://arxiv.org/abs/2511.12878)|**[link](https://github.com/SeanChenxy/Hand3DResearch)**|\n", "2511.12676": "|**2025-11-16**|**BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections**|Subin Varghese et.al.|[2511.12676](https://arxiv.org/abs/2511.12676)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12436": "|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Xiaoshuai Hao et.al.|[2511.12436](https://arxiv.org/abs/2511.12436)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2511.12405": "|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|Hyunki Seong et.al.|[2511.12405](https://arxiv.org/abs/2511.12405)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12149": "|**2025-11-15**|**AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models**|Jiayu Li et.al.|[2511.12149](https://arxiv.org/abs/2511.12149)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2511.12101": "|**2025-11-15**|**Decoupled Action Head: Confining Task Knowledge to Conditioning Layers**|Jian Zhou et.al.|[2511.12101](https://arxiv.org/abs/2511.12101)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14759": "|**2025-11-19**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Physical Intelligence et.al.|[2511.14759](https://arxiv.org/abs/2511.14759)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al.|[2511.14659](https://arxiv.org/abs/2511.14659)|**[link](https://huggingface.co/models/declare-lab/nora-1.5)**|\n", "2511.14499": "|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Jack Qin et.al.|[2511.14499](https://arxiv.org/abs/2511.14499)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14178": "|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Zhuo Li et.al.|[2511.14178](https://arxiv.org/abs/2511.14178)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Xiaoquan Sun et.al.|[2511.14161](https://arxiv.org/abs/2511.14161)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.14159": "|**2025-11-18**|**MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs**|Huiyi Chen et.al.|[2511.14159](https://arxiv.org/abs/2511.14159)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.14148": "|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Yuhua Jiang et.al.|[2511.14148](https://arxiv.org/abs/2511.14148)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.14120": "|**2025-11-18**|**Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models**|Hao Zhen et.al.|[2511.14120](https://arxiv.org/abs/2511.14120)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.14004": "|**2025-11-20**|**Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval**|Taijing Chen et.al.|[2511.14004](https://arxiv.org/abs/2511.14004)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15605": "|**2025-11-30**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei et.al.|[2511.15605](https://arxiv.org/abs/2511.15605)|**[link](https://github.com/sii-research/siiRL)**|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Jiashu Yang et.al.|[2511.15279](https://arxiv.org/abs/2511.15279)|null|\n", "2511.15159": "|**2025-11-19**|**Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation**|Firdavs Nasriddinov et.al.|[2511.15159](https://arxiv.org/abs/2511.15159)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Yang Tian et.al.|[2511.16651](https://arxiv.org/abs/2511.16651)|**[link](https://huggingface.co/datasets/InternRobotics/InternData-A1)**|\n", "2511.16449": "|**2025-11-21**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Ziyan Liu et.al.|[2511.16449](https://arxiv.org/abs/2511.16449)|**[link](https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling)**|\n", "2511.16233": "|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Kewei Chen et.al.|[2511.16233](https://arxiv.org/abs/2511.16233)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.16203": "|**2025-11-23**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan et.al.|[2511.16203](https://arxiv.org/abs/2511.16203)|**[link](https://github.com/liudaizong/Awesome-LVLM-Attack)**|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Yi Yang et.al.|[2511.16175](https://arxiv.org/abs/2511.16175)|**[link](https://huggingface.co/models/Yysrc/LIBERO-Object)**|\n", "2511.16166": "|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Zeting Liu et.al.|[2511.16166](https://arxiv.org/abs/2511.16166)|**[link](https://github.com/AIGeeksGroup/EvoVLA)**|\n", "2511.15722": "|**2025-11-14**|**Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods**|Weichen Liu et.al.|[2511.15722](https://arxiv.org/abs/2511.15722)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17502": "|**2025-11-24**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen et.al.|[2511.17502](https://arxiv.org/abs/2511.17502)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu et.al.|[2511.17366](https://arxiv.org/abs/2511.17366)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17199": "|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Hanyu Zhou et.al.|[2511.17199](https://arxiv.org/abs/2511.17199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17097": "|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Shuo Wang et.al.|[2511.17097](https://arxiv.org/abs/2511.17097)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.19433": "|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Dong Jing et.al.|[2511.19433](https://arxiv.org/abs/2511.19433)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19315": "|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Weiliang Tang et.al.|[2511.19315](https://arxiv.org/abs/2511.19315)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19221": "|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Jianhua Han et.al.|[2511.19221](https://arxiv.org/abs/2511.19221)|null|\n", "2511.18960": "|**2025-12-02**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Lei Xiao et.al.|[2511.18960](https://arxiv.org/abs/2511.18960)|null|\n", "2511.18950": "|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Juntao Gao et.al.|[2511.18950](https://arxiv.org/abs/2511.18950)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18845": "|**2025-11-24**|**UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model**|Changxin Huang et.al.|[2511.18845](https://arxiv.org/abs/2511.18845)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.18823": "|**2025-11-24**|**VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models**|Fufangchen Zhao et.al.|[2511.18823](https://arxiv.org/abs/2511.18823)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18810": "|**2025-11-24**|**MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent**|Yuxia Fu et.al.|[2511.18810](https://arxiv.org/abs/2511.18810)|**[link](https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications)**|\n", "2511.18787": "|**2025-11-24**|**Understanding Task Transfer in Vision-Language Models**|Bhuvan Sachdeva et.al.|[2511.18787](https://arxiv.org/abs/2511.18787)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18746": "|**2025-11-24**|**Any4D: Open-Prompt 4D Generation from Natural Language and Images**|Hao Li et.al.|[2511.18746](https://arxiv.org/abs/2511.18746)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18359": "|**2025-11-23**|**TRANSPORTER: Transferring Visual Semantics from VLM Manifolds**|Alexandros Stergiou et.al.|[2511.18359](https://arxiv.org/abs/2511.18359)|null|\n", "2511.18112": "|**2025-11-22**|**EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation**|Min Lin et.al.|[2511.18112](https://arxiv.org/abs/2511.18112)|null|\n", "2511.18085": "|**2025-11-25**|**Continually Evolving Skill Knowledge in Vision Language Action Model**|Yuxuan Wu et.al.|[2511.18085](https://arxiv.org/abs/2511.18085)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18082": "|**2025-11-22**|**ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models**|Wencheng Ye et.al.|[2511.18082](https://arxiv.org/abs/2511.18082)|**[link](https://github.com/gooogleshanghai/ActDistill)**|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Jiahui Zhang et.al.|[2511.20633](https://arxiv.org/abs/2511.20633)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20274": "|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Advik Sinha et.al.|[2511.20274](https://arxiv.org/abs/2511.20274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.19912": "|**2025-11-25**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Dapeng Zhang et.al.|[2511.19912](https://arxiv.org/abs/2511.19912)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19878": "|**2025-11-25**|**MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization**|Chengyue Huang et.al.|[2511.19878](https://arxiv.org/abs/2511.19878)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19861": "|**2025-11-30**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|GigaWorld Team et.al.|[2511.19861](https://arxiv.org/abs/2511.19861)|**[link](https://huggingface.co/models/open-gigaai/GigaWorld-0-Video-GR1-2b)**|\n", "2511.19859": "|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Xiangkai Ma et.al.|[2511.19859](https://arxiv.org/abs/2511.19859)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19768": "|**2025-11-24**|**Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering**|Noah Frahm et.al.|[2511.19768](https://arxiv.org/abs/2511.19768)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19584": "|**2025-11-24**|**Learning Massively Multitask World Models for Continuous Control**|Nicklas Hansen et.al.|[2511.19584](https://arxiv.org/abs/2511.19584)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.19528": "|**2025-11-24**|**Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories**|Rushuai Yang et.al.|[2511.19528](https://arxiv.org/abs/2511.19528)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.21663": "|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Naifu Zhang et.al.|[2511.21663](https://arxiv.org/abs/2511.21663)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Hui Zhou et.al.|[2511.21557](https://arxiv.org/abs/2511.21557)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan et.al.|[2511.21542](https://arxiv.org/abs/2511.21542)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21428": "|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Jiajie Zhang et.al.|[2511.21428](https://arxiv.org/abs/2511.21428)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.21192": "|**2025-11-30**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu et.al.|[2511.21192](https://arxiv.org/abs/2511.21192)|null|\n", "2511.21064": "|**2025-11-26**|**OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection**|Chujie Wang et.al.|[2511.21064](https://arxiv.org/abs/2511.21064)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20937": "|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Qineng Wang et.al.|[2511.20937](https://arxiv.org/abs/2511.20937)|**[link](https://huggingface.co/datasets/MLL-Lab/ENACT)**|\n", "2511.20841": "|**2025-11-25**|**OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping**|Edmond Tong et.al.|[2511.20841](https://arxiv.org/abs/2511.20841)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20720": "|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Haibo HU et.al.|[2511.20720](https://arxiv.org/abs/2511.20720)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23429": "|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|Junshu Tang et.al.|[2511.23429](https://arxiv.org/abs/2511.23429)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.23262": "|**2025-11-28**|**Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning**|Yang Li et.al.|[2511.23262](https://arxiv.org/abs/2511.23262)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23186": "|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Runyu Jiao et.al.|[2511.23186](https://arxiv.org/abs/2511.23186)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23055": "|**2025-11-28**|**MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents**|Ruoxuan Zhang et.al.|[2511.23055](https://arxiv.org/abs/2511.23055)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23034": "|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Zuolei Li et.al.|[2511.23034](https://arxiv.org/abs/2511.23034)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.23031": "|**2025-11-28**|**From Illusion to Intention: Visual Rationale Learning for Vision-Language Reasoning**|Changpeng Wang et.al.|[2511.23031](https://arxiv.org/abs/2511.23031)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22780": "|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Amir Rasouli et.al.|[2511.22780](https://arxiv.org/abs/2511.22780)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22777": "|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Sajjad Pakdamansavoji et.al.|[2511.22777](https://arxiv.org/abs/2511.22777)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22697": "|**2025-11-27**|**Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations**|Chancharik Mitra et.al.|[2511.22697](https://arxiv.org/abs/2511.22697)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22555": "|**2025-11-27**|**Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention**|Yanbo Mao et.al.|[2511.22555](https://arxiv.org/abs/2511.22555)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22532": "|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Zhaohui Wang et.al.|[2511.22532](https://arxiv.org/abs/2511.22532)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22433": "|**2025-12-02**|**SkeletonAgent: An Agentic Interaction Framework for Skeleton-based Action Recognition**|Hongda Liu et.al.|[2511.22433](https://arxiv.org/abs/2511.22433)|**[link](https://huggingface.co/models/firework8/SkeletonAgent)**|\n", "2511.22134": "|**2025-11-27**|**DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action**|Zhen Fang et.al.|[2511.22134](https://arxiv.org/abs/2511.22134)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02013": "|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Chenyang Gu et.al.|[2512.02013](https://arxiv.org/abs/2512.02013)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2512.01803": "|**2025-12-02**|**Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos**|Xavier Thomas et.al.|[2512.01803](https://arxiv.org/abs/2512.01803)|**[link](https://huggingface.co/datasets/dghadiya/TAG-Bench-Video)**|\n", "2512.01801": "|**2025-12-02**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yunfei Li et.al.|[2512.01801](https://arxiv.org/abs/2512.01801)|null|\n", "2512.01773": "|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Chenghao Gu et.al.|[2512.01773](https://arxiv.org/abs/2512.01773)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01715": "|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Wanpeng Zhang et.al.|[2512.01715](https://arxiv.org/abs/2512.01715)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Fei Liu et.al.|[2512.01550](https://arxiv.org/abs/2512.01550)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|Jiaming Tang et.al.|[2512.01031](https://arxiv.org/abs/2512.01031)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Yi-Lin Wei et.al.|[2512.01022](https://arxiv.org/abs/2512.01022)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00975": "|**2025-11-30**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Haotian Liang et.al.|[2512.00975](https://arxiv.org/abs/2512.00975)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00903": "|**2025-11-30**|**SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead**|Chaojun Ni et.al.|[2512.00903](https://arxiv.org/abs/2512.00903)|null|\n", "2512.00846": "|**2025-11-30**|**AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent**|Neeraj Anand et.al.|[2512.00846](https://arxiv.org/abs/2512.00846)|null|\n", "2512.00797": "|**2025-11-30**|**Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration**|Nan Sun et.al.|[2512.00797](https://arxiv.org/abs/2512.00797)|null|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang et.al.|[2512.00783](https://arxiv.org/abs/2512.00783)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00194": "|**2025-11-28**|**AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI**|Zag ElSayed et.al.|[2512.00194](https://arxiv.org/abs/2512.00194)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00087": "|**2025-11-26**|**Exploring Automated Recognition of Instructional Activity and Discourse from Multimodal Classroom Data**|Ivo Bueno et.al.|[2512.00087](https://arxiv.org/abs/2512.00087)|null|\n", "2512.02902": "|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Weiqi Li et.al.|[2512.02902](https://arxiv.org/abs/2512.02902)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02846": "|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Manuel Benavent-Lledo et.al.|[2512.02846](https://arxiv.org/abs/2512.02846)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02834": "|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Siyuan Yang et.al.|[2512.02834](https://arxiv.org/abs/2512.02834)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02814": "|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Yongrui Yu et.al.|[2512.02814](https://arxiv.org/abs/2512.02814)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02787": "|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng et.al.|[2512.02787](https://arxiv.org/abs/2512.02787)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang et.al.|[2512.02729](https://arxiv.org/abs/2512.02729)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03963": "|**2025-12-04**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Tao Wu et.al.|[2512.03963](https://arxiv.org/abs/2512.03963)|null|\n", "2512.03913": "|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Jeongeun Park et.al.|[2512.03913](https://arxiv.org/abs/2512.03913)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03724": "|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Ziwen Li et.al.|[2512.03724](https://arxiv.org/abs/2512.03724)|null|\n", "2512.03479": "|**2025-12-03**|**Towards Object-centric Understanding for Instructional Videos**|Wenliang Guo et.al.|[2512.03479](https://arxiv.org/abs/2512.03479)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu et.al.|[2512.05107](https://arxiv.org/abs/2512.05107)|null|\n", "2512.05103": "|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Xiaochuang Han et.al.|[2512.05103](https://arxiv.org/abs/2512.05103)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Yicheng Liu et.al.|[2512.04952](https://arxiv.org/abs/2512.04952)|null|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Yihong Tang et.al.|[2512.04733](https://arxiv.org/abs/2512.04733)|null|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang et.al.|[2512.04686](https://arxiv.org/abs/2512.04686)|**[link](https://huggingface.co/models/WangYipu2002/CroPond-3B)**|\n", "2512.04585": "|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Jingjing Li et.al.|[2512.04585](https://arxiv.org/abs/2512.04585)|null|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang et.al.|[2512.04537](https://arxiv.org/abs/2512.04537)|null|\n", "2512.04459": "|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Yingzi Ma et.al.|[2512.04459](https://arxiv.org/abs/2512.04459)|null|\n", "2512.04446": "|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Chang Liu et.al.|[2512.04446](https://arxiv.org/abs/2512.04446)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04441": "|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Bin Sun et.al.|[2512.04441](https://arxiv.org/abs/2512.04441)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.04381": "|**2025-12-04**|**FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination**|Chengyang He et.al.|[2512.04381](https://arxiv.org/abs/2512.04381)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.05964": "|**2025-12-05**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Kevin Black et.al.|[2512.05964](https://arxiv.org/abs/2512.05964)|null|\n", "2512.05955": "|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Haowen Liu et.al.|[2512.05955](https://arxiv.org/abs/2512.05955)|null|\n", "2512.05943": "|**2025-12-05**|**TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models**|Shima Imani et.al.|[2512.05943](https://arxiv.org/abs/2512.05943)|null|\n", "2512.05809": "|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Saurav Jha et.al.|[2512.05809](https://arxiv.org/abs/2512.05809)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.05693": "|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Zhiying Du et.al.|[2512.05693](https://arxiv.org/abs/2512.05693)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05546": "|**2025-12-05**|**Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models**|Weijue Bu et.al.|[2512.05546](https://arxiv.org/abs/2512.05546)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05524": "|**2025-12-05**|**VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation**|Chinthani Sugandhika et.al.|[2512.05524](https://arxiv.org/abs/2512.05524)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05277": "|**2025-12-04**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Kevin Cannons et.al.|[2512.05277](https://arxiv.org/abs/2512.05277)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2511.15669": "|**2025-10-31**|**DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models**|Cheng Yin et.al.|[2511.15669](https://arxiv.org/abs/2511.15669)|**[link](https://github.com/wadeKeith/DeepThinkVLA)**|\n", "2512.07582": "|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Guangyan Chen et.al.|[2512.07582](https://arxiv.org/abs/2512.07582)|null|\n", "2512.06951": "|**2025-12-07**|**Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge**|Ilia Larchenko et.al.|[2512.06951](https://arxiv.org/abs/2512.06951)|**[link](https://huggingface.co/models/IliaLarchenko/behavior_submission)**|\n"}, "Imitation Learning": {"2508.14441": "|**2025-08-20**|**FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy**|Yijin Chen et.al.|[2508.14441](https://arxiv.org/abs/2508.14441)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.14383": "|**2025-08-20**|**Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations**|Haitong Ma et.al.|[2508.14383](https://arxiv.org/abs/2508.14383)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14379": "|**2025-08-20**|**Action-Constrained Imitation Learning**|Chia-Han Yeh et.al.|[2508.14379](https://arxiv.org/abs/2508.14379)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14295": "|**2025-08-19**|**Pixels to Play: A Foundation Model for 3D Gameplay**|Yuguang Yue et.al.|[2508.14295](https://arxiv.org/abs/2508.14295)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14042": "|**2025-08-19**|**Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation**|Zhuoling Li et.al.|[2508.14042](https://arxiv.org/abs/2508.14042)|**[link](https://github.com/GuoleiSun/Awesome-SAM2)**|\n", "2508.13326": "|**2025-08-18**|**Decoding Communications with Partial Information**|Dylan Cope et.al.|[2508.13326](https://arxiv.org/abs/2508.13326)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.12274": "|**2025-08-17**|**Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments**|Jian Zhao et.al.|[2508.12274](https://arxiv.org/abs/2508.12274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.11767": "|**2025-08-15**|**Limitation Learning: Catching Adverse Dialog with GAIL**|Noah Kasmanoff et.al.|[2508.11767](https://arxiv.org/abs/2508.11767)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2508.11537": "|**2025-08-15**|**MultiPark: Multimodal Parking Transformer with Next-Segment Prediction**|Han Zheng et.al.|[2508.11537](https://arxiv.org/abs/2508.11537)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.10511": "|**2025-08-15**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Andrea Rosasco et.al.|[2508.10511](https://arxiv.org/abs/2508.10511)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.10399": "|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.10259": "|**2025-08-14**|**Leveraging OS-Level Primitives for Robotic Action Management**|Wenxin Zheng et.al.|[2508.10259](https://arxiv.org/abs/2508.10259)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09960": "|**2025-08-14**|**GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation**|Yifei Yao et.al.|[2508.09960](https://arxiv.org/abs/2508.09960)|**[link](https://github.com/jonyzhang2023/awesome-humanoid-learning)**|\n", "2508.09444": "|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Haoxiang Shi et.al.|[2508.09444](https://arxiv.org/abs/2508.09444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.08882": "|**2025-08-28**|**MSARL: Decoupling Reasoning and Tool Use with Multi-Small-Agent Reinforcement Learning**|Dayu Wang et.al.|[2508.08882](https://arxiv.org/abs/2508.08882)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.08748": "|**2025-08-12**|**Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT**|Muhammad A. Muttaqien et.al.|[2508.08748](https://arxiv.org/abs/2508.08748)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.08707": "|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Haoran Ding et.al.|[2508.08707](https://arxiv.org/abs/2508.08707)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.08170": "|**2025-08-21**|**ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction**|Chaojun Ni et.al.|[2508.08170](https://arxiv.org/abs/2508.08170)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.07770": "|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2508.07029": "|**2025-08-27**|**From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving**|Antonio Guillen-Perez et.al.|[2508.07029](https://arxiv.org/abs/2508.07029)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06319": "|**2025-08-08**|**Towards Balanced Behavior Cloning from Imbalanced Datasets**|Sagar Parekh et.al.|[2508.06319](https://arxiv.org/abs/2508.06319)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06042": "|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Daechul Ahn et.al.|[2508.06042](https://arxiv.org/abs/2508.06042)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05960": "|**2025-08-08**|**Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning**|Haohui Chen et.al.|[2508.05960](https://arxiv.org/abs/2508.05960)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05941": "|**2025-08-08**|**Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution**|Zhanyi Sun et.al.|[2508.05941](https://arxiv.org/abs/2508.05941)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05310": "|**2025-08-07**|**ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning**|Jelle Luijkx et.al.|[2508.05310](https://arxiv.org/abs/2508.05310)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05081": "|**2025-08-07**|**Cognitive Duality for Adaptive Web Agents**|Jiarun Liu et.al.|[2508.05081](https://arxiv.org/abs/2508.05081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05077": "|**2025-08-07**|**Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning**|Luai Abuelsamen et.al.|[2508.05077](https://arxiv.org/abs/2508.05077)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06571": "|**2025-08-15**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Anqing Jiang et.al.|[2508.06571](https://arxiv.org/abs/2508.06571)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2508.03129": "|**2025-08-05**|**Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection**|Le Qiu et.al.|[2508.03129](https://arxiv.org/abs/2508.03129)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.03043": "|**2025-08-05**|**Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control**|Yi-Hsuan Hsiao et.al.|[2508.03043](https://arxiv.org/abs/2508.03043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02617": "|**2025-08-04**|**Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach**|Peng Wei et.al.|[2508.02617](https://arxiv.org/abs/2508.02617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02219": "|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|**[link](https://github.com/XiaoWei-i/Awesome-VLA-RL)**|\n", "2508.02062": "|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2508.01600": "|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01442": "|**2025-08-02**|**Physically-based Lighting Augmentation for Robotic Manipulation**|Shutong Jin et.al.|[2508.01442](https://arxiv.org/abs/2508.01442)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01167": "|**2025-08-02**|**T2S: Tokenized Skill Scaling for Lifelong Imitation Learning**|Hongquan Zhang et.al.|[2508.01167](https://arxiv.org/abs/2508.01167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01131": "|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01060": "|**2025-08-01**|**Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation**|Ibrahim Althamary et.al.|[2508.01060](https://arxiv.org/abs/2508.01060)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00795": "|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2508.00697": "|**2025-08-01**|**On-Device Diffusion Transformer Policy for Efficient Robot Manipulation**|Yiming Wu et.al.|[2508.00697](https://arxiv.org/abs/2508.00697)|**[link](https://github.com/EmbodiedMind/DiffusionPolicy-Robotics)**|\n", "2508.00491": "|**2025-08-01**|**HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning**|Carlo Alessi et.al.|[2508.00491](https://arxiv.org/abs/2508.00491)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00261": "|**2025-08-01**|**Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning**|Saichao Liu et.al.|[2508.00261](https://arxiv.org/abs/2508.00261)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.23523": "|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.22380": "|**2025-07-30**|**Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations**|Yifei Chen et.al.|[2507.22380](https://arxiv.org/abs/2507.22380)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.22219": "|**2025-07-29**|**RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation**|Dongyub Jude Lee et.al.|[2507.22219](https://arxiv.org/abs/2507.22219)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.21981": "|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Yufei Jia et.al.|[2507.21981](https://arxiv.org/abs/2507.21981)|**[link](https://github.com/TATP-233/DISCOVERSE)**|\n", "2507.21796": "|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Yuying Zhang et.al.|[2507.21796](https://arxiv.org/abs/2507.21796)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.21533": "|**2025-07-29**|**Model Predictive Adversarial Imitation Learning for Planning from Observation**|Tyler Han et.al.|[2507.21533](https://arxiv.org/abs/2507.21533)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.21452": "|**2025-07-29**|**Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training**|Sodtavilan Odonchimed et.al.|[2507.21452](https://arxiv.org/abs/2507.21452)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.20622": "|**2025-07-28**|**FMimic: Foundation Models are Fine-grained Action Learners from Human Videos**|Guangyan Chen et.al.|[2507.20622](https://arxiv.org/abs/2507.20622)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.18066": "|**2025-08-25**|**Arnold: a generalist muscle transformer policy**|Alberto Silvio Chiappa et.al.|[2508.18066](https://arxiv.org/abs/2508.18066)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2508.17643": "|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Krishna Vinod et.al.|[2508.17643](https://arxiv.org/abs/2508.17643)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17600": "|**2025-09-17**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Guanxing Lu et.al.|[2508.17600](https://arxiv.org/abs/2508.17600)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2508.17547": "|**2025-08-24**|**LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations**|Weikang Wan et.al.|[2508.17547](https://arxiv.org/abs/2508.17547)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17452": "|**2025-08-24**|**ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories**|Dou Jiabao et.al.|[2508.17452](https://arxiv.org/abs/2508.17452)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2508.17449": "|**2025-09-04**|**Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges**|Zezeng Li et.al.|[2508.17449](https://arxiv.org/abs/2508.17449)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17230": "|**2025-09-06**|**4D Visual Pre-training for Robot Learning**|Chengkai Hou et.al.|[2508.17230](https://arxiv.org/abs/2508.17230)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2508.19191": "|**2025-08-27**|**AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot**|Yue Wang et.al.|[2508.19191](https://arxiv.org/abs/2508.19191)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19152": "|**2025-08-26**|**Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games**|Chiu-Chou Lin et.al.|[2508.19152](https://arxiv.org/abs/2508.19152)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19900": "|**2025-08-27**|**Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning**|Tan Jing et.al.|[2508.19900](https://arxiv.org/abs/2508.19900)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19476": "|**2025-08-26**|**Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning**|Dane Brouwer et.al.|[2508.19476](https://arxiv.org/abs/2508.19476)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20740": "|**2025-08-28**|**Non-expert to Expert Motion Translation Using Generative Adversarial Networks**|Yuki Tanaka et.al.|[2508.20740](https://arxiv.org/abs/2508.20740)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21501": "|**2025-08-29**|**Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting**|Pierrick Lorang et.al.|[2508.21501](https://arxiv.org/abs/2508.21501)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03222": "|**2025-09-03**|**The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation**|Sophia Bianchi Moyen et.al.|[2509.03222](https://arxiv.org/abs/2509.03222)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.03206": "|**2025-09-03**|**Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback**|Zeqiang Zhang et.al.|[2509.03206](https://arxiv.org/abs/2509.03206)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.02861": "|**2025-09-02**|**Power Grid Control with Graph-Based Distributed Reinforcement Learning**|Carlo Fabrizio et.al.|[2509.02861](https://arxiv.org/abs/2509.02861)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02761": "|**2025-09-04**|**Plan Verification for LLM-Based Embodied Task Completion Agents**|Ananth Hariharan et.al.|[2509.02761](https://arxiv.org/abs/2509.02761)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.01819": "|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Ge Yan et.al.|[2509.01819](https://arxiv.org/abs/2509.01819)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.01657": "|**2025-09-01**|**Data Retrieval with Importance Weights for Few-Shot Imitation Learning**|Amber Xie et.al.|[2509.01657](https://arxiv.org/abs/2509.01657)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00574": "|**2025-08-30**|**Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot**|Philip Lorimer et.al.|[2509.00574](https://arxiv.org/abs/2509.00574)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.00310": "|**2025-08-30**|**TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization**|Yuxuan Ding et.al.|[2509.00310](https://arxiv.org/abs/2509.00310)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|\n", "2509.04443": "|**2025-09-04**|**EMMA: Scaling Mobile Manipulation via Egocentric Human Data**|Lawrence Y. Zhu et.al.|[2509.04443](https://arxiv.org/abs/2509.04443)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04063": "|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Hongyin Zhang et.al.|[2509.04063](https://arxiv.org/abs/2509.04063)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.05007": "|**2025-09-08**|**Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework**|Jie Chen et.al.|[2509.05007](https://arxiv.org/abs/2509.05007)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04737": "|**2025-09-05**|**Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics**|Ryoga Oishi et.al.|[2509.04737](https://arxiv.org/abs/2509.04737)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.04628": "|**2025-09-04**|**Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control**|Alejandro Posadas-Nava et.al.|[2509.04628](https://arxiv.org/abs/2509.04628)|**[link](https://huggingface.co/models/arclabmit/iss_docking_act_model)**|\n", "2509.06853": "|**2025-09-08**|**Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor**|Juan D. Gil et.al.|[2509.06853](https://arxiv.org/abs/2509.06853)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06656": "|**2025-09-08**|**Group Effect Enhanced Generative Adversarial Imitation Learning for Individual Travel Behavior Modeling under Incentives**|Yuanyuan Wu et.al.|[2509.06656](https://arxiv.org/abs/2509.06656)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06426": "|**2025-09-11**|**Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster**|Pembe Gizem \u00d6zdil et.al.|[2509.06426](https://arxiv.org/abs/2509.06426)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.05513": "|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Ahad Jawaid et.al.|[2509.05513](https://arxiv.org/abs/2509.05513)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.05368": "|**2025-09-04**|**Long-Horizon Visual Imitation Learning via Plan and Code Reflection**|Quan Chen et.al.|[2509.05368](https://arxiv.org/abs/2509.05368)|**[link](https://huggingface.co/datasets/cq838/LongVILBench)**|\n", "2509.07953": "|**2025-09-09**|**RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction**|Zheyuan Hu et.al.|[2509.07953](https://arxiv.org/abs/2509.07953)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08435": "|**2025-09-10**|**PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching**|Lei Ye et.al.|[2509.08435](https://arxiv.org/abs/2509.08435)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08354": "|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Ce Guo et.al.|[2509.08354](https://arxiv.org/abs/2509.08354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08226": "|**2025-09-10**|**Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware**|Yoshiki Kanai et.al.|[2509.08226](https://arxiv.org/abs/2509.08226)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.07997": "|**2025-09-05**|**Learning-Based Planning for Improving Science Return of Earth Observation Satellites**|Abigail Breitfeld et.al.|[2509.07997](https://arxiv.org/abs/2509.07997)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09655": "|**2025-09-11**|**Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management**|Sanjay Basu et.al.|[2509.09655](https://arxiv.org/abs/2509.09655)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09893": "|**2025-09-11**|**Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision**|Hanbit Oh et.al.|[2509.09893](https://arxiv.org/abs/2509.09893)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.12081": "|**2025-09-15**|**Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors**|Anirudha Majumdar et.al.|[2509.12081](https://arxiv.org/abs/2509.12081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12026": "|**2025-09-15**|**Imitation Learning as Return Distribution Matching**|Filippo Lazzati et.al.|[2509.12026](https://arxiv.org/abs/2509.12026)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11880": "|**2025-09-15**|**Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning**|Carlos Celemin et.al.|[2509.11880](https://arxiv.org/abs/2509.11880)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11865": "|**2025-09-15**|**Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer**|Travis Davies et.al.|[2509.11865](https://arxiv.org/abs/2509.11865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11839": "|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Jiacheng Liu et.al.|[2509.11839](https://arxiv.org/abs/2509.11839)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.11481": "|**2025-09-15**|**RAPTOR: A Foundation Policy for Quadrotor Control**|Jonas Eschmann et.al.|[2509.11481](https://arxiv.org/abs/2509.11481)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11364": "|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Sheng Liu et.al.|[2509.11364](https://arxiv.org/abs/2509.11364)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11225": "|**2025-09-14**|**MEMBOT: Memory-Based Robot in Intermittent POMDP**|Youzhi Liang et.al.|[2509.11225](https://arxiv.org/abs/2509.11225)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11109": "|**2025-09-16**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Jiaxin Huang et.al.|[2509.11109](https://arxiv.org/abs/2509.11109)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11090": "|**2025-09-14**|**End-to-End Visual Autonomous Parking via Control-Aided Attention**|Chao Chen et.al.|[2509.11090](https://arxiv.org/abs/2509.11090)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11044": "|**2025-09-23**|**FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design**|Xuefeng Liu et.al.|[2509.11044](https://arxiv.org/abs/2509.11044)|**[link](https://github.com/AspirinCode/papers-for-molecular-design-using-DL)**|\n", "2509.10486": "|**2025-08-30**|**SABR: A Stable Adaptive Bitrate Framework Using Behavior Cloning Pretraining and Reinforcement Learning Fine-Tuning**|Pengcheng Luo et.al.|[2509.10486](https://arxiv.org/abs/2509.10486)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13200": "|**2025-09-18**|**StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening**|Moonyoung Lee et.al.|[2509.13200](https://arxiv.org/abs/2509.13200)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.12618": "|**2025-09-16**|**ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation**|Zekai Zhang et.al.|[2509.12618](https://arxiv.org/abs/2509.12618)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.12562": "|**2025-09-16**|**Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling**|Zhefei Gong et.al.|[2509.12562](https://arxiv.org/abs/2509.12562)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14159": "|**2025-09-17**|**MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies**|Dayi Dong et.al.|[2509.14159](https://arxiv.org/abs/2509.14159)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13736": "|**2025-09-17**|**Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning**|Muyuan Ma et.al.|[2509.13736](https://arxiv.org/abs/2509.13736)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13579": "|**2025-09-16**|**TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning**|Momchil S. Tomov et.al.|[2509.13579](https://arxiv.org/abs/2509.13579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15155": "|**2025-09-18**|**Self-Improving Embodied Foundation Models**|Seyed Kamyar Seyed Ghasemipour et.al.|[2509.15155](https://arxiv.org/abs/2509.15155)|**[link](https://github.com/masamasa59/ai-agent-papers)**|\n", "2509.15099": "|**2025-09-18**|**Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach**|Taoyuan Yu et.al.|[2509.15099](https://arxiv.org/abs/2509.15099)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2509.15042": "|**2025-09-18**|**Reinforcement Learning Agent for a 2D Shooter Game**|Thomas Ackermann et.al.|[2509.15042](https://arxiv.org/abs/2509.15042)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14688": "|**2025-09-18**|**exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation**|Yue Xu et.al.|[2509.14688](https://arxiv.org/abs/2509.14688)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2509.14548": "|**2025-09-18**|**SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching**|Emily Sumner et.al.|[2509.14548](https://arxiv.org/abs/2509.14548)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.14349": "|**2025-09-17**|**LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation**|Zhengyang Kris Weng et.al.|[2509.14349](https://arxiv.org/abs/2509.14349)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16053": "|**2025-09-19**|**Compose by Focus: Scene Graph-based Atomic Skills**|Han Qi et.al.|[2509.16053](https://arxiv.org/abs/2509.16053)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15880": "|**2025-09-19**|**Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder**|An Dinh Vuong et.al.|[2509.15880](https://arxiv.org/abs/2509.15880)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15443": "|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Xingyu Chen et.al.|[2509.15443](https://arxiv.org/abs/2509.15443)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2509.15400": "|**2025-09-18**|**Exploring multimodal implicit behavior learning for vehicle navigation in simulated cities**|Eric Aislan Antonelo et.al.|[2509.15400](https://arxiv.org/abs/2509.15400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18043": "|**2025-09-22**|**Prepare Before You Act: Learning From Humans to Rearrange Initial States**|Yinlong Dai et.al.|[2509.18043](https://arxiv.org/abs/2509.18043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17964": "|**2025-09-22**|**FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance**|Yang Li et.al.|[2509.17964](https://arxiv.org/abs/2509.17964)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17940": "|**2025-09-22**|**DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving**|Shuyao Shang et.al.|[2509.17940](https://arxiv.org/abs/2509.17940)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17759": "|**2025-09-22**|**MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies**|Chengbo Yuan et.al.|[2509.17759](https://arxiv.org/abs/2509.17759)|**[link](https://huggingface.co/datasets/michaelyuanqwq/motiontrans)**|\n", "2509.17244": "|**2025-09-21**|**Scalable Multi Agent Diffusion Policies for Coverage Control**|Frederic Vatnsdal et.al.|[2509.17244](https://arxiv.org/abs/2509.17244)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17204": "|**2025-09-23**|**Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation**|James R. Han et.al.|[2509.17204](https://arxiv.org/abs/2509.17204)|**[link](https://github.com/Shuijing725/awesome-robot-social-navigation)**|\n", "2509.17195": "|**2025-09-21**|**MAST: Multi-Agent Spatial Transformer for Learning to Collaborate**|Damian Owerko et.al.|[2509.17195](https://arxiv.org/abs/2509.17195)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17125": "|**2025-09-21**|**Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation**|Liang Heng et.al.|[2509.17125](https://arxiv.org/abs/2509.17125)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17057": "|**2025-09-21**|**RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments**|Masaki Murooka et.al.|[2509.17057](https://arxiv.org/abs/2509.17057)|**[link](https://github.com/isri-aist/RoboManipBaselines)**|\n", "2509.17053": "|**2025-09-21**|**FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks**|Haizhou Ge et.al.|[2509.17053](https://arxiv.org/abs/2509.17053)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16965": "|**2025-09-21**|**Preference Distillation via Value based Reinforcement Learning**|Minchan Kwon et.al.|[2509.16965](https://arxiv.org/abs/2509.16965)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.16894": "|**2025-09-21**|**End2Race: Efficient End-to-End Imitation Learning for Real-Time F1Tenth Racing**|Zhijie Qiao et.al.|[2509.16894](https://arxiv.org/abs/2509.16894)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19301": "|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Lars Ankile et.al.|[2509.19301](https://arxiv.org/abs/2509.19301)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.19261": "|**2025-09-23**|**Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces**|Kuanqi Cai et.al.|[2509.19261](https://arxiv.org/abs/2509.19261)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19102": "|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Hongli Xu et.al.|[2509.19102](https://arxiv.org/abs/2509.19102)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19080": "|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Zhennan Jiang et.al.|[2509.19080](https://arxiv.org/abs/2509.19080)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.19047": "|**2025-09-23**|**ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation**|Geonhyup Lee et.al.|[2509.19047](https://arxiv.org/abs/2509.19047)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18865": "|**2025-09-23**|**Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation**|Masato Kobayashi et.al.|[2509.18865](https://arxiv.org/abs/2509.18865)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.18778": "|**2025-09-23**|**VGGT-DP: Generalizable Robot Control via Vision Foundation Models**|Shijia Ge et.al.|[2509.18778](https://arxiv.org/abs/2509.18778)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18757": "|**2025-09-23**|**MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning**|Omar Rayyan et.al.|[2509.18757](https://arxiv.org/abs/2509.18757)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18644": "|**2025-09-24**|**Do You Need Proprioceptive States in Visuomotor Policies?**|Juntu Zhao et.al.|[2509.18644](https://arxiv.org/abs/2509.18644)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.18631": "|**2025-09-24**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Shuo Cheng et.al.|[2509.18631](https://arxiv.org/abs/2509.18631)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat et.al.|[2509.18428](https://arxiv.org/abs/2509.18428)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.18404": "|**2025-09-22**|**Zero-Shot Transferable Solution Method for Parametric Optimal Control Problems**|Xingjian Li et.al.|[2509.18404](https://arxiv.org/abs/2509.18404)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18311": "|**2025-09-22**|**Fine-Tuning Robot Policies While Maintaining User Privacy**|Benjamin A. Christie et.al.|[2509.18311](https://arxiv.org/abs/2509.18311)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Pengxiang Li et.al.|[2509.20109](https://arxiv.org/abs/2509.20109)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2509.20070": "|**2025-09-24**|**LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs**|Abraham George et.al.|[2509.20070](https://arxiv.org/abs/2509.20070)|**[link](https://github.com/wendell0218/Awesome-RL-for-Video-Generation)**|\n", "2509.19853": "|**2025-09-24**|**SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process**|BinXu Wu et.al.|[2509.19853](https://arxiv.org/abs/2509.19853)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19658": "|**2025-09-24**|**RoboSSM: Scalable In-context Imitation Learning via State-Space Models**|Youngju Yoo et.al.|[2509.19658](https://arxiv.org/abs/2509.19658)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19626": "|**2025-09-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Ryan Punamiya et.al.|[2509.19626](https://arxiv.org/abs/2509.19626)|**[link](https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence)**|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin et.al.|[2509.19571](https://arxiv.org/abs/2509.19571)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.19460": "|**2025-09-23**|**Self-evolved Imitation Learning in Simulated World**|Yifan Ye et.al.|[2509.19460](https://arxiv.org/abs/2509.19460)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19454": "|**2025-09-23**|**ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation**|Jason Chen et.al.|[2509.19454](https://arxiv.org/abs/2509.19454)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19379": "|**2025-09-20**|**Learning from Observation: A Survey of Recent Advances**|Returaj Burnwal et.al.|[2509.19379](https://arxiv.org/abs/2509.19379)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.21172": "|**2025-09-25**|**Inverse Reinforcement Learning Using Just Classification and a Few Regressions**|Lars van der Laan et.al.|[2509.21172](https://arxiv.org/abs/2509.21172)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|Hanna Yurchyk et.al.|[2509.20579](https://arxiv.org/abs/2509.20579)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo et.al.|[2509.22643](https://arxiv.org/abs/2509.22643)|**[link](https://github.com/OpenHelix-Team/Awesome-VLA-RL)**|\n", "2509.22601": "|**2025-09-26**|**Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning**|Yulei Qin et.al.|[2509.22601](https://arxiv.org/abs/2509.22601)|**[link](https://huggingface.co/models/yolay/SPEAR-ReTool-Qwen2.5-32B)**|\n", "2509.22578": "|**2025-09-26**|**EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation**|Yuan Xu et.al.|[2509.22578](https://arxiv.org/abs/2509.22578)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2509.22550": "|**2025-10-03**|**An Intention-driven Lane Change Framework Considering Heterogeneous Dynamic Cooperation in Mixed-traffic Environment**|Xiaoyun Qiu et.al.|[2509.22550](https://arxiv.org/abs/2509.22550)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22149": "|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Haoqi Yuan et.al.|[2509.22149](https://arxiv.org/abs/2509.22149)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22023": "|**2025-09-26**|**Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error**|Panagiotis Giannoulis et.al.|[2509.22023](https://arxiv.org/abs/2509.22023)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25097": "|**2025-10-01**|**Curriculum Imitation Learning of Distributed Multi-Robot Policies**|Jes\u00fas Roche et.al.|[2509.25097](https://arxiv.org/abs/2509.25097)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24972": "|**2025-09-29**|**Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks**|Vijja Wichitwechkarn et.al.|[2509.24972](https://arxiv.org/abs/2509.24972)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao et.al.|[2509.24948](https://arxiv.org/abs/2509.24948)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Markus Peschl et.al.|[2509.24917](https://arxiv.org/abs/2509.24917)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24784": "|**2025-09-29**|**Quantifying Generalisation in Imitation Learning**|Nathan Gavenski et.al.|[2509.24784](https://arxiv.org/abs/2509.24784)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24697": "|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Evelyn D'Elia et.al.|[2509.24697](https://arxiv.org/abs/2509.24697)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2509.24539": "|**2025-09-29**|**Unlocking the Potential of Soft Actor-Critic for Imitation Learning**|Nayari Marie Lessa et.al.|[2509.24539](https://arxiv.org/abs/2509.24539)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Tomoyuki Kagaya et.al.|[2509.24219](https://arxiv.org/abs/2509.24219)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23829": "|**2025-09-28**|**DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation**|Kefei Zhu et.al.|[2509.23829](https://arxiv.org/abs/2509.23829)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian et.al.|[2509.23823](https://arxiv.org/abs/2509.23823)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.23778": "|**2025-09-30**|**Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse**|Zeyuan Zhao et.al.|[2509.23778](https://arxiv.org/abs/2509.23778)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23220": "|**2025-09-27**|**GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking**|Ye Chen et.al.|[2509.23220](https://arxiv.org/abs/2509.23220)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23203": "|**2025-09-27**|**CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation**|Kai Yang et.al.|[2509.23203](https://arxiv.org/abs/2509.23203)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23112": "|**2025-09-27**|**FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task**|Ryo Watanabe et.al.|[2509.23112](https://arxiv.org/abs/2509.23112)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.23111": "|**2025-09-27**|**Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications**|Chen Yizhe et.al.|[2509.23111](https://arxiv.org/abs/2509.23111)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22914": "|**2025-09-26**|**ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality**|Rohan Walia et.al.|[2509.22914](https://arxiv.org/abs/2509.22914)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26605": "|**2025-09-30**|**Fine-tuning Behavioral Cloning Policies with Preference-Based Reinforcement Learning**|Ma\u00ebl Macuglia et.al.|[2509.26605](https://arxiv.org/abs/2509.26605)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26294": "|**2025-09-30**|**Noise-Guided Transport for Imitation Learning**|Lionel Blond\u00e9 et.al.|[2509.26294](https://arxiv.org/abs/2509.26294)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26137": "|**2025-09-30**|**Accelerating Transformers in Online RL**|Daniil Zelezetsky et.al.|[2509.26137](https://arxiv.org/abs/2509.26137)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25822": "|**2025-10-01**|**Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies**|Jing Wang et.al.|[2509.25822](https://arxiv.org/abs/2509.25822)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25718": "|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Si-Cheng Wang et.al.|[2509.25718](https://arxiv.org/abs/2509.25718)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2509.25466": "|**2025-09-29**|**Data-Efficient Multitask DAgger**|Haotian Fu et.al.|[2509.25466](https://arxiv.org/abs/2509.25466)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25411": "|**2025-09-29**|**Boolean Satisfiability via Imitation Learning**|Zewei Zhang et.al.|[2509.25411](https://arxiv.org/abs/2509.25411)|**[link](https://huggingface.co/models/zeweizhang/ImitSAT)**|\n", "2509.25358": "|**2025-10-02**|**SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation**|Qianzhong Chen et.al.|[2509.25358](https://arxiv.org/abs/2509.25358)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02298": "|**2025-10-02**|**ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation**|Wenye Yu et.al.|[2510.02298](https://arxiv.org/abs/2510.02298)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02268": "|**2025-10-02**|**Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning**|Tianchong Jiang et.al.|[2510.02268](https://arxiv.org/abs/2510.02268)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02180": "|**2025-10-02**|**GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning**|Silvia Sapora et.al.|[2510.02180](https://arxiv.org/abs/2510.02180)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01661": "|**2025-10-02**|**Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation**|Yifei Simon Shao et.al.|[2510.01661](https://arxiv.org/abs/2510.01661)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01635": "|**2025-10-02**|**MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model**|Yifei Chen et.al.|[2510.01635](https://arxiv.org/abs/2510.01635)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01603": "|**2025-10-02**|**MiniBEE: A New Form Factor for Compact Bimanual Dexterity**|Sharfin Islam et.al.|[2510.01603](https://arxiv.org/abs/2510.01603)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01545": "|**2025-10-02**|**Predictive Preference Learning from Human Interventions**|Haoyuan Cai et.al.|[2510.01545](https://arxiv.org/abs/2510.01545)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.01519": "|**2025-10-01**|**Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments**|Wei Han Chen et.al.|[2510.01519](https://arxiv.org/abs/2510.01519)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01479": "|**2025-10-03**|**Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets**|Shriram Karpoora Sundara Pandian et.al.|[2510.01479](https://arxiv.org/abs/2510.01479)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01404": "|**2025-10-01**|**How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?**|Lexi Foland et.al.|[2510.01404](https://arxiv.org/abs/2510.01404)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Arthur Zhang et.al.|[2510.01388](https://arxiv.org/abs/2510.01388)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01023": "|**2025-10-01**|**Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|S. Satsevich et.al.|[2510.01023](https://arxiv.org/abs/2510.01023)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00922": "|**2025-10-01**|**On Discovering Algorithms for Adversarial Imitation Learning**|Shashank Reddy Chirra et.al.|[2510.00922](https://arxiv.org/abs/2510.00922)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00906": "|**2025-10-01**|**TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes**|Julian Lemmel et.al.|[2510.00906](https://arxiv.org/abs/2510.00906)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00814": "|**2025-10-01**|**RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator**|Kai Tang et.al.|[2510.00814](https://arxiv.org/abs/2510.00814)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00739": "|**2025-10-01**|**TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning**|Marco Bagatella et.al.|[2510.00739](https://arxiv.org/abs/2510.00739)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li et.al.|[2510.00406](https://arxiv.org/abs/2510.00406)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2510.00358": "|**2025-09-30**|**DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts**|Linjin He et.al.|[2510.00358](https://arxiv.org/abs/2510.00358)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01272": "|**2025-09-29**|**Modeling Others' Minds as Code**|Kunal Jha et.al.|[2510.01272](https://arxiv.org/abs/2510.01272)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00060": "|**2025-10-03**|**Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving**|Sheng Yang et.al.|[2510.00060](https://arxiv.org/abs/2510.00060)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.03013": "|**2025-10-06**|**Distributional Inverse Reinforcement Learning**|Feiyang Wu et.al.|[2510.03013](https://arxiv.org/abs/2510.03013)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02851": "|**2025-10-03**|**Action Deviation-Aware Inference for Low-Latency Wireless Robots**|Jeyoung Park et.al.|[2510.02851](https://arxiv.org/abs/2510.02851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02738": "|**2025-10-03**|**Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data**|Tianyu Li et.al.|[2510.02738](https://arxiv.org/abs/2510.02738)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02538": "|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Yilin Wang et.al.|[2510.02538](https://arxiv.org/abs/2510.02538)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.02493": "|**2025-10-02**|**Beyond Imitation: Recovering Dense Rewards from Demonstrations**|Jiangnan Li et.al.|[2510.02493](https://arxiv.org/abs/2510.02493)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04592": "|**2025-10-06**|**MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation**|Yilin Mei et.al.|[2510.04592](https://arxiv.org/abs/2510.04592)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04354": "|**2025-10-05**|**Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators**|Apurva Badithela et.al.|[2510.04354](https://arxiv.org/abs/2510.04354)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04333": "|**2025-10-05**|**RAP: 3D Rasterization Augmented End-to-End Planning**|Lan Feng et.al.|[2510.04333](https://arxiv.org/abs/2510.04333)|**[link](https://huggingface.co/models/Lanl11/RAP_ckpts)**|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang et.al.|[2510.04246](https://arxiv.org/abs/2510.04246)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.03885": "|**2025-10-04**|**Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning**|Sunghwan Kim et.al.|[2510.03885](https://arxiv.org/abs/2510.03885)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03706": "|**2025-10-04**|**EmbodiSwap for Zero-Shot Robot Imitation Learning**|Eadom Dessalene et.al.|[2510.03706](https://arxiv.org/abs/2510.03706)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03699": "|**2025-10-04**|**Dissecting Larval Zebrafish Hunting using Deep Reinforcement Learning Trained RNN Agents**|Raaghav Malik et.al.|[2510.03699](https://arxiv.org/abs/2510.03699)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06179": "|**2025-10-07**|**Differentiable Model Predictive Control on the GPU**|Emre Adabag et.al.|[2510.06179](https://arxiv.org/abs/2510.06179)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06127": "|**2025-10-07**|**Towards Autonomous Tape Handling for Robotic Wound Redressing**|Xiao Liang et.al.|[2510.06127](https://arxiv.org/abs/2510.06127)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.06913": "|**2025-10-09**|**DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning**|Ke Guo et.al.|[2510.06913](https://arxiv.org/abs/2510.06913)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2510.06499": "|**2025-10-07**|**Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels**|Zhepeng Cen et.al.|[2510.06499](https://arxiv.org/abs/2510.06499)|**[link](https://huggingface.co/datasets/Salesforce/Webscale-RL)**|\n", "2510.08558": "|**2025-10-13**|**Agent Learning via Early Experience**|Kai Zhang et.al.|[2510.08558](https://arxiv.org/abs/2510.08558)|**[link](https://github.com/DSXiangLi/DecryptPrompt)**|\n", "2510.08547": "|**2025-10-09**|**R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation**|Xiuwei Xu et.al.|[2510.08547](https://arxiv.org/abs/2510.08547)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|\n", "2510.07562": "|**2025-10-08**|**EBGAN-MDN: An Energy-Based Adversarial Framework for Multi-Modal Behavior Cloning**|Yixiao Li et.al.|[2510.07562](https://arxiv.org/abs/2510.07562)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09543": "|**2025-10-13**|**Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards**|Chenghao Wang et.al.|[2510.09543](https://arxiv.org/abs/2510.09543)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09497": "|**2025-10-10**|**Autonomous Soft Robotic Guidewire Navigation via Imitation Learning**|Noah Barnes et.al.|[2510.09497](https://arxiv.org/abs/2510.09497)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09487": "|**2025-10-13**|**Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning**|Shangzhe Li et.al.|[2510.09487](https://arxiv.org/abs/2510.09487)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2510.09459": "|**2025-10-13**|**Failure Prediction at Runtime for Generative Robot Policies**|Ralf R\u00f6mer et.al.|[2510.09459](https://arxiv.org/abs/2510.09459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09325": "|**2025-10-10**|**Rate optimal learning of equilibria from data**|Till Freihaut et.al.|[2510.09325](https://arxiv.org/abs/2510.09325)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09229": "|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Yuyang Gao et.al.|[2510.09229](https://arxiv.org/abs/2510.09229)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09222": "|**2025-10-13**|**FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning**|Zhenglin Wan et.al.|[2510.09222](https://arxiv.org/abs/2510.09222)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09096": "|**2025-10-10**|**When a Robot is More Capable than a Human: Learning from Constrained Demonstrators**|Xinhu Li et.al.|[2510.09096](https://arxiv.org/abs/2510.09096)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09036": "|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Chuanrui Zhang et.al.|[2510.09036](https://arxiv.org/abs/2510.09036)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2510.08787": "|**2025-10-09**|**Geometry-aware Policy Imitation**|Yiming Li et.al.|[2510.08787](https://arxiv.org/abs/2510.08787)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.08627": "|**2025-10-08**|**A Denoising Diffusion-Based Evolutionary Algorithm Framework: Application to the Maximum Independent Set Problem**|Joan Salv\u00e0 Soler et.al.|[2510.08627](https://arxiv.org/abs/2510.08627)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11307": "|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Sabrina McCallum et.al.|[2510.11307](https://arxiv.org/abs/2510.11307)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.11258": "|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Yuhui Fu et.al.|[2510.11258](https://arxiv.org/abs/2510.11258)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2510.11083": "|**2025-10-13**|**Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling**|Tianyi Tan et.al.|[2510.11083](https://arxiv.org/abs/2510.11083)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.10865": "|**2025-10-13**|**GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments**|Ahmed Alanazi et.al.|[2510.10865](https://arxiv.org/abs/2510.10865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10451": "|**2025-10-12**|**Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning**|Keisuke Fujii et.al.|[2510.10451](https://arxiv.org/abs/2510.10451)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10221": "|**2025-10-11**|**A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots**|Hyogo Hiruma et.al.|[2510.10221](https://arxiv.org/abs/2510.10221)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10217": "|**2025-10-11**|**UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction**|Hyogo Hiruma et.al.|[2510.10217](https://arxiv.org/abs/2510.10217)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09817": "|**2025-10-10**|**Cross-Sensor Touch Generation**|Samanta Rodriguez et.al.|[2510.09817](https://arxiv.org/abs/2510.09817)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|\n", "2510.12689": "|**2025-10-14**|**From Delegates to Trustees: How Optimizing for Long-Term Interests Shapes Bias and Alignment in LLM**|Suyash Fulay et.al.|[2510.12689](https://arxiv.org/abs/2510.12689)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12638": "|**2025-10-14**|**Expert or not? assessing data quality in offline reinforcement learning**|Arip Asadulaev et.al.|[2510.12638](https://arxiv.org/abs/2510.12638)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12560": "|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Xiaoji Zheng et.al.|[2510.12560](https://arxiv.org/abs/2510.12560)|**[link](https://huggingface.co/models/Student-Xiaoji/CoIRL-AD-models)**|\n", "2510.12403": "|**2025-10-14**|**Robot Learning: A Tutorial**|Francesco Capuano et.al.|[2510.12403](https://arxiv.org/abs/2510.12403)|**[link](https://huggingface.co/spaces/lerobot/robot-learning-tutorial)**|\n", "2510.12392": "|**2025-10-14**|**Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking**|Junhyuk So et.al.|[2510.12392](https://arxiv.org/abs/2510.12392)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13324": "|**2025-10-15**|**Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation**|Erik Helmut et.al.|[2510.13324](https://arxiv.org/abs/2510.13324)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.13229": "|**2025-10-15**|**Beyond Static LLM Policies: Imitation-Enhanced Reinforcement Learning for Recommendation**|Yi Zhang et.al.|[2510.13229](https://arxiv.org/abs/2510.13229)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14930": "|**2025-10-18**|**VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning**|Binghao Huang et.al.|[2510.14930](https://arxiv.org/abs/2510.14930)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2510.14851": "|**2025-10-16**|**SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time**|Jakob Bichler et.al.|[2510.14851](https://arxiv.org/abs/2510.14851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14830": "|**2025-11-03**|**RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning**|Kun Lei et.al.|[2510.14830](https://arxiv.org/abs/2510.14830)|**[link](https://github.com/YanjieZe/3D-Diffusion-Policy)**|\n", "2510.14771": "|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Xu Chi et.al.|[2510.14771](https://arxiv.org/abs/2510.14771)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.14467": "|**2025-10-16**|**Restoring Noisy Demonstration for Imitation Learning With Diffusion Models**|Shang-Fu Chen et.al.|[2510.14467](https://arxiv.org/abs/2510.14467)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15530": "|**2025-11-03**|**VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation**|Zehao Ni et.al.|[2510.15530](https://arxiv.org/abs/2510.15530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15510": "|**2025-10-17**|**Exploring Conditions for Diffusion models in Robotic Control**|Heeseong Shin et.al.|[2510.15510](https://arxiv.org/abs/2510.15510)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15505": "|**2025-10-17**|**Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving**|Aron Distelzweig et.al.|[2510.15505](https://arxiv.org/abs/2510.15505)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15464": "|**2025-10-17**|**Learning to Answer from Correct Demonstrations**|Nirmit Joshi et.al.|[2510.15464](https://arxiv.org/abs/2510.15464)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15388": "|**2025-10-17**|**Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning**|Mingyang Sun et.al.|[2510.15388](https://arxiv.org/abs/2510.15388)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.15189": "|**2025-10-16**|**RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation**|Xiangyu Chen et.al.|[2510.15189](https://arxiv.org/abs/2510.15189)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Yuquan Xue et.al.|[2510.17640](https://arxiv.org/abs/2510.17640)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.17531": "|**2025-10-20**|**Plasma Shape Control via Zero-shot Generative Reinforcement Learning**|Niannian Wu et.al.|[2510.17531](https://arxiv.org/abs/2510.17531)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17143": "|**2025-10-20**|**Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning**|Shantnav Agarwal et.al.|[2510.17143](https://arxiv.org/abs/2510.17143)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17038": "|**2025-10-19**|**DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation**|Pedram Fekri et.al.|[2510.17038](https://arxiv.org/abs/2510.17038)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16774": "|**2025-10-19**|**Learning to play: A Multimodal Agent for 3D Game-Play**|Yuguang Yue et.al.|[2510.16774](https://arxiv.org/abs/2510.16774)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16462": "|**2025-10-18**|**Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making**|Emmanuelle Claeys et.al.|[2510.16462](https://arxiv.org/abs/2510.16462)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.16424": "|**2025-10-18**|**Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach**|Dan Guo et.al.|[2510.16424](https://arxiv.org/abs/2510.16424)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18316": "|**2025-10-21**|**MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation**|Chengshu Li et.al.|[2510.18316](https://arxiv.org/abs/2510.18316)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18085": "|**2025-10-20**|**R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations**|Connor Mattson et.al.|[2510.18085](https://arxiv.org/abs/2510.18085)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18060": "|**2025-10-20**|**SPACeR: Self-Play Anchoring with Centralized Reference Models**|Wei-Jer Chang et.al.|[2510.18060](https://arxiv.org/abs/2510.18060)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19495": "|**2025-10-25**|**Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning**|Kevin Huang et.al.|[2510.19495](https://arxiv.org/abs/2510.19495)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19356": "|**2025-10-22**|**Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model**|Yu Fang et.al.|[2510.19356](https://arxiv.org/abs/2510.19356)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.19307": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Byung-Kwan Lee et.al.|[2510.19307](https://arxiv.org/abs/2510.19307)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20406": "|**2025-10-23**|**PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning**|Xiaogang Jia et.al.|[2510.20406](https://arxiv.org/abs/2510.20406)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20150": "|**2025-10-24**|**Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning**|Yaochen Zhu et.al.|[2510.20150](https://arxiv.org/abs/2510.20150)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20040": "|**2025-10-22**|**Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning**|Changrui Liu et.al.|[2510.20040](https://arxiv.org/abs/2510.20040)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.21090": "|**2025-10-24**|**Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only**|Qingru Zhang et.al.|[2510.21090](https://arxiv.org/abs/2510.21090)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Jesse Haworth et.al.|[2510.20965](https://arxiv.org/abs/2510.20965)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2510.23184": "|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Junho Kim et.al.|[2510.23184](https://arxiv.org/abs/2510.23184)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.23016": "|**2025-10-27**|**ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation**|Zhuo Li et.al.|[2510.23016](https://arxiv.org/abs/2510.23016)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22718": "|**2025-10-26**|**Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication**|Yujie Wan et.al.|[2510.22718](https://arxiv.org/abs/2510.22718)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.22641": "|**2025-10-26**|**FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference**|Divya Jyoti Bajpai et.al.|[2510.22641](https://arxiv.org/abs/2510.22641)|**[link](https://github.com/chenhongyu2048/LLM-inference-optimization-paper)**|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Minho Park et.al.|[2510.22201](https://arxiv.org/abs/2510.22201)|**[link](https://huggingface.co/models/DAVIAN-Robotics/GR00T-N1-2B-tuned-RoboCasa-MG100-FrankaPandaGripper)**|\n", "2510.21771": "|**2025-10-17**|**Improving the performance of AI-powered Affordable Robotics for Assistive Tasks**|Dharunish Yugeswardeenoo et.al.|[2510.21771](https://arxiv.org/abs/2510.21771)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24680": "|**2025-10-28**|**Fare: Failure Resilience in Learned Visual Navigation Control**|Zishuo Wang et.al.|[2510.24680](https://arxiv.org/abs/2510.24680)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24650": "|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Nitin Rai et.al.|[2510.24650](https://arxiv.org/abs/2510.24650)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24461": "|**2025-10-28**|**Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks**|Korneel Van den Berghe et.al.|[2510.24461](https://arxiv.org/abs/2510.24461)|**[link](https://github.com/TheBrainLab/Awesome-Spiking-Neural-Networks)**|\n", "2510.24194": "|**2025-10-28**|**Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames**|Ev Zisselman et.al.|[2510.24194](https://arxiv.org/abs/2510.24194)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24108": "|**2025-10-28**|**ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring**|Zhenxin Li et.al.|[2510.24108](https://arxiv.org/abs/2510.24108)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24055": "|**2025-10-28**|**Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation**|Xiucheng Zhang et.al.|[2510.24055](https://arxiv.org/abs/2510.24055)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Wang zhi et.al.|[2510.25268](https://arxiv.org/abs/2510.25268)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.24988": "|**2025-10-28**|**Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series**|Hemanath Arumugam et.al.|[2510.24988](https://arxiv.org/abs/2510.24988)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2510.26670": "|**2025-10-30**|**Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation**|Qianyou Zhao et.al.|[2510.26670](https://arxiv.org/abs/2510.26670)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26438": "|**2025-10-31**|**An Impulse Control Approach to Market Making in a Hawkes LOB Market**|Konark Jain et.al.|[2510.26438](https://arxiv.org/abs/2510.26438)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26406": "|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Guanxing Lu et.al.|[2510.26406](https://arxiv.org/abs/2510.26406)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26292": "|**2025-10-30**|**Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving**|Lin Liu et.al.|[2510.26292](https://arxiv.org/abs/2510.26292)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2510.26165": "|**2025-10-30**|**Learning to Manage Investment Portfolios beyond Simple Utility Functions**|Maarten P. Scholl et.al.|[2510.26165](https://arxiv.org/abs/2510.26165)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27630": "|**2025-11-03**|**Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training**|Dayuan Fu et.al.|[2510.27630](https://arxiv.org/abs/2510.27630)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27545": "|**2025-10-31**|**EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities**|Travis Davies et.al.|[2510.27545](https://arxiv.org/abs/2510.27545)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27334": "|**2025-10-31**|**When AI Trading Agents Compete: Adverse Selection of Meta-Orders by Reinforcement Learning-Based Market Making**|Ali Raza Jafree et.al.|[2510.27334](https://arxiv.org/abs/2510.27334)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.27114": "|**2025-10-31**|**Learning Generalizable Visuomotor Policy through Dynamics-Alignment**|Dohyeok Lee et.al.|[2510.27114](https://arxiv.org/abs/2510.27114)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.02807": "|**2025-11-04**|**Audience Amplified: Virtual Audiences in Asynchronously Performed AR Theater**|You-Jin Kim et.al.|[2511.02807](https://arxiv.org/abs/2511.02807)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.02504": "|**2025-11-04**|**Dexterous Robotic Piano Playing at Scale**|Le Chen et.al.|[2511.02504](https://arxiv.org/abs/2511.02504)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.01083": "|**2025-11-02**|**Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment**|Zihan Wang et.al.|[2511.01083](https://arxiv.org/abs/2511.01083)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00998": "|**2025-11-02**|**GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies**|Ziye Wang et.al.|[2511.00998](https://arxiv.org/abs/2511.00998)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2511.00555": "|**2025-11-01**|**Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy**|Dianye Huang et.al.|[2511.00555](https://arxiv.org/abs/2511.00555)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00153": "|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Justin Yu et.al.|[2511.00153](https://arxiv.org/abs/2511.00153)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.00088": "|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|NVIDIA et.al.|[2511.00088](https://arxiv.org/abs/2511.00088)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03616": "|**2025-11-05**|**Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning**|Iason Chrysomallis et.al.|[2511.03616](https://arxiv.org/abs/2511.03616)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03565": "|**2025-11-05**|**Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances**|Iason Chrysomallis et.al.|[2511.03565](https://arxiv.org/abs/2511.03565)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03181": "|**2025-11-05**|**Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control**|Rewida Ali et.al.|[2511.03181](https://arxiv.org/abs/2511.03181)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03077": "|**2025-11-04**|**WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models**|R. Khorrambakht et.al.|[2511.03077](https://arxiv.org/abs/2511.03077)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04357": "|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Ma\u00eblic Neau et.al.|[2511.04357](https://arxiv.org/abs/2511.04357)|**[link](https://github.com/ChocoWu/Awesome-Scene-Graph-Generation)**|\n", "2511.03882": "|**2025-11-05**|**Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures**|Florence Klitzner et.al.|[2511.03882](https://arxiv.org/abs/2511.03882)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05158": "|**2025-11-07**|**Follow-Me in Micro-Mobility with End-to-End Imitation Learning**|Sahar Salimpour et.al.|[2511.05158](https://arxiv.org/abs/2511.05158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05094": "|**2025-11-07**|**FM4Com: Foundation Model for Scene-Adaptive Communication Strategy Optimization**|Zhaoyang Li et.al.|[2511.05094](https://arxiv.org/abs/2511.05094)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.04831": "|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|NVIDIA et.al.|[2511.04831](https://arxiv.org/abs/2511.04831)|**[link](https://github.com/isaac-sim/IsaacLab)**|\n", "2511.04812": "|**2025-11-06**|**Unified Multimodal Diffusion Forcing for Forceful Manipulation**|Zixuan Huang et.al.|[2511.04812](https://arxiv.org/abs/2511.04812)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.07288": "|**2025-11-10**|**Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization**|Sayambhu Sen et.al.|[2511.07288](https://arxiv.org/abs/2511.07288)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.05855": "|**2025-11-08**|**Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills**|Jiayu Zhou et.al.|[2511.05855](https://arxiv.org/abs/2511.05855)|**[link](https://github.com/NathanWu7/NathanWu7)**|\n", "2511.05680": "|**2025-11-07**|**VLM-driven Skill Selection for Robotic Assembly Tasks**|Jeong-Jung Kim et.al.|[2511.05680](https://arxiv.org/abs/2511.05680)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2408.10568": "|**2024-08-21**|**Constrained Behavior Cloning for Robotic Learning**|Wensheng Liang et.al.|[2408.10568](https://arxiv.org/abs/2408.10568)|**[link](https://github.com/Boxjod/RLBench_ACT)**|\n", "2010.04767": "|**2021-10-19**|**Robust Behavioral Cloning for Autonomous Vehicles using End-to-End Imitation Learning**|Tanmay Vilas Samak et.al.|[2010.04767](https://arxiv.org/abs/2010.04767)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2407.15007": "|**2024-12-03**|**Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning**|Dylan J. Foster et.al.|[2407.15007](https://arxiv.org/abs/2407.15007)|**[link](https://github.com/KentoNishi/awesome-all-you-need-papers)**|\n", "2008.01205": "|**2020-08-05**|**Concurrent Training Improves the Performance of Behavioral Cloning from Observation**|Zachary W. Robertson et.al.|[2008.01205](https://arxiv.org/abs/2008.01205)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2502.07645": "|**2025-10-10**|**Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning**|Zhaoting Li et.al.|[2502.07645](https://arxiv.org/abs/2502.07645)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2211.04005": "|**2022-11-09**|**ABC: Adversarial Behavioral Cloning for Offline Mode-Seeking Imitation Learning**|Eddy Hudson et.al.|[2211.04005](https://arxiv.org/abs/2211.04005)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1904.08980": "|**2019-04-22**|**Exploring the Limitations of Behavior Cloning for Autonomous Driving**|Felipe Codevilla et.al.|[1904.08980](https://arxiv.org/abs/1904.08980)|**[link](https://github.com/zhulf0804/3D-PointCloud)**|\n", "2302.13335": "|**2024-06-04**|**Diffusion Model-Augmented Behavioral Cloning**|Shang-Fu Chen et.al.|[2302.13335](https://arxiv.org/abs/2302.13335)|**[link](https://github.com/EmbodiedMind/DiffusionPolicy-Robotics)**|\n", "2008.12969": "|**2020-09-01**|**Driving Through Ghosts: Behavioral Cloning with False Positives**|Andreas B\u00fchler et.al.|[2008.12969](https://arxiv.org/abs/2008.12969)|**[link](https://github.com/PaoPaoRobot/IROS2020-paper-list)**|\n", "2202.09271": "|**2022-02-21**|**Enhanced Behavioral Cloning with Environmental Losses for Self-Driving Vehicles**|Nelson Fernandez Pinto et.al.|[2202.09271](https://arxiv.org/abs/2202.09271)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2206.00695": "|**2022-06-03**|**Know Your Boundaries: The Necessity of Explicit Behavioral Cloning in Offline RL**|Wonjoon Goo et.al.|[2206.00695](https://arxiv.org/abs/2206.00695)|**[link](https://github.com/hanjuku-kaso/awesome-offline-rl)**|\n", "1904.03438": "|**2019-08-27**|**Reinforced Imitation in Heterogeneous Action Space**|Konrad Zolna et.al.|[1904.03438](https://arxiv.org/abs/1904.03438)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1703.03121": "|**2018-05-28**|**Coordinated Multi-Agent Imitation Learning**|Hoang M. Le et.al.|[1703.03121](https://arxiv.org/abs/1703.03121)|**[link](https://github.com/zziz/pwc)**|\n", "1907.03976": "|**2019-10-15**|**Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations**|Daniel S. Brown et.al.|[1907.03976](https://arxiv.org/abs/1907.03976)|**[link](https://github.com/kristery/Awesome-Imitation-Learning)**|\n", "2307.14619": "|**2023-10-25**|**Provable Guarantees for Generative Behavior Cloning: Bridging Low-Level Stability and High-Level Behavior**|Adam Block et.al.|[2307.14619](https://arxiv.org/abs/2307.14619)|**[link](https://github.com/YanjieZe/Paper-List)**|\n", "2205.10816": "|**2022-05-24**|**Chain of Thought Imitation with Procedure Cloning**|Mengjiao Yang et.al.|[2205.10816](https://arxiv.org/abs/2205.10816)|**[link](https://huggingface.co/datasets/OpenDILabCommunity/Pong-v4-expert-MCTS)**|\n", "2306.00323": "|**2024-01-19**|**Thought Cloning: Learning to Think while Acting by Imitating Human Thinking**|Shengran Hu et.al.|[2306.00323](https://arxiv.org/abs/2306.00323)|**[link](https://github.com/ShengranHu/Thought-Cloning)**|\n", "2506.19250": "|**2025-08-12**|**Robust Behavior Cloning Via Global Lipschitz Regularization**|Shili Wu et.al.|[2506.19250](https://arxiv.org/abs/2506.19250)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2302.04334": "|**2023-02-10**|**Asking for Help: Failure Prediction in Behavioral Cloning through Value Approximation**|Cem Gokmen et.al.|[2302.04334](https://arxiv.org/abs/2302.04334)|**[link](https://github.com/ryanbgriffiths/ICRA2023PaperList)**|\n", "2008.00524": "|**2022-03-09**|**Interactive Imitation Learning in State-Space**|Snehal Jauhri et.al.|[2008.00524](https://arxiv.org/abs/2008.00524)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2505.10760": "|**2025-05-19**|**Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations**|Shahabedin Sagheb et.al.|[2505.10760](https://arxiv.org/abs/2505.10760)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2109.00137": "|**2021-09-02**|**Implicit Behavioral Cloning**|Pete Florence et.al.|[2109.00137](https://arxiv.org/abs/2109.00137)|**[link](https://github.com/hanjuku-kaso/awesome-offline-rl)**|\n", "2002.11197": "|**2020-02-27**|**Behavior Cloning in OpenAI using Case Based Reasoning**|Chad Peters et.al.|[2002.11197](https://arxiv.org/abs/2002.11197)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2408.06246": "|**2024-08-13**|**Stable-BC: Controlling Covariate Shift with Stable Behavior Cloning**|Shaunak A. Mehta et.al.|[2408.06246](https://arxiv.org/abs/2408.06246)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1907.03423": "|**2020-05-19**|**On-Policy Robot Imitation Learning from a Converging Supervisor**|Ashwin Balakrishna et.al.|[1907.03423](https://arxiv.org/abs/1907.03423)|**[link](https://github.com/kristery/Awesome-Imitation-Learning)**|\n", "1812.05841": "|**2018-12-17**|**Imitation Learning for End to End Vehicle Longitudinal Control with Forward Camera**|Laurent George et.al.|[1812.05841](https://arxiv.org/abs/1812.05841)|**[link](https://github.com/gopala-kr/summary)**|\n", "1805.01954": "|**2018-05-15**|**Behavioral Cloning from Observation**|Faraz Torabi et.al.|[1805.01954](https://arxiv.org/abs/1805.01954)|**[link](https://github.com/hanjuku-kaso/awesome-offline-rl)**|\n", "2007.05740": "|**2021-12-14**|**Enhanced Behavioral Cloning Based self-driving Car Using Transfer Learning**|Uppala Sumanth et.al.|[2007.05740](https://arxiv.org/abs/2007.05740)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1709.04905": "|**2017-09-15**|**One-Shot Visual Imitation Learning via Meta-Learning**|Chelsea Finn et.al.|[1709.04905](https://arxiv.org/abs/1709.04905)|**[link](https://github.com/floodsung/Meta-Learning-Papers)**|\n", "2410.07209": "|**2024-10-11**|**Behavior Cloning for Mini Autonomous Car Path Following**|Pablo Moraes et.al.|[2410.07209](https://arxiv.org/abs/2410.07209)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2503.06869": "|**2025-03-11**|**Collective Behavior Clone with Visual Attention via Neural Interaction Graph Prediction**|Kai Li et.al.|[2503.06869](https://arxiv.org/abs/2503.06869)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2105.06411": "|**2021-06-11**|**Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration**|Edward Johns et.al.|[2105.06411](https://arxiv.org/abs/2105.06411)|**[link](https://github.com/dectrfov/ICRA2021PaperList)**|\n", "2412.07617": "|**2024-12-11**|**Swarm Behavior Cloning**|Jonas N\u00fc\u00dflein et.al.|[2412.07617](https://arxiv.org/abs/2412.07617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2411.18201": "|**2024-11-28**|**Learning for Long-Horizon Planning via Neuro-Symbolic Abductive Imitation**|Jie-Jing Shao et.al.|[2411.18201](https://arxiv.org/abs/2411.18201)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2306.09082": "|**2023-06-16**|**Behavioral Cloning via Search in Embedded Demonstration Dataset**|Federico Malato et.al.|[2306.09082](https://arxiv.org/abs/2306.09082)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1910.04281": "|**2020-04-07**|**Integrating Behavior Cloning and Reinforcement Learning for Improved Performance in Dense and Sparse Reward Environments**|Vinicius G. Goecks et.al.|[1910.04281](https://arxiv.org/abs/1910.04281)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2309.10175": "|**2023-09-20**|**One ACT Play: Single Demonstration Behavior Cloning with Action Chunking Transformers**|Abraham George et.al.|[2309.10175](https://arxiv.org/abs/2309.10175)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2206.11251": "|**2022-10-13**|**Behavior Transformers: Cloning $k$ modes with one stone**|Nur Muhammad Mahi Shafiullah et.al.|[2206.11251](https://arxiv.org/abs/2206.11251)|**[link](https://github.com/hanjuku-kaso/awesome-offline-rl)**|\n", "2409.07218": "|**2024-09-12**|**Behavioral Cloning Models Reality Check for Autonomous Driving**|Mustafa Yildirim et.al.|[2409.07218](https://arxiv.org/abs/2409.07218)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2204.05618": "|**2022-04-13**|**When Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning?**|Aviral Kumar et.al.|[2204.05618](https://arxiv.org/abs/2204.05618)|**[link](https://github.com/hanjuku-kaso/awesome-offline-rl)**|\n", "1911.07027": "|**2019-11-19**|**On Value Discrepancy of Imitation Learning**|Tian Xu et.al.|[1911.07027](https://arxiv.org/abs/1911.07027)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2104.00123": "|**2021-04-02**|**Generalized Reinforcement Learning for Building Control using Behavioral Cloning**|Zachary E. Lee et.al.|[2104.00123](https://arxiv.org/abs/2104.00123)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1910.06734": "|**2019-10-16**|**Self Driving RC Car using Behavioral Cloning**|Aliasgar Haji et.al.|[1910.06734](https://arxiv.org/abs/1910.06734)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1701.06699": "|**2017-01-25**|**Imitating Driver Behavior with Generative Adversarial Networks**|Alex Kuefler et.al.|[1701.06699](https://arxiv.org/abs/1701.06699)|**[link](https://github.com/nightrome/really-awesome-gan)**|\n", "2006.04678": "|**2021-03-18**|**Primal Wasserstein Imitation Learning**|Robert Dadashi et.al.|[2006.04678](https://arxiv.org/abs/2006.04678)|**[link](https://github.com/Kaixhin/imitation-learning)**|\n", "2506.10137": "|**2025-10-16**|**Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning**|Daniel Lawson et.al.|[2506.10137](https://arxiv.org/abs/2506.10137)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1811.11441": "|**2018-12-18**|**Trajectory-based Learning for Ball-in-Maze Games**|Sujoy Paul et.al.|[1811.11441](https://arxiv.org/abs/1811.11441)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10110": "|**2025-11-13**|**Learning a Thousand Tasks in a Day**|Kamil Dreczkowski et.al.|[2511.10110](https://arxiv.org/abs/2511.10110)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09932": "|**2025-11-13**|**A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation**|Hanwen Wang et.al.|[2511.09932](https://arxiv.org/abs/2511.09932)|**[link](https://github.com/NickDee96/ASR-TTS-paper-daily)**|\n", "2511.09839": "|**2025-11-13**|**Evolving Rules: Imitation and Best Response Learning in Cournot Oligopoly**|Xiaomeng Ding et.al.|[2511.09839](https://arxiv.org/abs/2511.09839)|null|\n", "2511.09727": "|**2025-11-12**|**Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard**|Stelios Zarifis et.al.|[2511.09727](https://arxiv.org/abs/2511.09727)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.09661": "|**2025-11-18**|**Statistically Consistent Approximate Model Predictive Control**|Elias Milios et.al.|[2511.09661](https://arxiv.org/abs/2511.09661)|null|\n", "2511.09302": "|**2025-11-12**|**UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning**|Yan Huang et.al.|[2511.09302](https://arxiv.org/abs/2511.09302)|null|\n", "2511.08583": "|**2025-11-11**|**SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment**|Rong Xue et.al.|[2511.08583](https://arxiv.org/abs/2511.08583)|null|\n", "2511.08214": "|**2025-11-11**|**Prioritizing Perception-Guided Self-Supervision: A New Paradigm for Causal Modeling in End-to-End Autonomous Driving**|Yi Huang et.al.|[2511.08214](https://arxiv.org/abs/2511.08214)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.08136": "|**2025-11-14**|**SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories**|Returaj Burnwal et.al.|[2511.08136](https://arxiv.org/abs/2511.08136)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.07942": "|**2025-11-11**|**Balance Equation-based Distributionally Robust Offline Imitation Learning**|Rishabh Agrawal et.al.|[2511.07942](https://arxiv.org/abs/2511.07942)|null|\n", "2511.07619": "|**2025-11-10**|**CAVER: Curious Audiovisual Exploring Robot**|Luca Macesanu et.al.|[2511.07619](https://arxiv.org/abs/2511.07619)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.06976": "|**2025-11-10**|**Rethinking Crystal Symmetry Prediction: A Decoupled Perspective**|Liheng Yu et.al.|[2511.06976](https://arxiv.org/abs/2511.06976)|**[link](https://github.com/baigeiguai/XRDecoupler)**|\n", "2511.05778": "|**2025-11-08**|**TOPSIS-like metaheuristic for LABS problem**|Aleksandra Urba\u0144czyk et.al.|[2511.05778](https://arxiv.org/abs/2511.05778)|null|\n", "2511.04137": "|**2025-11-06**|**Learning from Online Videos at Inference Time for Computer-Use Agents**|Yujian Liu et.al.|[2511.04137](https://arxiv.org/abs/2511.04137)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.03996": "|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Yushi Wang et.al.|[2511.03996](https://arxiv.org/abs/2511.03996)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.03828": "|**2025-11-05**|**From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification**|Lipeng Zu et.al.|[2511.03828](https://arxiv.org/abs/2511.03828)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01181": "|**2025-11-03**|**Learning When to Quit in Sales Conversations**|Emaad Manzoor et.al.|[2511.01181](https://arxiv.org/abs/2511.01181)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01924": "|**2025-11-02**|**Neural Green's Functions**|Seungwoo Yoo et.al.|[2511.01924](https://arxiv.org/abs/2511.01924)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26954": "|**2025-10-30**|**Can machines think efficiently?**|Adam Winchell et.al.|[2510.26954](https://arxiv.org/abs/2510.26954)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.26020": "|**2025-10-29**|**PORTool: Tool-Use LLM Training with Rewarded Tree**|Feijie Wu et.al.|[2510.26020](https://arxiv.org/abs/2510.26020)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.25992": "|**2025-10-29**|**Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning**|Yihe Deng et.al.|[2510.25992](https://arxiv.org/abs/2510.25992)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11131": "|**2025-11-14**|**Convergence of Flow-Policy Gradient Learning for Linear Quadratic Regulator Problems**|Farnaz Adib Yaghmaie et.al.|[2511.11131](https://arxiv.org/abs/2511.11131)|null|\n", "2511.11043": "|**2025-11-24**|**Autonomous Vehicle Path Planning by Searching With Differentiable Simulation**|Asen Nachkov et.al.|[2511.11043](https://arxiv.org/abs/2511.11043)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.13306": "|**2025-11-17**|**DAP: A Discrete-token Autoregressive Planner for Autonomous Driving**|Bowen Ye et.al.|[2511.13306](https://arxiv.org/abs/2511.13306)|null|\n", "2511.12986": "|**2025-11-17**|**Learning Branching Policies for MILPs with Proximal Policy Optimization**|Abdelouahed Ben Mhamed et.al.|[2511.12986](https://arxiv.org/abs/2511.12986)|null|\n", "2511.12848": "|**2025-11-17**|**Structured Imitation Learning of Interactive Policies through Inverse Games**|Max M. Sun et.al.|[2511.12848](https://arxiv.org/abs/2511.12848)|null|\n", "2511.12101": "|**2025-11-15**|**Decoupled Action Head: Confining Task Knowledge to Conditioning Layers**|Jian Zhou et.al.|[2511.12101](https://arxiv.org/abs/2511.12101)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11997": "|**2025-11-15**|**Imitation Learning with Safety and L2 Stability Certificates for Boundary Control of Reaction-Diffusion PDEs**|Paulo Henrique Foganholo Biazetto et.al.|[2511.11997](https://arxiv.org/abs/2511.11997)|null|\n", "2511.11931": "|**2025-11-14**|**MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy**|Saida Liu et.al.|[2511.11931](https://arxiv.org/abs/2511.11931)|**[link](https://github.com/CINAPSLab/MATT-Diff)**|\n", "2511.11870": "|**2025-11-14**|**Graph-Based Imitation and Reinforcement Learning for Efficient Benders Decomposition**|Bernard T. Agyeman et.al.|[2511.11870](https://arxiv.org/abs/2511.11870)|null|\n", "2511.14396": "|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi et.al.|[2511.14396](https://arxiv.org/abs/2511.14396)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13765": "|**2025-11-14**|**PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning**|Shengjie Sun et.al.|[2511.13765](https://arxiv.org/abs/2511.13765)|null|\n", "2511.15520": "|**2025-11-19**|**Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies**|Gabriel Lauzier et.al.|[2511.15520](https://arxiv.org/abs/2511.15520)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15407": "|**2025-11-19**|**IPR-1: Interactive Physical Reasoner**|Mingyu Zhang et.al.|[2511.15407](https://arxiv.org/abs/2511.15407)|null|\n", "2511.15292": "|**2025-11-19**|**Adversarial Attack on Black-Box Multi-Agent by Adaptive Perturbation**|Jianming Chen et.al.|[2511.15292](https://arxiv.org/abs/2511.15292)|**[link](https://github.com/JMChen121/AdapAM)**|\n", "2511.15200": "|**2025-11-27**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Tairan He et.al.|[2511.15200](https://arxiv.org/abs/2511.15200)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2511.16407": "|**2025-11-20**|**LAOF: Robust Latent Action Learning with Optical Flow Constraints**|Xizhou Bu et.al.|[2511.16407](https://arxiv.org/abs/2511.16407)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16223": "|**2025-11-20**|**DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks**|Vincenzo Pomponi et.al.|[2511.16223](https://arxiv.org/abs/2511.16223)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.16050": "|**2025-11-20**|**Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers**|Takeru Tsunoori et.al.|[2511.16050](https://arxiv.org/abs/2511.16050)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17001": "|**2025-11-21**|**Stable Offline Hand-Eye Calibration for any Robot with Just One Mark**|Sicheng Xie et.al.|[2511.17001](https://arxiv.org/abs/2511.17001)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.19033": "|**2025-11-24**|**ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay**|Gengyuan Zhang et.al.|[2511.19033](https://arxiv.org/abs/2511.19033)|null|\n", "2511.18958": "|**2025-11-25**|**Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation**|Qisen Chai et.al.|[2511.18958](https://arxiv.org/abs/2511.18958)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.18617": "|**2025-11-25**|**AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations**|Litian Gong et.al.|[2511.18617](https://arxiv.org/abs/2511.18617)|null|\n", "2511.18299": "|**2025-11-23**|**MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing**|Steven Oh et.al.|[2511.18299](https://arxiv.org/abs/2511.18299)|null|\n", "2511.18140": "|**2025-11-22**|**Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting**|Yilong Wang et.al.|[2511.18140](https://arxiv.org/abs/2511.18140)|null|\n", "2511.17595": "|**2025-11-17**|**Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design**|Markus D. Solbach et.al.|[2511.17595](https://arxiv.org/abs/2511.17595)|null|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Jiahui Zhang et.al.|[2511.20633](https://arxiv.org/abs/2511.20633)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.20216": "|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Haebin Seong et.al.|[2511.20216](https://arxiv.org/abs/2511.20216)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20095": "|**2025-11-25**|**WPT: World-to-Policy Transfer via Online World Model Distillation**|Guangfeng Jiang et.al.|[2511.20095](https://arxiv.org/abs/2511.20095)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2511.20094": "|**2025-11-25**|**The Making of Digital Ghosts: Designing Ethical AI Afterlives**|Giovanni Spitale et.al.|[2511.20094](https://arxiv.org/abs/2511.20094)|**[link](https://github.com/ZhikangNiu/arxiv_daily)**|\n", "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Ziyi Chen et.al.|[2511.21135](https://arxiv.org/abs/2511.21135)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20992": "|**2025-11-26**|**Dataset Poisoning Attacks on Behavioral Cloning Policies**|Akansha Kalra et.al.|[2511.20992](https://arxiv.org/abs/2511.20992)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|\n", "2511.20913": "|**2025-11-25**|**Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment**|Yingchuan Sun et.al.|[2511.20913](https://arxiv.org/abs/2511.20913)|**[link](https://github.com/ysun564/rl4h_timestep)**|\n", "2511.20906": "|**2025-11-25**|**Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy**|Inkook Chun et.al.|[2511.20906](https://arxiv.org/abs/2511.20906)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2511.20887": "|**2025-11-25**|**ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation**|Rui Yan et.al.|[2511.20887](https://arxiv.org/abs/2511.20887)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20766": "|**2025-11-25**|**OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability**|Karen Ullrich et.al.|[2511.20766](https://arxiv.org/abs/2511.20766)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.22505": "|**2025-12-08**|**RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion**|Xiujian Liang et.al.|[2511.22505](https://arxiv.org/abs/2511.22505)|null|\n", "2511.22445": "|**2025-11-27**|**Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion**|Yikai Tang et.al.|[2511.22445](https://arxiv.org/abs/2511.22445)|**[link](https://github.com/aramisjiang-wq/arxiv-daily)**|\n", "2511.22018": "|**2025-11-27**|**MedEyes: Learning Dynamic Visual Focus for Medical Progressive Diagnosis**|Chunzheng Zhu et.al.|[2511.22018](https://arxiv.org/abs/2511.22018)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21848": "|**2025-11-26**|**Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics**|Eric Leonardis et.al.|[2511.21848](https://arxiv.org/abs/2511.21848)|**[link](https://github.com/talmolab/mouse-reach-mjx-neurips)**|\n", "2511.22777": "|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Sajjad Pakdamansavoji et.al.|[2511.22777](https://arxiv.org/abs/2511.22777)|null|\n", "2511.22773": "|**2025-11-27**|**CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance**|Rui Heng Yang et.al.|[2511.22773](https://arxiv.org/abs/2511.22773)|null|\n", "2512.02011": "|**2025-12-01**|**Learning Dexterous Manipulation Skills from Imperfect Simulations**|Elvis Hsieh et.al.|[2512.02011](https://arxiv.org/abs/2512.02011)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01995": "|**2025-12-01**|**Dimensionality and confinement reshape competition in cellular renewing active matter**|Patrick Zimmer et.al.|[2512.01995](https://arxiv.org/abs/2512.01995)|null|\n", "2512.01993": "|**2025-12-01**|**RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies**|Guillermo Garcia-Cobo et.al.|[2512.01993](https://arxiv.org/abs/2512.01993)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2512.01809": "|**2025-12-05**|**Much Ado About Noising: Dispelling the Myths of Generative Robotic Control**|Chaoyi Pan et.al.|[2512.01809](https://arxiv.org/abs/2512.01809)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01383": "|**2025-12-01**|**PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**|Yunze Liu et.al.|[2512.01383](https://arxiv.org/abs/2512.01383)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Yi-Lin Wei et.al.|[2512.01022](https://arxiv.org/abs/2512.01022)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00960": "|**2025-11-30**|**Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction**|Boran Wen et.al.|[2512.00960](https://arxiv.org/abs/2512.00960)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|\n", "2512.00536": "|**2025-11-29**|**Algorithmic Guarantees for Distilling Supervised and Offline RL Datasets**|Aaryan Gupta et.al.|[2512.00536](https://arxiv.org/abs/2512.00536)|null|\n", "2512.00453": "|**2025-11-29**|**Sample-Efficient Expert Query Control in Active Imitation Learning via Conformal Prediction**|Arad Firouzkouhi et.al.|[2512.00453](https://arxiv.org/abs/2512.00453)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.00324": "|**2025-11-29**|**MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation**|Jinda Du et.al.|[2512.00324](https://arxiv.org/abs/2512.00324)|null|\n", "2512.00077": "|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi et.al.|[2512.00077](https://arxiv.org/abs/2512.00077)|**[link](https://github.com/heyzbw/HuSls)**|\n", "2512.03028": "|**2025-12-03**|**SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control**|Yuxuan Mu et.al.|[2512.03028](https://arxiv.org/abs/2512.03028)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang et.al.|[2512.02729](https://arxiv.org/abs/2512.02729)|null|\n", "2512.02609": "|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Shengkai Wu et.al.|[2512.02609](https://arxiv.org/abs/2512.02609)|null|\n", "2512.02580": "|**2025-12-02**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Changpeng Yang et.al.|[2512.02580](https://arxiv.org/abs/2512.02580)|null|\n", "2512.02543": "|**2025-12-02**|**In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs**|Vishnu Sarukkai et.al.|[2512.02543](https://arxiv.org/abs/2512.02543)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02535": "|**2025-12-02**|**AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning**|Jeric Lew et.al.|[2512.02535](https://arxiv.org/abs/2512.02535)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2512.03973": "|**2025-12-03**|**Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning**|Franki Nguimatsia Tiofack et.al.|[2512.03973](https://arxiv.org/abs/2512.03973)|**[link](https://github.com/iszhanjiawei/flow_matching_arxiv_daily)**|\n", "2512.03556": "|**2025-12-03**|**RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL**|Yinzhou Tang et.al.|[2512.03556](https://arxiv.org/abs/2512.03556)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.03347": "|**2025-12-03**|**GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation**|William van den Bogert et.al.|[2512.03347](https://arxiv.org/abs/2512.03347)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03079": "|**2025-11-28**|**Watermarks for Embeddings-as-a-Service Large Language Models**|Anudeex Shetty et.al.|[2512.03079](https://arxiv.org/abs/2512.03079)|null|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu et.al.|[2512.05107](https://arxiv.org/abs/2512.05107)|null|\n", "2512.05094": "|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|James Ni et.al.|[2512.05094](https://arxiv.org/abs/2512.05094)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|\n", "2512.04987": "|**2025-12-04**|**Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction**|Nex-AGI Team et.al.|[2512.04987](https://arxiv.org/abs/2512.04987)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.04960": "|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Jonne Van Haastregt et.al.|[2512.04960](https://arxiv.org/abs/2512.04960)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04813": "|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Huanqian Wang et.al.|[2512.04813](https://arxiv.org/abs/2512.04813)|**[link](https://huggingface.co/datasets/BAAI/MOVE)**|\n", "2512.04695": "|**2025-12-04**|**TRINITY: An Evolved LLM Coordinator**|Jinglue Xu et.al.|[2512.04695](https://arxiv.org/abs/2512.04695)|**[link](https://github.com/polyidoit/Arxiv-Quantum)**|\n", "2512.04279": "|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Feeza Khan Khanzada et.al.|[2512.04279](https://arxiv.org/abs/2512.04279)|null|\n", "2512.05953": "|**2025-12-05**|**Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning**|Yunhao Cao et.al.|[2512.05953](https://arxiv.org/abs/2512.05953)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05530": "|**2025-12-05**|**MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models**|Chuang Yu et.al.|[2512.05530](https://arxiv.org/abs/2512.05530)|null|\n", "2512.05335": "|**2025-12-05**|**State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning**|Yuxiang Liu et.al.|[2512.05335](https://arxiv.org/abs/2512.05335)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.07745": "|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Jialv Zou et.al.|[2512.07745](https://arxiv.org/abs/2512.07745)|**[link](https://github.com/hustvl/DiffusionDriveV2)**|\n", "2512.07697": "|**2025-12-08**|**Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks**|Aileen Liao et.al.|[2512.07697](https://arxiv.org/abs/2512.07697)|null|\n", "2512.07371": "|**2025-12-08**|**ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning**|Byungju Kim et.al.|[2512.07371](https://arxiv.org/abs/2512.07371)|null|\n", "2512.07248": "|**2025-12-08**|**Benchmarking Humanoid Imitation Learning with Motion Difficulty**|Zhaorui Meng et.al.|[2512.07248](https://arxiv.org/abs/2512.07248)|null|\n", "2512.07212": "|**2025-12-08**|**Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation**|Zhaoyang Liu et.al.|[2512.07212](https://arxiv.org/abs/2512.07212)|null|\n", "2512.07032": "|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Runcong Wang et.al.|[2512.07032](https://arxiv.org/abs/2512.07032)|null|\n", "2512.06956": "|**2025-12-07**|**Statistical analysis of Inverse Entropy-regularized Reinforcement Learning**|Denis Belomestny et.al.|[2512.06956](https://arxiv.org/abs/2512.06956)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Ruicheng Zhang et.al.|[2512.06628](https://arxiv.org/abs/2512.06628)|**[link](https://github.com/Richard-Zhang-AI/MIND-V)**|\n", "2512.06013": "|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Wenhao Li et.al.|[2512.06013](https://arxiv.org/abs/2512.06013)|**[link](https://github.com/lucidrains/vit-pytorch)**|\n"}, "Robotic Navigation": {"2508.13785": "|**2025-09-29**|**Blast Hole Seeking and Dipping -- The Navigation and Perception Framework in a Mine Site Inspection Robot**|Liyang Liu et.al.|[2508.13785](https://arxiv.org/abs/2508.13785)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.13601": "|**2025-08-19**|**Unleashing Semantic and Geometric Priors for 3D Scene Completion**|Shiyuan Chen et.al.|[2508.13601](https://arxiv.org/abs/2508.13601)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.13459": "|**2025-09-11**|**Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms**|Rohan Chandra et.al.|[2508.13459](https://arxiv.org/abs/2508.13459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.14105": "|**2025-08-17**|**Efficient Environment Design for Multi-Robot Navigation via Continuous Control**|Jahid Chowdhury Choton et.al.|[2508.14105](https://arxiv.org/abs/2508.14105)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.09444": "|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Haoxiang Shi et.al.|[2508.09444](https://arxiv.org/abs/2508.09444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.07269": "|**2025-08-10**|**Navigation and Exploration with Active Inference: from Biology to Industry**|Daria de Tinguy et.al.|[2508.07269](https://arxiv.org/abs/2508.07269)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.07045": "|**2025-08-09**|**From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline**|Dennis Benders et.al.|[2508.07045](https://arxiv.org/abs/2508.07045)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.06944": "|**2025-08-12**|**AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance**|Lixuan He et.al.|[2508.06944](https://arxiv.org/abs/2508.06944)|**[link](https://github.com/TSYJ-He/AMFT)**|\n", "2508.06177": "|**2025-08-08**|**Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor**|Dominik Br\u00e4mer et.al.|[2508.06177](https://arxiv.org/abs/2508.06177)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.05634": "|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.03408": "|**2025-08-06**|**Opti-Acoustic Scene Reconstruction in Highly Turbid Underwater Environments**|Ivana Collado-Gonzalez et.al.|[2508.03408](https://arxiv.org/abs/2508.03408)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.03350": "|**2025-08-05**|**Investigation of Air Fluidization during Intruder Penetration in Sand**|Bowen Wang et.al.|[2508.03350](https://arxiv.org/abs/2508.03350)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.03138": "|**2025-08-05**|**Language as Cost: Proactive Hazard Mapping using VLM for Robot Navigation**|Mintaek Oh et.al.|[2508.03138](https://arxiv.org/abs/2508.03138)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.02549": "|**2025-08-04**|**MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming**|Shuo Wang et.al.|[2508.02549](https://arxiv.org/abs/2508.02549)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01639": "|**2025-08-03**|**Glass Surface Segmentation with an RGB-D Camera via Weighted Feature Fusion for Service Robots**|Henghong Lin et.al.|[2508.01639](https://arxiv.org/abs/2508.01639)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.01539": "|**2025-08-03**|**HALO: Human Preference Aligned Offline Reward Learning for Robot Navigation**|Gershom Seneviratne et.al.|[2508.01539](https://arxiv.org/abs/2508.01539)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00580": "|**2025-08-01**|**OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery**|Raul Castilla-Arquillo et.al.|[2508.00580](https://arxiv.org/abs/2508.00580)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.00390": "|**2025-08-01**|**SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation**|Hengxing Cai et.al.|[2508.00390](https://arxiv.org/abs/2508.00390)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.23735": "|**2025-08-04**|**Distributed AI Agents for Cognitive Underwater Robot Autonomy**|Markus Buchholz et.al.|[2507.23735](https://arxiv.org/abs/2507.23735)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.22742": "|**2025-07-30**|**Social-Pose: Enhancing Trajectory Prediction with Human Body Pose**|Yang Gao et.al.|[2507.22742](https://arxiv.org/abs/2507.22742)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.21450": "|**2025-07-29**|**Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation**|Bolei Chen et.al.|[2507.21450](https://arxiv.org/abs/2507.21450)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.18317": "|**2025-07-24**|**AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments**|Chenglong Qian et.al.|[2507.18317](https://arxiv.org/abs/2507.18317)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2507.18206": "|**2025-09-09**|**MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation**|Arup Kumar Sahoo et.al.|[2507.18206](https://arxiv.org/abs/2507.18206)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.18033": "|**2025-07-24**|**OpenNav: Open-World Navigation with Multimodal Large Language Models**|Mingfeng Yuan et.al.|[2507.18033](https://arxiv.org/abs/2507.18033)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2507.17856": "|**2025-08-09**|**A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation**|Dennis Benders et.al.|[2507.17856](https://arxiv.org/abs/2507.17856)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.17317": "|**2025-07-25**|**HuNavSim 2.0: An Enhanced Human Navigation Simulator for Human-Aware Robot Navigation**|Miguel Escudero-Jim\u00e9nez et.al.|[2507.17317](https://arxiv.org/abs/2507.17317)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.17220": "|**2025-07-23**|**PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models**|Jiansong Wan et.al.|[2507.17220](https://arxiv.org/abs/2507.17220)|**[link](https://huggingface.co/models/zpschang/PIG-Nav)**|\n", "2507.16034": "|**2025-07-21**|**Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation**|Xuying Huang et.al.|[2507.16034](https://arxiv.org/abs/2507.16034)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.15484": "|**2025-07-21**|**Robots for Kiwifruit Harvesting and Pollination**|Jamie Bell et.al.|[2507.15484](https://arxiv.org/abs/2507.15484)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.14700": "|**2025-07-19**|**Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation**|Nicholas Mohammad et.al.|[2507.14700](https://arxiv.org/abs/2507.14700)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.13277": "|**2025-07-17**|**Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour**|Emma M. A. Harrison et.al.|[2507.13277](https://arxiv.org/abs/2507.13277)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.13152": "|**2025-08-26**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al.|[2507.13152](https://arxiv.org/abs/2507.13152)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|\n", "2507.12744": "|**2025-07-17**|**ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation**|Cheng Liu et.al.|[2507.12744](https://arxiv.org/abs/2507.12744)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.11464": "|**2025-07-15**|**LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control**|Ajay Shankar et.al.|[2507.11464](https://arxiv.org/abs/2507.11464)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.09858": "|**2025-07-14**|**Customize Harmonic Potential Fields via Hybrid Optimization over Homotopic Paths**|Shuaikang Wang et.al.|[2507.09858](https://arxiv.org/abs/2507.09858)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.09538": "|**2025-07-13**|**On the Importance of Neural Membrane Potential Leakage for LIDAR-based Robot Obstacle Avoidance using Spiking Neural Networks**|Zainab Ali et.al.|[2507.09538](https://arxiv.org/abs/2507.09538)|**[link](https://github.com/SpikingChen/SNN-Daily-Arxiv)**|\n", "2507.08112": "|**2025-07-10**|**Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion**|Lamiaa H. Zain et.al.|[2507.08112](https://arxiv.org/abs/2507.08112)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.07602": "|**2025-07-10**|**Advancing Medical Image Segmentation via Self-supervised Instance-adaptive Prototype Learning**|Guoyan Liang et.al.|[2507.07602](https://arxiv.org/abs/2507.07602)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.04686": "|**2025-07-07**|**MOSU: Autonomous Long-range Robot Navigation with Multi-modal Scene Understanding**|Jing Liang et.al.|[2507.04686](https://arxiv.org/abs/2507.04686)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.04509": "|**2025-07-06**|**MVL-Loc: Leveraging Vision-Language Model for Generalizable Multi-Scene Camera Relocalization**|Zhendong Xiao et.al.|[2507.04509](https://arxiv.org/abs/2507.04509)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.08831": "|**2025-07-15**|**View Invariant Learning for Vision-Language Navigation in Continuous Environments**|Josh Qixuan Sun et.al.|[2507.08831](https://arxiv.org/abs/2507.08831)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.04086": "|**2025-07-05**|**Are Learning-Based Approaches Ready for Real-World Indoor Navigation? A Case for Imitation Learning**|Nigitha Selvaraj et.al.|[2507.04086](https://arxiv.org/abs/2507.04086)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.01143": "|**2025-07-01**|**A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods**|Reza Jalayer et.al.|[2507.01143](https://arxiv.org/abs/2507.01143)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2507.01125": "|**2025-07-01**|**VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting**|Keiko Nagami et.al.|[2507.01125](https://arxiv.org/abs/2507.01125)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|\n", "2507.00552": "|**2025-07-01**|**Generation of Indoor Open Street Maps for Robot Navigation from CAD Files**|Jiajie Zhang et.al.|[2507.00552](https://arxiv.org/abs/2507.00552)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2506.22956": "|**2025-06-28**|**SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes**|David Rodr\u00edguez-Mart\u00ednez et.al.|[2506.22956](https://arxiv.org/abs/2506.22956)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.20376": "|**2025-06-25**|**Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation**|Lingyun Chen et.al.|[2506.20376](https://arxiv.org/abs/2506.20376)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.20320": "|**2025-06-26**|**Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation**|Malte Probst et.al.|[2506.20320](https://arxiv.org/abs/2506.20320)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.20315": "|**2025-06-25**|**Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead**|Mat\u00edas Mattamala et.al.|[2506.20315](https://arxiv.org/abs/2506.20315)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.18016": "|**2025-07-27**|**ADA-DPM: A Neural Descriptors-based Adaptive Noise Filtering Strategy for SLAM**|Yongxin Shao et.al.|[2506.18016](https://arxiv.org/abs/2506.18016)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.17643": "|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Krishna Vinod et.al.|[2508.17643](https://arxiv.org/abs/2508.17643)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.16913": "|**2025-08-23**|**Chat-Driven Reconfiguration of Model Predictive Control**|Yuya Miyaoka et.al.|[2508.16913](https://arxiv.org/abs/2508.16913)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.19595": "|**2025-08-27**|**A Lightweight Crowd Model for Robot Social Navigation**|Maryam Kazemi Eskeri et.al.|[2508.19595](https://arxiv.org/abs/2508.19595)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.20981": "|**2025-08-28**|**ActLoc: Learning to Localize on the Move via Active Viewpoint Selection**|Jiajie Li et.al.|[2508.20981](https://arxiv.org/abs/2508.20981)|**[link](https://github.com/cvg/ActLoc)**|\n", "2508.21595": "|**2025-08-29**|**Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics**|Yang You et.al.|[2508.21595](https://arxiv.org/abs/2508.21595)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21455": "|**2025-08-29**|**Assessing Human Cooperation for Enhancing Social Robot Navigation**|Hariharan Arunachalam et.al.|[2508.21455](https://arxiv.org/abs/2508.21455)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2508.21205": "|**2025-08-28**|**Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)**|Usman A. Khan et.al.|[2508.21205](https://arxiv.org/abs/2508.21205)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02134": "|**2025-09-02**|**Learning Social Heuristics for Human-Aware Path Planning**|Andrea Eirale et.al.|[2509.02134](https://arxiv.org/abs/2509.02134)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.02011": "|**2025-09-02**|**Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions**|Beibei Zhou et.al.|[2509.02011](https://arxiv.org/abs/2509.02011)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01251": "|**2025-09-01**|**Towards Data-Driven Metrics for Social Robot Navigation Benchmarking**|Pilar Bachiller-Burgos et.al.|[2509.01251](https://arxiv.org/abs/2509.01251)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.01212": "|**2025-09-01**|**nRTIS: Low-Cost Real-Time 3D Sonar Imaging Circular Array Supporting Beamforming for Industrial Applications**|Rens Baeyens et.al.|[2509.01212](https://arxiv.org/abs/2509.01212)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.06593": "|**2025-09-08**|**A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling**|Meher V. R. Malladi et.al.|[2509.06593](https://arxiv.org/abs/2509.06593)|**[link](https://github.com/PRBonn/rko_lio)**|\n", "2509.05672": "|**2025-09-06**|**Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation**|Juho Kalliokoski et.al.|[2509.05672](https://arxiv.org/abs/2509.05672)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08757": "|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Michael J. Munje et.al.|[2509.08757](https://arxiv.org/abs/2509.08757)|**[link](https://huggingface.co/datasets/michaelmunje/SocialNav-SUB)**|\n", "2509.08699": "|**2025-09-10**|**TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals**|Stefan Podgorski et.al.|[2509.08699](https://arxiv.org/abs/2509.08699)|**[link](https://github.com/DoongLi/ICRA2025-Paper-List)**|\n", "2509.08521": "|**2025-09-10**|**FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning**|Soheil Espahbodini Nia et.al.|[2509.08521](https://arxiv.org/abs/2509.08521)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.08435": "|**2025-09-10**|**PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching**|Lei Ye et.al.|[2509.08435](https://arxiv.org/abs/2509.08435)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.09200": "|**2025-09-11**|**MGTraj: Multi-Granularity Goal-Guided Human Trajectory Prediction with Recursive Refinement Network**|Ge Sun et.al.|[2509.09200](https://arxiv.org/abs/2509.09200)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.10454": "|**2025-09-12**|**GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation**|Hang Yin et.al.|[2509.10454](https://arxiv.org/abs/2509.10454)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.11742": "|**2025-09-15**|**Adaptive Motorized LiDAR Scanning Control for Robust Localization with OpenStreetMap**|Jianping Li et.al.|[2509.11742](https://arxiv.org/abs/2509.11742)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.11388": "|**2025-09-14**|**Quantum deep reinforcement learning for humanoid robot navigation task**|Romerik Lokossou et.al.|[2509.11388](https://arxiv.org/abs/2509.11388)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12912": "|**2025-09-16**|**Spotting the Unfriendly Robot -- Towards better Metrics for Interactions**|Raphael Wenzel et.al.|[2509.12912](https://arxiv.org/abs/2509.12912)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12890": "|**2025-09-16**|**Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation**|Malte Probst et.al.|[2509.12890](https://arxiv.org/abs/2509.12890)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12846": "|**2025-09-16**|**Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration**|Junlin Song et.al.|[2509.12846](https://arxiv.org/abs/2509.12846)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.12747": "|**2025-09-17**|**NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts**|Botao He et.al.|[2509.12747](https://arxiv.org/abs/2509.12747)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13733": "|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou et.al.|[2509.13733](https://arxiv.org/abs/2509.13733)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.13720": "|**2025-09-17**|**EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility**|Tianle Zeng et.al.|[2509.13720](https://arxiv.org/abs/2509.13720)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.15180": "|**2025-09-18**|**Parallel Simulation of Contact and Actuation for Soft Growing Robots**|Yitian Gao et.al.|[2509.15180](https://arxiv.org/abs/2509.15180)|null|\n", "2509.17287": "|**2025-09-21**|**Event-Based Visual Teach-and-Repeat via Fast Fourier-Domain Cross-Correlation**|Gokul B. Nair et.al.|[2509.17287](https://arxiv.org/abs/2509.17287)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.17204": "|**2025-09-23**|**Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation**|James R. Han et.al.|[2509.17204](https://arxiv.org/abs/2509.17204)|**[link](https://github.com/Shuijing725/awesome-robot-social-navigation)**|\n", "2509.16483": "|**2025-09-20**|**Octree Latent Diffusion for Semantic 3D Scene Generation and Completion**|Xujia Zhang et.al.|[2509.16483](https://arxiv.org/abs/2509.16483)|**[link](https://github.com/HuaiyuanXu/3D-Occupancy-Perception)**|\n", "2509.16412": "|**2025-09-19**|**Subteaming and Adaptive Formation Control for Coordinated Multi-Robot Navigation**|Zihao Deng et.al.|[2509.16412](https://arxiv.org/abs/2509.16412)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19105": "|**2025-09-23**|**Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation**|Sarvesh Prajapati et.al.|[2509.19105](https://arxiv.org/abs/2509.19105)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang et.al.|[2509.18610](https://arxiv.org/abs/2509.18610)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.18592": "|**2025-09-23**|**VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation**|Neel P. Bhatt et.al.|[2509.18592](https://arxiv.org/abs/2509.18592)|**[link](https://github.com/wendell0218/Awesome-RL-for-Video-Generation)**|\n", "2509.18384": "|**2025-09-22**|**AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback**|Yunhao Yang et.al.|[2509.18384](https://arxiv.org/abs/2509.18384)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.19480": "|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Noriaki Hirose et.al.|[2509.19480](https://arxiv.org/abs/2509.19480)|**[link](https://github.com/NHirose/OmniVLA)**|\n", "2509.21189": "|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Bhargav Chandaka et.al.|[2509.21189](https://arxiv.org/abs/2509.21189)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2509.20739": "|**2025-09-25**|**SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning**|Guoyang Zhao et.al.|[2509.20739](https://arxiv.org/abs/2509.20739)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20499": "|**2025-09-24**|**Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting**|Boqi Li et.al.|[2509.20499](https://arxiv.org/abs/2509.20499)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.20401": "|**2025-10-16**|**SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment**|Binod Singh et.al.|[2509.20401](https://arxiv.org/abs/2509.20401)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.22548": "|**2025-09-26**|**JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation**|Shuang Zeng et.al.|[2509.22548](https://arxiv.org/abs/2509.22548)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2509.21657": "|**2025-10-31**|**FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction**|Yixiang Dai et.al.|[2509.21657](https://arxiv.org/abs/2509.21657)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2509.21377": "|**2025-09-23**|**Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation**|Yinfeng Yu et.al.|[2509.21377](https://arxiv.org/abs/2509.21377)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.25091": "|**2025-09-29**|**Crop Spirals: Re-thinking the field layout for future robotic agriculture**|Lakshan Lavan et.al.|[2509.25091](https://arxiv.org/abs/2509.25091)|**[link](https://github.com/ai-agriculture-circuits-and-systems/ai_agriculture_news)**|\n", "2509.24907": "|**2025-10-17**|**Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation**|Thanh Long Nguyen et.al.|[2509.24907](https://arxiv.org/abs/2509.24907)|null|\n", "2509.24733": "|**2025-09-29**|**APREBot: Active Perception System for Reflexive Evasion Robot**|Zihao Xu et.al.|[2509.24733](https://arxiv.org/abs/2509.24733)|null|\n", "2509.24387": "|**2025-09-29**|**AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation**|Xin Ding et.al.|[2509.24387](https://arxiv.org/abs/2509.24387)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.24321": "|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Yao Wang et.al.|[2509.24321](https://arxiv.org/abs/2509.24321)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2509.26339": "|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Eric R. Damm et.al.|[2509.26339](https://arxiv.org/abs/2509.26339)|**[link](https://github.com/knightnemo/Awesome-World-Models)**|\n", "2509.25482": "|**2025-09-29**|**Message passing-based inference in an autoregressive active inference agent**|Wouter M. Kouw et.al.|[2509.25482](https://arxiv.org/abs/2509.25482)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01519": "|**2025-10-01**|**Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments**|Wei Han Chen et.al.|[2510.01519](https://arxiv.org/abs/2510.01519)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01483": "|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Mohamad Al Mdfaa et.al.|[2510.01483](https://arxiv.org/abs/2510.01483)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Arthur Zhang et.al.|[2510.01388](https://arxiv.org/abs/2510.01388)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00942": "|**2025-10-01**|**Non-submodular Visual Attention for Robot Navigation**|Reza Vafaee et.al.|[2510.00942](https://arxiv.org/abs/2510.00942)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00604": "|**2025-10-01**|**Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation**|Yunbo Xu et.al.|[2510.00604](https://arxiv.org/abs/2510.00604)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00530": "|**2025-10-01**|**Throttling for metric dimension and its variants**|Boris Brimkov et.al.|[2510.00530](https://arxiv.org/abs/2510.00530)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00466": "|**2025-10-01**|**Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation**|Run Su et.al.|[2510.00466](https://arxiv.org/abs/2510.00466)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.00405": "|**2025-10-01**|**EgoTraj-Bench: Towards Robust Trajectory Prediction Under Ego-view Noisy Observations**|Jiayi Liu et.al.|[2510.00405](https://arxiv.org/abs/2510.00405)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02941": "|**2025-10-03**|**Metrics vs Surveys: Can Quantitative Measures Replace Human Surveys in Social Robot Navigation? A Correlation Analysis**|Stefano Trepella et.al.|[2510.02941](https://arxiv.org/abs/2510.02941)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.02728": "|**2025-11-06**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Lingfeng Zhang et.al.|[2510.02728](https://arxiv.org/abs/2510.02728)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.02584": "|**2025-10-02**|**Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC**|Mohammad Abtahi et.al.|[2510.02584](https://arxiv.org/abs/2510.02584)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.04190": "|**2025-10-05**|**Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification**|Jian-jie Zheng et.al.|[2510.04190](https://arxiv.org/abs/2510.04190)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.03504": "|**2025-10-03**|**Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning**|Yutong Wang et.al.|[2510.03504](https://arxiv.org/abs/2510.03504)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.05330": "|**2025-10-10**|**Adaptive Dynamics Planning for Robot Navigation**|Yuanjie Lu et.al.|[2510.05330](https://arxiv.org/abs/2510.05330)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09574": "|**2025-10-10**|**Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference**|Daria de tinguy et.al.|[2510.09574](https://arxiv.org/abs/2510.09574)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09396": "|**2025-10-10**|**Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems**|Sajad Khatiri et.al.|[2510.09396](https://arxiv.org/abs/2510.09396)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09323": "|**2025-10-10**|**Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks**|Gopal Chandra Dutta et.al.|[2510.09323](https://arxiv.org/abs/2510.09323)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.09188": "|**2025-10-10**|**Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication**|Zihao Mao et.al.|[2510.09188](https://arxiv.org/abs/2510.09188)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10865": "|**2025-10-13**|**GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments**|Ahmed Alanazi et.al.|[2510.10865](https://arxiv.org/abs/2510.10865)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.10597": "|**2025-10-12**|**Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation**|David Rodr\u00edguez-Mart\u00ednez et.al.|[2510.10597](https://arxiv.org/abs/2510.10597)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12215": "|**2025-10-14**|**Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications**|Chanwoo Kim et.al.|[2510.12215](https://arxiv.org/abs/2510.12215)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.12919": "|**2025-10-14**|**Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation**|Mouhyemen Khan et.al.|[2510.12919](https://arxiv.org/abs/2510.12919)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17564": "|**2025-10-20**|**An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning**|Lindsay Spoor et.al.|[2510.17564](https://arxiv.org/abs/2510.17564)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.17525": "|**2025-10-20**|**HumanMPC - Safe and Efficient MAV Navigation among Humans**|Simon Schaefer et.al.|[2510.17525](https://arxiv.org/abs/2510.17525)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2510.18211": "|**2025-10-21**|**Distributed Stochastic Search for Multi-Agent Model Predictive Control**|Taehyun Yoon et.al.|[2510.18211](https://arxiv.org/abs/2510.18211)|null|\n", "2510.18063": "|**2025-10-20**|**MOFM-Nav: On-Manifold Ordering-Flexible Multi-Robot Navigation**|Bin-Bin Hu et.al.|[2510.18063](https://arxiv.org/abs/2510.18063)|null|\n", "2510.19655": "|**2025-10-22**|**LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments**|Hongyu Ding et.al.|[2510.19655](https://arxiv.org/abs/2510.19655)|null|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Mateo Guaman Castro et.al.|[2510.20818](https://arxiv.org/abs/2510.20818)|null|\n", "2510.23509": "|**2025-10-27**|**Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model**|Weizheng Wang et.al.|[2510.23509](https://arxiv.org/abs/2510.23509)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.23258": "|**2025-10-27**|**Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation**|Riko Yokozawa et.al.|[2510.23258](https://arxiv.org/abs/2510.23258)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2510.23057": "|**2025-10-27**|**Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation**|Oskar Natan et.al.|[2510.23057](https://arxiv.org/abs/2510.23057)|**[link](https://github.com/ZhuYingJessica/cv-daily)**|\n", "2510.22448": "|**2025-10-25**|**A short methodological review on social robot navigation benchmarking**|Pranup Chhetri et.al.|[2510.22448](https://arxiv.org/abs/2510.22448)|null|\n", "2510.21809": "|**2025-10-21**|**Embodied Navigation with Auxiliary Task of Action Description Prediction**|Haru Kondoh et.al.|[2510.21809](https://arxiv.org/abs/2510.21809)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|\n", "2510.25760": "|**2025-11-02**|**Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks**|Xu Zheng et.al.|[2510.25760](https://arxiv.org/abs/2510.25760)|**[link](https://github.com/52CV/CV-Surveys)**|\n", "2510.25191": "|**2025-10-29**|**SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning**|Hongyu Song et.al.|[2510.25191](https://arxiv.org/abs/2510.25191)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2510.26646": "|**2025-10-30**|**Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments**|Xiaoyi He et.al.|[2510.26646](https://arxiv.org/abs/2510.26646)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2510.27324": "|**2025-10-31**|**Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis**|Weiming Chen et.al.|[2510.27324](https://arxiv.org/abs/2510.27324)|**[link](https://github.com/cshw2021/Learned-Image-Video-Compression)**|\n", "2510.26909": "|**2025-11-04**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Tim Windecker et.al.|[2510.26909](https://arxiv.org/abs/2510.26909)|**[link](https://huggingface.co/spaces/leggedrobotics/navitrace_leaderboard)**|\n", "2511.06182": "|**2025-11-21**|**OpenVLN: Open-world Aerial Vision-Language Navigation**|Peican Lin et.al.|[2511.06182](https://arxiv.org/abs/2511.06182)|null|\n", "2511.05889": "|**2025-11-08**|**From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation**|Zeyuan Feng et.al.|[2511.05889](https://arxiv.org/abs/2511.05889)|null|\n", "2104.04167": "|**2021-08-26**|**The Road to Know-Where: An Object-and-Room Informed Sequential BERT for Indoor Vision-Language Navigation**|Yuankai Qi et.al.|[2104.04167](https://arxiv.org/abs/2104.04167)|**[link](https://github.com/ChanganVR/awesome-embodied-vision)**|\n", "2412.09082": "|**2025-03-20**|**Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method**|Xinshuai Song et.al.|[2412.09082](https://arxiv.org/abs/2412.09082)|**[link](https://huggingface.co/datasets/Starry123/LHPR-VLN)**|\n", "2202.02312": "|**2022-08-16**|**A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility**|Andrea Burns et.al.|[2202.02312](https://arxiv.org/abs/2202.02312)|**[link](https://github.com/codefuse-ai/Awesome-Code-LLM)**|\n", "1711.07280": "|**2018-04-09**|**Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments**|Peter Anderson et.al.|[1711.07280](https://arxiv.org/abs/1711.07280)|**[link](https://github.com/sangminwoo/awesome-vision-and-language)**|\n", "1911.12377": "|**2021-08-02**|**Multimodal Attention Networks for Low-Level Vision-and-Language Navigation**|Federico Landi et.al.|[1911.12377](https://arxiv.org/abs/1911.12377)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2011.03807": "|**2020-11-10**|**Sim-to-Real Transfer for Vision-and-Language Navigation**|Peter Anderson et.al.|[2011.03807](https://arxiv.org/abs/2011.03807)|**[link](https://github.com/ChanganVR/awesome-embodied-vision)**|\n", "2210.03087": "|**2023-12-27**|**Iterative Vision-and-Language Navigation**|Jacob Krantz et.al.|[2210.03087](https://arxiv.org/abs/2210.03087)|**[link](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List)**|\n", "1910.11301": "|**2020-12-08**|**Cross-Lingual Vision-Language Navigation**|An Yan et.al.|[1910.11301](https://arxiv.org/abs/1910.11301)|**[link](https://github.com/eric-ai-lab/awesome-vision-language-navigation)**|\n", "2508.07406": "|**2025-08-12**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiaobei Zhao et.al.|[2508.07406](https://arxiv.org/abs/2508.07406)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2411.14811": "|**2024-12-03**|**Fine-Grained Alignment in Vision-and-Language Navigation through Bayesian Optimization**|Yuhang Song et.al.|[2411.14811](https://arxiv.org/abs/2411.14811)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2211.16649": "|**2022-12-01**|**CLIP-Nav: Using CLIP for Zero-Shot Vision-and-Language Navigation**|Vishnu Sashank Dorbala et.al.|[2211.16649](https://arxiv.org/abs/2211.16649)|**[link](https://github.com/zhangyuejoslin/VLN-Survey-with-Foundation-Models)**|\n", "2407.12366": "|**2024-09-23**|**NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models**|Gengze Zhou et.al.|[2407.12366](https://arxiv.org/abs/2407.12366)|**[link](https://huggingface.co/datasets/ZGZzz/NavGPT-Instruct)**|\n", "2105.11589": "|**2022-03-17**|**VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator**|Ayush Shrivastava et.al.|[2105.11589](https://arxiv.org/abs/2105.11589)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2412.04453": "|**2025-02-18**|**NaVILA: Legged Robot Vision-Language-Action Model for Navigation**|An-Chieh Cheng et.al.|[2412.04453](https://arxiv.org/abs/2412.04453)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "1908.03409": "|**2019-08-14**|**Transferable Representation Learning in Vision-and-Language Navigation**|Haoshuo Huang et.al.|[1908.03409](https://arxiv.org/abs/1908.03409)|**[link](https://github.com/ChanganVR/awesome-embodied-vision)**|\n", "2210.10020": "|**2022-10-19**|**ULN: Towards Underspecified Vision-and-Language Navigation**|Weixi Feng et.al.|[2210.10020](https://arxiv.org/abs/2210.10020)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2201.10788": "|**2022-01-27**|**Self-supervised 3D Semantic Representation Learning for Vision-and-Language Navigation**|Sinan Tan et.al.|[2201.10788](https://arxiv.org/abs/2201.10788)|**[link](https://github.com/DirtyHarryLYL/Transformer-in-Vision)**|\n", "2509.22441": "|**2025-09-29**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Zhangyuan Wang et.al.|[2509.22441](https://arxiv.org/abs/2509.22441)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2501.17403": "|**2025-01-30**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403](https://arxiv.org/abs/2501.17403)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2103.16561": "|**2022-05-05**|**Diagnosing Vision-and-Language Navigation: What Really Matters**|Wanrong Zhu et.al.|[2103.16561](https://arxiv.org/abs/2103.16561)|**[link](https://github.com/eric-ai-lab/awesome-vision-language-navigation)**|\n", "2007.00229": "|**2021-02-05**|**Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation**|Wanrong Zhu et.al.|[2007.00229](https://arxiv.org/abs/2007.00229)|**[link](https://github.com/eric-ai-lab/awesome-vision-language-navigation)**|\n", "2304.03047": "|**2024-01-23**|**ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments**|Dong An et.al.|[2304.03047](https://arxiv.org/abs/2304.03047)|**[link](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List)**|\n", "2312.15820": "|**2023-12-27**|**WebVLN: Vision-and-Language Navigation on Websites**|Qi Chen et.al.|[2312.15820](https://arxiv.org/abs/2312.15820)|**[link](https://github.com/showlab/Awesome-GUI-Agent)**|\n", "2305.16986": "|**2023-10-20**|**NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models**|Gengze Zhou et.al.|[2305.16986](https://arxiv.org/abs/2305.16986)|**[link](https://github.com/WooooDyy/LLM-Agent-Paper-List)**|\n", "2012.05292": "|**2020-12-11**|**Topological Planning with Transformers for Vision-and-Language Navigation**|Kevin Chen et.al.|[2012.05292](https://arxiv.org/abs/2012.05292)|**[link](https://github.com/52CV/CVPR-2021-Papers)**|\n", "2307.10790": "|**2023-07-21**|**Behavioral Analysis of Vision-and-Language Navigation Agents**|Zijiao Yang et.al.|[2307.10790](https://arxiv.org/abs/2307.10790)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2203.12667": "|**2022-06-07**|**Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions**|Jing Gu et.al.|[2203.12667](https://arxiv.org/abs/2203.12667)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2206.08645": "|**2022-06-23**|**Local Slot Attention for Vision-and-Language Navigation**|Yifeng Zhuang et.al.|[2206.08645](https://arxiv.org/abs/2206.08645)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2109.15207": "|**2021-10-01**|**Language-Aligned Waypoint (LAW) Supervision for Vision-and-Language Navigation in Continuous Environments**|Sonia Raychaudhuri et.al.|[2109.15207](https://arxiv.org/abs/2109.15207)|**[link](https://github.com/yinyunie/3D-Shape-Analysis-Paper-List)**|\n", "2502.07306": "|**2025-06-11**|**TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation**|Navid Rajabi et.al.|[2502.07306](https://arxiv.org/abs/2502.07306)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2503.13966": "|**2025-03-19**|**FlexVLN: Flexible Adaptation for Diverse Vision-and-Language Navigation Tasks**|Siqi Zhang et.al.|[2503.13966](https://arxiv.org/abs/2503.13966)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2308.07997": "|**2023-08-17**|**$A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models**|Peihao Chen et.al.|[2308.07997](https://arxiv.org/abs/2308.07997)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2203.05137": "|**2022-03-22**|**Cross-modal Map Learning for Vision and Language Navigation**|Georgios Georgakis et.al.|[2203.05137](https://arxiv.org/abs/2203.05137)|**[link](https://github.com/52CV/CVPR-2022-Papers)**|\n", "2112.04138": "|**2021-12-10**|**Contrastive Instruction-Trajectory Learning for Vision-Language Navigation**|Xiwen Liang et.al.|[2112.04138](https://arxiv.org/abs/2112.04138)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "1803.07729": "|**2018-07-27**|**Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation**|Xin Wang et.al.|[1803.07729](https://arxiv.org/abs/1803.07729)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2506.14507": "|**2025-06-18**|**Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?**|Nitesh Subedi et.al.|[2506.14507](https://arxiv.org/abs/2506.14507)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2310.10822": "|**2023-10-18**|**Vision and Language Navigation in the Real World via Online Visual Language Mapping**|Chengguang Xu et.al.|[2310.10822](https://arxiv.org/abs/2310.10822)|**[link](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List)**|\n", "2108.09105": "|**2021-08-23**|**Airbert: In-domain Pretraining for Vision-and-Language Navigation**|Pierre-Louis Guhur et.al.|[2108.09105](https://arxiv.org/abs/2108.09105)|**[link](https://github.com/ChanganVR/awesome-embodied-vision)**|\n", "2203.15685": "|**2022-03-30**|**EnvEdit: Environment Editing for Vision-and-Language Navigation**|Jialu Li et.al.|[2203.15685](https://arxiv.org/abs/2203.15685)|**[link](https://github.com/52CV/CVPR-2022-Papers)**|\n", "2402.15852": "|**2024-07-02**|**NaVid: Video-based VLM Plans the Next Step for Vision-and-Language Navigation**|Jiazhao Zhang et.al.|[2402.15852](https://arxiv.org/abs/2402.15852)|**[link](https://github.com/GT-RIPL/Awesome-LLM-Robotics)**|\n", "2505.11383": "|**2025-05-19**|**Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation**|Zihan Wang et.al.|[2505.11383](https://arxiv.org/abs/2505.11383)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2002.10638": "|**2020-04-07**|**Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-training**|Weituo Hao et.al.|[2002.10638](https://arxiv.org/abs/2002.10638)|**[link](https://github.com/pliang279/awesome-multimodal-ml)**|\n", "2402.03561": "|**2024-02-08**|**VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation**|Jialu Li et.al.|[2402.03561](https://arxiv.org/abs/2402.03561)|**[link](https://github.com/zhangyuejoslin/VLN-Survey-with-Foundation-Models)**|\n", "1905.13358": "|**2019-06-03**|**Multi-modal Discriminative Model for Vision-and-Language Navigation**|Haoshuo Huang et.al.|[1905.13358](https://arxiv.org/abs/1905.13358)|**[link](https://github.com/pliang279/awesome-multimodal-ml)**|\n", "2503.16394": "|**2025-03-21**|**Do Visual Imaginations Improve Vision-and-Language Navigation Agents?**|Akhil Perincherry et.al.|[2503.16394](https://arxiv.org/abs/2503.16394)|**[link](https://github.com/AGI-Edgerunners/LLM-Agents-Papers)**|\n", "2403.15049": "|**2025-11-03**|**Continual Vision-and-Language Navigation**|Seongjun Jeong et.al.|[2403.15049](https://arxiv.org/abs/2403.15049)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "1907.04957": "|**2019-10-15**|**Vision-and-Dialog Navigation**|Jesse Thomason et.al.|[1907.04957](https://arxiv.org/abs/1907.04957)|**[link](https://github.com/pliang279/awesome-multimodal-ml)**|\n", "2502.00114": "|**2025-04-30**|**Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model Approach**|Aaron Hao Tan et.al.|[2502.00114](https://arxiv.org/abs/2502.00114)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2402.14304": "|**2024-03-21**|**Vision-Language Navigation with Embodied Intelligence: A Survey**|Peng Gao et.al.|[2402.14304](https://arxiv.org/abs/2402.14304)|**[link](https://github.com/cmhungsteve/Awesome-Transformer-Attention)**|\n", "2108.11544": "|**2022-04-05**|**Vision-Language Navigation: A Survey and Taxonomy**|Wansen Wu et.al.|[2108.11544](https://arxiv.org/abs/2108.11544)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel et.al.|[2511.10615](https://arxiv.org/abs/2511.10615)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.10376": "|**2025-11-14**|**MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation**|Xun Huang et.al.|[2511.10376](https://arxiv.org/abs/2511.10376)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.09885": "|**2025-11-13**|**PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion**|Shashwat Singh et.al.|[2511.09885](https://arxiv.org/abs/2511.09885)|**[link](https://github.com/XiaomingX/arxiv-daily)**|\n", "2511.09820": "|**2025-11-12**|**From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance**|Jeongho Min et.al.|[2511.09820](https://arxiv.org/abs/2511.09820)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.09331": "|**2025-11-12**|**CoRL-MPPI: Enhancing MPPI With Learnable Behaviours For Efficient And Provably-Safe Multi-Robot Collision Avoidance**|Stepan Dergachev et.al.|[2511.09331](https://arxiv.org/abs/2511.09331)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08978": "|**2025-11-12**|**Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding**|Jingtian Ma et.al.|[2511.08978](https://arxiv.org/abs/2511.08978)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08942": "|**2025-11-12**|**Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning**|Mobin Habibpour et.al.|[2511.08942](https://arxiv.org/abs/2511.08942)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08935": "|**2025-11-12**|**Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation**|Ningnan Wang et.al.|[2511.08935](https://arxiv.org/abs/2511.08935)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.08822": "|**2025-11-11**|**Low-cost Multi-agent Fleet for Acoustic Cooperative Localization Research**|Nelson Durrant et.al.|[2511.08822](https://arxiv.org/abs/2511.08822)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08545": "|**2025-11-11**|**RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses**|Sriram Srinivasan et.al.|[2511.08545](https://arxiv.org/abs/2511.08545)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08502": "|**2025-11-11**|**Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1**|Ruya Karagulle et.al.|[2511.08502](https://arxiv.org/abs/2511.08502)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08277": "|**2025-11-11**|**X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention**|Dehan Shen et.al.|[2511.08277](https://arxiv.org/abs/2511.08277)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.08098": "|**2025-11-11**|**PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision**|Sabrina Patania et.al.|[2511.08098](https://arxiv.org/abs/2511.08098)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.07927": "|**2025-11-11**|**Local Path Planning with Dynamic Obstacle Avoidance in Unstructured Environments**|Okan Arif Guvenkaya et.al.|[2511.07927](https://arxiv.org/abs/2511.07927)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.07811": "|**2025-11-11**|**Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution**|Sagar Gupta et.al.|[2511.07811](https://arxiv.org/abs/2511.07811)|null|\n", "2511.07727": "|**2025-11-11**|**LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models**|Xiaohan Zhang et.al.|[2511.07727](https://arxiv.org/abs/2511.07727)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.07710": "|**2025-11-29**|**Cross Modal Fine-Grained Alignment via Granularity-Aware and Region-Uncertain Modeling**|Jiale Liu et.al.|[2511.07710](https://arxiv.org/abs/2511.07710)|null|\n", "2511.07687": "|**2025-11-10**|**Testing and Evaluation of Underwater Vehicle Using Hardware-In-The-Loop Simulation with HoloOcean**|Braden Meyers et.al.|[2511.07687](https://arxiv.org/abs/2511.07687)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.07634": "|**2025-11-10**|**Accessibility, Safety, and Accommodation Burden in U.S. Higher Education Syllabi for Blind and Low-Vision Students**|Chadani Acharya et.al.|[2511.07634](https://arxiv.org/abs/2511.07634)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.07392": "|**2025-11-11**|**Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction**|Hyeryun Park et.al.|[2511.07392](https://arxiv.org/abs/2511.07392)|**[link](https://github.com/halsay/ASR-TTS-paper-daily)**|\n", "2511.06998": "|**2025-11-10**|**Raspi$^2$USBL: An open-source Raspberry Pi-Based Passive Inverted Ultra-Short Baseline Positioning System for Underwater Robotics**|Jin Huang et.al.|[2511.06998](https://arxiv.org/abs/2511.06998)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06840": "|**2025-11-10**|**PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory**|Qunchao Jin et.al.|[2511.06840](https://arxiv.org/abs/2511.06840)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06801": "|**2025-11-10**|**Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots**|Praveen Kumar et.al.|[2511.06801](https://arxiv.org/abs/2511.06801)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.06240": "|**2025-11-09**|**Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation**|Tzu-Jung Lin et.al.|[2511.06240](https://arxiv.org/abs/2511.06240)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.06080": "|**2025-11-11**|**An Artificial Intelligence-based Assistant for the Visually Impaired**|Luis Marquez-Carpintero et.al.|[2511.06080](https://arxiv.org/abs/2511.06080)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.05900": "|**2025-11-08**|**Disentangled Control of Multi-Agent Systems**|Ruoyu Lin et.al.|[2511.05900](https://arxiv.org/abs/2511.05900)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05798": "|**2025-11-08**|**An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles**|William R. Johnson et.al.|[2511.05798](https://arxiv.org/abs/2511.05798)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05158": "|**2025-11-07**|**Follow-Me in Micro-Mobility with End-to-End Imitation Learning**|Sahar Salimpour et.al.|[2511.05158](https://arxiv.org/abs/2511.05158)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.05052": "|**2025-11-07**|**TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments**|Zihao Li et.al.|[2511.05052](https://arxiv.org/abs/2511.05052)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03882": "|**2025-11-05**|**Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures**|Florence Klitzner et.al.|[2511.03882](https://arxiv.org/abs/2511.03882)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03651": "|**2025-11-05**|**Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural**|Andrei A. Korigodskii et.al.|[2511.03651](https://arxiv.org/abs/2511.03651)|**[link](https://github.com/ryanbgriffiths/IROS2024PaperList)**|\n", "2511.03591": "|**2025-11-05**|**Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning**|Qingyi Chen et.al.|[2511.03591](https://arxiv.org/abs/2511.03591)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.03576": "|**2025-11-05**|**Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution**|Aniol Civit et.al.|[2511.03576](https://arxiv.org/abs/2511.03576)|null|\n", "2511.03173": "|**2025-11-05**|**Optimizing Earth-Moon Transfer and Cislunar Navigation: Integrating Low-Energy Trajectories, AI Techniques and GNSS-R Technologies**|Arsalan Muhammad et.al.|[2511.03173](https://arxiv.org/abs/2511.03173)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.03167": "|**2025-11-05**|**Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning**|Xin Liu et.al.|[2511.03167](https://arxiv.org/abs/2511.03167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.03165": "|**2025-11-05**|**SENT Map -- Semantically Enhanced Topological Maps with Foundation Models**|Raj Surya Rajendran Kathirvel et.al.|[2511.03165](https://arxiv.org/abs/2511.03165)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.02979": "|**2025-11-04**|**Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications**|Esther Sun et.al.|[2511.02979](https://arxiv.org/abs/2511.02979)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01797": "|**2025-11-03**|**Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator**|Javier Ballesteros-Jerez et.al.|[2511.01797](https://arxiv.org/abs/2511.01797)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01199": "|**2025-11-03**|**Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures**|Max McCandless et.al.|[2511.01199](https://arxiv.org/abs/2511.01199)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01186": "|**2025-11-03**|**LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping**|Lijie Wang et.al.|[2511.01186](https://arxiv.org/abs/2511.01186)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.01083": "|**2025-11-02**|**Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment**|Zihan Wang et.al.|[2511.01083](https://arxiv.org/abs/2511.01083)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00945": "|**2025-11-02**|**\"Less is More\": Reducing Cognitive Load and Task Drift in Real-Time Multimodal Assistive Agents for the Visually Impaired**|Yi Zhao et.al.|[2511.00945](https://arxiv.org/abs/2511.00945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00934": "|**2025-11-02**|**pacSTL: PAC-Bounded Signal Temporal Logic from Data-Driven Reachability Analysis**|Elizabeth Dietrich et.al.|[2511.00934](https://arxiv.org/abs/2511.00934)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00933": "|**2025-11-02**|**Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation**|Xiangyu Shi et.al.|[2511.00933](https://arxiv.org/abs/2511.00933)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.00858": "|**2025-11-02**|**Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction**|Yu Liu et.al.|[2511.00858](https://arxiv.org/abs/2511.00858)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00783": "|**2025-11-06**|**When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage**|Jingzehua Xu et.al.|[2511.00783](https://arxiv.org/abs/2511.00783)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.00710": "|**2025-11-11**|**Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries**|Minghe Shen et.al.|[2511.00710](https://arxiv.org/abs/2511.00710)|**[link](https://huggingface.co/models/KOKKKOKK/Ariadne)**|\n", "2511.00140": "|**2025-10-31**|**Supply Chain Exploitation of Secure ROS 2 Systems: A Proof-of-Concept on Autonomous Platform Compromise via Keystore Exfiltration**|Tahmid Hasan Sakib et.al.|[2511.00140](https://arxiv.org/abs/2511.00140)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11552": "|**2025-11-14**|**DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding**|Dawei Zhu et.al.|[2511.11552](https://arxiv.org/abs/2511.11552)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.11529": "|**2025-11-14**|**Terrain Costmap Generation via Scaled Preference Conditioning**|Luisa Mao et.al.|[2511.11529](https://arxiv.org/abs/2511.11529)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11310": "|**2025-11-14**|**Simulating an Autonomous System in CARLA using ROS 2**|Joseph Abdo et.al.|[2511.11310](https://arxiv.org/abs/2511.11310)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.11169": "|**2025-11-14**|**Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA**|Ayush Pandey et.al.|[2511.11169](https://arxiv.org/abs/2511.11169)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.10874": "|**2025-11-14**|**Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation**|Yorai Shaoul et.al.|[2511.10874](https://arxiv.org/abs/2511.10874)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.10816": "|**2025-11-17**|**Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios**|William Harris et.al.|[2511.10816](https://arxiv.org/abs/2511.10816)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2511.13524": "|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Yuhang Peng et.al.|[2511.13524](https://arxiv.org/abs/2511.13524)|**[link](https://huggingface.co/datasets/Astronaut-PENG/FreeAskWorld)**|\n", "2511.13269": "|**2025-11-17**|**Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation**|Lingfeng Zhang et.al.|[2511.13269](https://arxiv.org/abs/2511.13269)|**[link](https://huggingface.co/models/llxs/Sky-VLM)**|\n", "2511.13259": "|**2025-11-17**|**GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models**|Yushuo Zheng et.al.|[2511.13259](https://arxiv.org/abs/2511.13259)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n", "2511.13216": "|**2025-11-17**|**GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry**|Chiyun Noh et.al.|[2511.13216](https://arxiv.org/abs/2511.13216)|**[link](https://github.com/ChiyunNoh/GaRLILEO)**|\n", "2511.13188": "|**2025-11-17**|**Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control**|Osama Al Sheikh Ali et.al.|[2511.13188](https://arxiv.org/abs/2511.13188)|null|\n", "2511.13132": "|**2025-11-17**|**Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack**|Chenyang Li et.al.|[2511.13132](https://arxiv.org/abs/2511.13132)|null|\n", "2511.13071": "|**2025-11-17**|**Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers**|Michal Levin et.al.|[2511.13071](https://arxiv.org/abs/2511.13071)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.13048": "|**2025-11-17**|**Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments**|Yong Li et.al.|[2511.13048](https://arxiv.org/abs/2511.13048)|**[link](https://github.com/ryanbgriffiths/ICRA2023PaperList)**|\n", "2511.13047": "|**2025-11-17**|**DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation**|Yan Gong et.al.|[2511.13047](https://arxiv.org/abs/2511.13047)|**[link](https://github.com/ZhuYingJessica/cv-daily)**|\n", "2511.13042": "|**2025-11-17**|**APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation**|Yong Li et.al.|[2511.13042](https://arxiv.org/abs/2511.13042)|**[link](https://github.com/ryanbgriffiths/ICRA2024PaperList)**|\n", "2511.12984": "|**2025-11-17**|**CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner**|Miryeong Park et.al.|[2511.12984](https://arxiv.org/abs/2511.12984)|**[link](https://github.com/Active-SLAM/Active-SLAM-Paper-List)**|\n", "2511.12972": "|**2025-11-17**|**SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models**|Siddarth Narasimhan et.al.|[2511.12972](https://arxiv.org/abs/2511.12972)|**[link](https://github.com/3D-Vision-World/awesome-NeRF-and-3DGS-SLAM)**|\n", "2511.12910": "|**2025-11-17**|**TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints**|Yong Li et.al.|[2511.12910](https://arxiv.org/abs/2511.12910)|**[link](https://github.com/DoongLi/IROS2025-Paper-List)**|\n", "2511.12778": "|**2025-11-16**|**DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation**|Vignesh Rajagopal et.al.|[2511.12778](https://arxiv.org/abs/2511.12778)|**[link](https://github.com/vigneshrl/drnav_deadend_recovery)**|\n", "2511.12676": "|**2025-11-16**|**BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections**|Subin Varghese et.al.|[2511.12676](https://arxiv.org/abs/2511.12676)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.12526": "|**2025-11-16**|**Botany Meets Robotics in Alpine Scree Monitoring**|Davide De Benedittis et.al.|[2511.12526](https://arxiv.org/abs/2511.12526)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.12436": "|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Xiaoshuai Hao et.al.|[2511.12436](https://arxiv.org/abs/2511.12436)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|\n", "2511.12232": "|**2025-11-18**|**SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation**|Lingfeng Zhang et.al.|[2511.12232](https://arxiv.org/abs/2511.12232)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2511.12022": "|**2025-11-15**|**SBAMP: Sampling Based Adaptive Motion Planning**|Anh-Quan Pham et.al.|[2511.12022](https://arxiv.org/abs/2511.12022)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14499": "|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Jack Qin et.al.|[2511.14499](https://arxiv.org/abs/2511.14499)|null|\n", "2511.14458": "|**2025-11-18**|**Advancing Minimally Invasive Precision Surgery in Open Cavities with Robotic Flexible Endoscopy**|Michelle Mattille et.al.|[2511.14458](https://arxiv.org/abs/2511.14458)|null|\n", "2511.14341": "|**2025-11-18**|**Going Places: Place Recognition in Artificial and Natural Systems**|Michael Milford et.al.|[2511.14341](https://arxiv.org/abs/2511.14341)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Xiaoquan Sun et.al.|[2511.14161](https://arxiv.org/abs/2511.14161)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|\n", "2511.14149": "|**2025-11-18**|**iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion**|Hao Wang et.al.|[2511.14149](https://arxiv.org/abs/2511.14149)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.14131": "|**2025-11-18**|**Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation**|Yu Zhong et.al.|[2511.14131](https://arxiv.org/abs/2511.14131)|null|\n", "2511.14107": "|**2025-11-18**|**RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment**|Zeyu Cheng et.al.|[2511.14107](https://arxiv.org/abs/2511.14107)|null|\n", "2511.14037": "|**2025-11-18**|**BIM-Discrepancy-Driven Active Sensing for Risk-Aware UAV-UGV Navigation**|Hesam Mojtahedi et.al.|[2511.14037](https://arxiv.org/abs/2511.14037)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.14024": "|**2025-11-18**|**FACA: Fair and Agile Multi-Robot Collision Avoidance in Constrained Environments with Dynamic Priorities**|Jaskirat Singh et.al.|[2511.14024](https://arxiv.org/abs/2511.14024)|null|\n", "2511.13985": "|**2025-11-17**|**LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry**|Jan Quenzel et.al.|[2511.13985](https://arxiv.org/abs/2511.13985)|null|\n", "2511.13782": "|**2025-11-16**|**Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models**|Xiaoxing Lian et.al.|[2511.13782](https://arxiv.org/abs/2511.13782)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.15614": "|**2025-11-19**|**Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography**|Sai Puppala et.al.|[2511.15614](https://arxiv.org/abs/2511.15614)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.15597": "|**2025-11-19**|**Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition**|Xufei Wang et.al.|[2511.15597](https://arxiv.org/abs/2511.15597)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.15567": "|**2025-11-19**|**Computer-Use Agents as Judges for Generative User Interface**|Kevin Qinghong Lin et.al.|[2511.15567](https://arxiv.org/abs/2511.15567)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.15513": "|**2025-11-19**|**Discovering Optimal Natural Gaits of Dissipative Systems via Virtual Energy Injection**|Korbinian Griesbauer et.al.|[2511.15513](https://arxiv.org/abs/2511.15513)|null|\n", "2511.15239": "|**2025-11-19**|**Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy**|Tomoki Nakao et.al.|[2511.15239](https://arxiv.org/abs/2511.15239)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16349": "|**2025-11-20**|**CRISTAL: Real-time Camera Registration in Static LiDAR Scans using Neural Rendering**|Joni Vanherck et.al.|[2511.16349](https://arxiv.org/abs/2511.16349)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.16140": "|**2025-11-20**|**Real-Time 3D Object Detection with Inference-Aligned Learning**|Chenyu Zhao et.al.|[2511.16140](https://arxiv.org/abs/2511.16140)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.16048": "|**2025-11-20**|**Semantic Glitch: Agency and Artistry in an Autonomous Pixel Cloud**|Qing Zhang et.al.|[2511.16048](https://arxiv.org/abs/2511.16048)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.17497": "|**2025-11-21**|**HALO: High-Altitude Language-Conditioned Monocular Aerial Exploration and Navigation**|Yuezhan Tao et.al.|[2511.17497](https://arxiv.org/abs/2511.17497)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.17401": "|**2025-11-21**|**Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment**|Xiaoshan Zhou et.al.|[2511.17401](https://arxiv.org/abs/2511.17401)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17384": "|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yifan Li et.al.|[2511.17384](https://arxiv.org/abs/2511.17384)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.17097": "|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Shuo Wang et.al.|[2511.17097](https://arxiv.org/abs/2511.17097)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.17013": "|**2025-11-21**|**MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints**|Yiwen Ying et.al.|[2511.17013](https://arxiv.org/abs/2511.17013)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.18878": "|**2025-11-24**|**Accelerating Reinforcement Learning via Error-Related Human Brain Signals**|Suzie Kim et.al.|[2511.18878](https://arxiv.org/abs/2511.18878)|null|\n", "2511.18857": "|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Changsheng Luo et.al.|[2511.18857](https://arxiv.org/abs/2511.18857)|null|\n", "2511.18845": "|**2025-11-24**|**UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model**|Changxin Huang et.al.|[2511.18845](https://arxiv.org/abs/2511.18845)|null|\n", "2511.18756": "|**2025-11-24**|**SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map**|Xueyu Du et.al.|[2511.18756](https://arxiv.org/abs/2511.18756)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18694": "|**2025-11-24**|**Stable Multi-Drone GNSS Tracking System for Marine Robots**|Shuo Wen et.al.|[2511.18694](https://arxiv.org/abs/2511.18694)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.18525": "|**2025-11-23**|**Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation**|Samarth Chopra et.al.|[2511.18525](https://arxiv.org/abs/2511.18525)|null|\n", "2511.18183": "|**2025-11-22**|**Off-Road Navigation via Implicit Neural Representation of Terrain Traversability**|Yixuan Jia et.al.|[2511.18183](https://arxiv.org/abs/2511.18183)|null|\n", "2511.18151": "|**2025-11-22**|**AVERY: Adaptive VLM Split Computing through Embodied Self-Awareness for Efficient Disaster Response Systems**|Rajat Bhattacharjya et.al.|[2511.18151](https://arxiv.org/abs/2511.18151)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.18112": "|**2025-11-22**|**EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation**|Min Lin et.al.|[2511.18112](https://arxiv.org/abs/2511.18112)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.17798": "|**2025-11-21**|**SM2ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control**|Francesco D'Orazio et.al.|[2511.17798](https://arxiv.org/abs/2511.17798)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.17781": "|**2025-11-21**|**SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs**|Kristy Sakano et.al.|[2511.17781](https://arxiv.org/abs/2511.17781)|**[link](https://github.com/Farama-Foundation/stable-retro)**|\n", "2511.17765": "|**2025-11-21**|**LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation**|Darren Chiu et.al.|[2511.17765](https://arxiv.org/abs/2511.17765)|null|\n", "2511.17656": "|**2025-11-20**|**Multi-Agent Coordination in Autonomous Vehicle Routing: A Simulation-Based Study of Communication, Memory, and Routing Loops**|KM Khalid Saifullah et.al.|[2511.17656](https://arxiv.org/abs/2511.17656)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.17609": "|**2025-11-18**|**3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF**|Linh Van Ma et.al.|[2511.17609](https://arxiv.org/abs/2511.17609)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.20467": "|**2025-11-25**|**Power-Efficient Autonomous Mobile Robots**|Liangkai Liu et.al.|[2511.20467](https://arxiv.org/abs/2511.20467)|null|\n", "2511.20394": "|**2025-11-25**|**Improved adaptive wind driven optimization algorithm for real-time path planning**|Shiqian Liu et.al.|[2511.20394](https://arxiv.org/abs/2511.20394)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.20216": "|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Haebin Seong et.al.|[2511.20216](https://arxiv.org/abs/2511.20216)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2511.20180": "|**2025-11-25**|**Hibikino-Musashi@Home 2025 Team Description Paper**|Ryohei Kobayashi et.al.|[2511.20180](https://arxiv.org/abs/2511.20180)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.19770": "|**2025-11-26**|**Multi-Hypotheses Ego-Tracking for Resilient Navigation**|Peter Iwer Hoedt Karstensen et.al.|[2511.19770](https://arxiv.org/abs/2511.19770)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2511.19768": "|**2025-11-24**|**Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering**|Noah Frahm et.al.|[2511.19768](https://arxiv.org/abs/2511.19768)|null|\n", "2511.19451": "|**2025-11-19**|**Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control**|Apurva Patil et.al.|[2511.19451](https://arxiv.org/abs/2511.19451)|null|\n", "2511.19448": "|**2025-11-18**|**PuzzlePoles: Cylindrical Fiducial Markers Based on the PuzzleBoard Pattern**|Juri Zach et.al.|[2511.19448](https://arxiv.org/abs/2511.19448)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.21312": "|**2025-11-26**|**Neural NMPC through Signed Distance Field Encoding for Collision Avoidance**|Martin Jacquet et.al.|[2511.21312](https://arxiv.org/abs/2511.21312)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Ziyi Chen et.al.|[2511.21135](https://arxiv.org/abs/2511.21135)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2511.21083": "|**2025-11-26**|**Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry**|Feiyang Pan et.al.|[2511.21083](https://arxiv.org/abs/2511.21083)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2511.20894": "|**2025-11-25**|**Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization**|Vivek Pandey et.al.|[2511.20894](https://arxiv.org/abs/2511.20894)|null|\n", "2511.20720": "|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Haibo HU et.al.|[2511.20720](https://arxiv.org/abs/2511.20720)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2511.22685": "|**2025-11-27**|**Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation**|Haoyi Wang et.al.|[2511.22685](https://arxiv.org/abs/2511.22685)|null|\n", "2511.22364": "|**2025-11-27**|**BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands**|Seongwon Cho et.al.|[2511.22364](https://arxiv.org/abs/2511.22364)|null|\n", "2511.22018": "|**2025-11-27**|**MedEyes: Learning Dynamic Visual Focus for Medical Progressive Diagnosis**|Chunzheng Zhu et.al.|[2511.22018](https://arxiv.org/abs/2511.22018)|null|\n", "2512.01952": "|**2025-12-01**|**GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment**|Haoyang He et.al.|[2512.01952](https://arxiv.org/abs/2512.01952)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.01897": "|**2025-12-01**|**NeuroHJR: Hamilton-Jacobi Reachability-based Obstacle Avoidance in Complex Environments with Physics-Informed Neural Networks**|Granthik Halder et.al.|[2512.01897](https://arxiv.org/abs/2512.01897)|**[link](https://github.com/CYandYue/Auto-Get-Papers-pro)**|\n", "2512.01668": "|**2025-12-01**|**Dynamic Log-Gaussian Process Control Barrier Function for Safe Robotic Navigation in Dynamic Environments**|Xin Yin et.al.|[2512.01668](https://arxiv.org/abs/2512.01668)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|\n", "2512.01608": "|**2025-12-01**|**Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track**|Mo Chen et.al.|[2512.01608](https://arxiv.org/abs/2512.01608)|**[link](https://github.com/XiaomingX/arxiv-daily)**|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Fei Liu et.al.|[2512.01550](https://arxiv.org/abs/2512.01550)|null|\n", "2512.01194": "|**2025-12-01**|**RoboLoc: A Benchmark Dataset for Point Place Recognition and Localization in Indoor-Outdoor Integrated Environments**|Jaejin Jeon et.al.|[2512.01194](https://arxiv.org/abs/2512.01194)|null|\n", "2512.01052": "|**2025-11-30**|**Autonomous Grasping On Quadruped Robot With Task Level Interaction**|Muhtadin et.al.|[2512.01052](https://arxiv.org/abs/2512.01052)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.01009": "|**2025-11-30**|**FOM-Nav: Frontier-Object Maps for Object Goal Navigation**|Thomas Chabal et.al.|[2512.01009](https://arxiv.org/abs/2512.01009)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.00736": "|**2025-11-30**|**REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories**|Jacob Thompson et.al.|[2512.00736](https://arxiv.org/abs/2512.00736)|**[link](https://github.com/zezhishao/DailyArXiv)**|\n", "2512.00592": "|**2025-11-29**|**HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks**|Mihir Chauhan et.al.|[2512.00592](https://arxiv.org/abs/2512.00592)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.00226": "|**2025-11-28**|**DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation**|Zirui Wang et.al.|[2512.00226](https://arxiv.org/abs/2512.00226)|null|\n", "2512.00080": "|**2025-11-25**|**Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels**|Andr\u00e9 Dehne et.al.|[2512.00080](https://arxiv.org/abs/2512.00080)|**[link](https://github.com/ZhuYingJessica/cv-daily)**|\n", "2512.00076": "|**2025-11-25**|**Arcadia: Toward a Full-Lifecycle Framework for Embodied Lifelong Learning**|Minghe Gao et.al.|[2512.00076](https://arxiv.org/abs/2512.00076)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|\n", "2512.02851": "|**2025-12-03**|**SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots**|Iana Zhura et.al.|[2512.02851](https://arxiv.org/abs/2512.02851)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02631": "|**2025-12-02**|**SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization**|Zhengcheng Wang et.al.|[2512.02631](https://arxiv.org/abs/2512.02631)|**[link](https://huggingface.co/models/wangzc9865/SeeNav-Agent)**|\n", "2512.02458": "|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Zhongyi Cai et.al.|[2512.02458](https://arxiv.org/abs/2512.02458)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.02423": "|**2025-12-02**|**GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning**|Haolong Yan et.al.|[2512.02423](https://arxiv.org/abs/2512.02423)|**[link](https://github.com/stepfun-ai/gelab-zero)**|\n", "2512.03958": "|**2025-12-03**|**MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation**|Xiaobei Zhao et.al.|[2512.03958](https://arxiv.org/abs/2512.03958)|**[link](https://github.com/luohongk/Embodied-AI-Daily)**|\n", "2512.03736": "|**2025-12-03**|**Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control**|Kenneth Stewart et.al.|[2512.03736](https://arxiv.org/abs/2512.03736)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03639": "|**2025-12-03**|**Context-Triggered Contingency Games for Strategic Multi-Agent Interaction**|Kilian Schweppe et.al.|[2512.03639](https://arxiv.org/abs/2512.03639)|**[link](https://github.com/Blake-Jiang/ad-arxiv-daily)**|\n", "2512.03558": "|**2025-12-03**|**CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding**|Huy Quang Ung et.al.|[2512.03558](https://arxiv.org/abs/2512.03558)|null|\n", "2512.03429": "|**2025-12-03**|**World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations**|Raul Steinmetz et.al.|[2512.03429](https://arxiv.org/abs/2512.03429)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.03422": "|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Tianchen Deng et.al.|[2512.03422](https://arxiv.org/abs/2512.03422)|**[link](https://github.com/3D-Vision-World/awesome-NeRF-and-3DGS-SLAM)**|\n", "2512.03204": "|**2025-12-02**|**Scaling Internal-State Policy-Gradient Methods for POMDPs**|Douglas Aberdeen et.al.|[2512.03204](https://arxiv.org/abs/2512.03204)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|\n", "2512.04772": "|**2025-12-04**|**TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards**|Mauro Martini et.al.|[2512.04772](https://arxiv.org/abs/2512.04772)|**[link](https://github.com/Vincentqyw/cv-arxiv-daily)**|\n", "2512.04404": "|**2025-12-04**|**Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation**|Chaoran Wang et.al.|[2512.04404](https://arxiv.org/abs/2512.04404)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|\n", "2512.04381": "|**2025-12-04**|**FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination**|Chengyang He et.al.|[2512.04381](https://arxiv.org/abs/2512.04381)|null|\n", "2512.05808": "|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Sushmita Bhattacharya et.al.|[2512.05808](https://arxiv.org/abs/2512.05808)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2512.05211": "|**2025-12-04**|**Wake Vectoring for Efficient Morphing Flight**|Ioannis Mandralis et.al.|[2512.05211](https://arxiv.org/abs/2512.05211)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|\n", "2511.17588": "|**2025-11-16**|**Synthesis of mass-spring networks from high-level code descriptions**|Parisa Omidvar et.al.|[2511.17588](https://arxiv.org/abs/2511.17588)|null|\n", "2512.00041": "|**2025-11-14**|**VISTAv2: World Imagination for Indoor Vision-and-Language Navigation**|Yanjia Huang et.al.|[2512.00041](https://arxiv.org/abs/2512.00041)|**[link](https://github.com/leofan90/Awesome-World-Models)**|\n", "2512.00027": "|**2025-11-06**|**A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation**|Nivedan Yakolli et.al.|[2512.00027](https://arxiv.org/abs/2512.00027)|null|\n", "2510.26782": "|**2025-11-18**|**Clone Deterministic 3D Worlds**|Zaishuo Xia et.al.|[2510.26782](https://arxiv.org/abs/2510.26782)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|\n", "2511.00033": "|**2025-10-27**|**STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization**|Diqi He et.al.|[2511.00033](https://arxiv.org/abs/2511.00033)|null|\n", "2512.06147": "|**2025-12-05**|**GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers**|Hochul Hwang et.al.|[2512.06147](https://arxiv.org/abs/2512.06147)|**[link](https://github.com/Jianqiuer/Awesome6DPoseEstimation)**|\n"}}