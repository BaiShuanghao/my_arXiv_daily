---
layout: default
---

## Updated on 2025.08.12
> Usage instructions: [here](./docs/README.md#usage)

## Robot & Agent

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-08-11**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-09**|**$\mathcal{P}^3$ : Toward Versatile Embodied Agents**|Shengli Zhou et.al.|[2508.07033](https://arxiv.org/abs/2508.07033)|null|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-09**|**Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model**|Aswin Paul et.al.|[2508.06980](https://arxiv.org/abs/2508.06980)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Minku Kim et.al.|[2508.06779](https://arxiv.org/abs/2508.06779)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-08**|**Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation**|Youguang Xing et.al.|[2508.06426](https://arxiv.org/abs/2508.06426)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-08-04**|**A "good regulator theorem" for embodied agents**|Nathaniel Virgo et.al.|[2508.06326](https://arxiv.org/abs/2508.06326)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|**[link](https://github.com/wonderNefelibata/Awesome-LRM-Safety)**|
|**2025-08-07**|**OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks**|Zixuan Wang et.al.|[2508.05614](https://arxiv.org/abs/2508.05614)|**[link](https://huggingface.co/datasets/wangzx1210/OmniEAR)**|
|**2025-08-07**|**CleanUpBench: Embodied Sweeping and Grasping Benchmark**|Wenbo Li et.al.|[2508.05543](https://arxiv.org/abs/2508.05543)|null|
|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|null|
|**2025-08-05**|**DiWA: Diffusion Policy Adaptation with World Models**|Akshay L Chandra et.al.|[2508.03645](https://arxiv.org/abs/2508.03645)|null|
|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|Sirui Chen et.al.|[2508.03068](https://arxiv.org/abs/2508.03068)|null|
|**2025-08-04**|**Learning User Interaction Forces using Vision for a Soft Finger Exosuit**|Mohamed Irfan Refai et.al.|[2508.02870](https://arxiv.org/abs/2508.02870)|null|
|**2025-08-06**|**HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents**|Yibin Liu et.al.|[2508.02629](https://arxiv.org/abs/2508.02629)|**[link](https://github.com/jyyang621/DailyArXiv)**|
|**2025-08-04**|**Talking Surveys: How Photorealistic Embodied Conversational Agents Shape Response Quality, Engagement, and Satisfaction**|Matus Krajcovic et.al.|[2508.02376](https://arxiv.org/abs/2508.02376)|**[link](https://github.com/zhengzangw/DailyArXiv)**|
|**2025-08-04**|**ScrewSplat: An End-to-End Method for Articulated Object Recognition**|Seungyeon Kim et.al.|[2508.02146](https://arxiv.org/abs/2508.02146)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-03**|**Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by Recurrent Action-Confidence Chunking with Transformer**|Yu Tian et.al.|[2508.01808](https://arxiv.org/abs/2508.01808)|null|
|**2025-08-05**|**VPN: Visual Prompt Navigation**|Shuo Feng et.al.|[2508.01766](https://arxiv.org/abs/2508.01766)|null|
|**2025-08-03**|**OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping**|Danyang Li et.al.|[2508.01723](https://arxiv.org/abs/2508.01723)|null|
|**2025-08-03**|**DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding**|Hanqing Wang et.al.|[2508.01651](https://arxiv.org/abs/2508.01651)|null|
|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|null|
|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|null|
|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-08-01**|**Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking**|Haoyu Wang et.al.|[2508.00500](https://arxiv.org/abs/2508.00500)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-08-01**|**Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents**|Janika Deborah Gajo et.al.|[2508.00400](https://arxiv.org/abs/2508.00400)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-01**|**Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging**|Tianshuang Qiu et.al.|[2508.00354](https://arxiv.org/abs/2508.00354)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|
|**2025-07-31**|**SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting**|Di Li et.al.|[2507.23772](https://arxiv.org/abs/2507.23772)|**[link](https://github.com/hq-King/Awesome-Affordance-Learning)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-31**|**Policy Learning from Large Vision-Language Model Feedback without Reward Modeling**|Tung M. Luu et.al.|[2507.23391](https://arxiv.org/abs/2507.23391)|**[link](https://github.com/tunglm2203/plare)**|
|**2025-07-29**|**From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning**|Honglin He et.al.|[2507.22028](https://arxiv.org/abs/2507.22028)|**[link](https://github.com/ai4ce/CityWalker)**|
|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Yufei Jia et.al.|[2507.21981](https://arxiv.org/abs/2507.21981)|**[link](https://github.com/TATP-233/DISCOVERSE)**|
|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Yuying Zhang et.al.|[2507.21796](https://arxiv.org/abs/2507.21796)|null|
|**2025-08-03**|**Learning Physical Interaction Skills from Human Demonstrations**|Tianyu Li et.al.|[2507.20445](https://arxiv.org/abs/2507.20445)|null|
|**2025-07-26**|**Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models**|Anjali R. Menon et.al.|[2507.19854](https://arxiv.org/abs/2507.19854)|null|
|**2025-07-26**|**Moving Out: Physically-grounded Human-AI Collaboration**|Xuhui Kang et.al.|[2507.18623](https://arxiv.org/abs/2507.18623)|null|
|**2025-07-24**|**EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs**|Yuping He et.al.|[2507.18342](https://arxiv.org/abs/2507.18342)|null|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Chang Nie et.al.|[2507.17462](https://arxiv.org/abs/2507.17462)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al.|[2507.17294](https://arxiv.org/abs/2507.17294)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-25**|**Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning**|Po-Yen Wu et.al.|[2507.17275](https://arxiv.org/abs/2507.17275)|null|
|**2025-07-23**|**Towards Human-level Intelligence via Human-like Whole-Body Manipulation**|Guang Gao et.al.|[2507.17141](https://arxiv.org/abs/2507.17141)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-22**|**Benchmarking LLM Privacy Recognition for Social Robot Decision Making**|Dakota Sullivan et.al.|[2507.16124](https://arxiv.org/abs/2507.16124)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-21**|**Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers**|Ian Chuang et.al.|[2507.15833](https://arxiv.org/abs/2507.15833)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-22**|**GR-3 Technical Report**|Chilam Cheang et.al.|[2507.15493](https://arxiv.org/abs/2507.15493)|**[link](https://github.com/lucidrains/pi-zero-pytorch)**|
|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Jiaao Li et.al.|[2507.15428](https://arxiv.org/abs/2507.15428)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-20**|**Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions**|Majid Roshanfar et.al.|[2507.15155](https://arxiv.org/abs/2507.15155)|null|
|**2025-07-20**|**TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP**|Fan Li et.al.|[2507.14904](https://arxiv.org/abs/2507.14904)|**[link](https://github.com/Lyz103/LLM-Agent-Paper-daily)**|
|**2025-07-17**|**Latent Policy Steering with Embodiment-Agnostic Pretrained World Models**|Yiqi Wang et.al.|[2507.13340](https://arxiv.org/abs/2507.13340)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|
|**2025-07-17**|**Learning to Predict Mobile Robot Stability in Off-Road Environments**|Nathaniel Rose et.al.|[2507.12731](https://arxiv.org/abs/2507.12731)|null|

## Robotic Manipulation

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Kaijun Wang et.al.|[2508.08240](https://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling**|Zhuohao Yu et.al.|[2508.08211](https://arxiv.org/abs/2508.08211)|null|
|**2025-08-11**|**Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization**|Nicholas Klein et.al.|[2508.08141](https://arxiv.org/abs/2508.08141)|null|
|**2025-08-11**|**AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies**|Yinpei Dai et.al.|[2508.08113](https://arxiv.org/abs/2508.08113)|**[link](https://github.com/aimbot-reticle/openpi0-aimbot)**|
|**2025-08-11**|**False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability**|Yancheng Jiang et.al.|[2508.08043](https://arxiv.org/abs/2508.08043)|null|
|**2025-08-11**|**Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks**|Thusitha Dayaratne et.al.|[2508.08029](https://arxiv.org/abs/2508.08029)|null|
|**2025-08-11**|**Expert Preference-based Evaluation of Automated Related Work Generation**|Furkan Şahinuç et.al.|[2508.07955](https://arxiv.org/abs/2508.07955)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-11**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|En Yen Puang et.al.|[2508.07945](https://arxiv.org/abs/2508.07945)|null|
|**2025-08-11**|**Gate tunable spin-charge interconversion in a graphene/ReS $_{2}$ heterostructure up to room temperature**|Eoin Dolan et.al.|[2508.07888](https://arxiv.org/abs/2508.07888)|null|
|**2025-08-11**|**Selective Contrastive Learning for Weakly Supervised Affordance Grounding**|WonJun Moon et.al.|[2508.07877](https://arxiv.org/abs/2508.07877)|**[link](https://github.com/hynnsk/SelectiveCL)**|
|**2025-08-11**|**KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations**|Mubaris Nadeem et.al.|[2508.07834](https://arxiv.org/abs/2508.07834)|null|
|**2025-08-11**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation**|Antonio Rosales et.al.|[2508.07758](https://arxiv.org/abs/2508.07758)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-11**|**Observation and Modulation of the Quantum Mpemba Effect on a Superconducting Quantum Processor**|Yueshan Xu et.al.|[2508.07707](https://arxiv.org/abs/2508.07707)|null|
|**2025-08-11**|**Improving Continuous Grasp Force Decoding from EEG with Time-Frequency Regressors and Premotor-Parietal Network Integration**|Parth G. Dangi et.al.|[2508.07677](https://arxiv.org/abs/2508.07677)|**[link](https://github.com/HAIx-Lab/EEGForceMap)**|
|**2025-08-11**|**Ethics2vec: aligning automatic agents and human preferences**|Gianluca Bontempi et.al.|[2508.07673](https://arxiv.org/abs/2508.07673)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Helong Huang et.al.|[2508.07650](https://arxiv.org/abs/2508.07650)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-11**|**Grasp-HGN: Grasping the Unexpected**|Mehrshad Zandigohar et.al.|[2508.07648](https://arxiv.org/abs/2508.07648)|null|
|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Dejie Yang et.al.|[2508.07626](https://arxiv.org/abs/2508.07626)|null|
|**2025-08-11**|**Instantaneous optical selection rule for independent control of valley currents**|Wanzhu He et.al.|[2508.07612](https://arxiv.org/abs/2508.07612)|null|
|**2025-08-11**|**From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users**|Shahroz Tariq et.al.|[2508.07596](https://arxiv.org/abs/2508.07596)|null|
|**2025-08-11**|**Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning**|Stephan Rabanser et.al.|[2508.07556](https://arxiv.org/abs/2508.07556)|null|
|**2025-08-10**|**Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten**|Wei Qian et.al.|[2508.07458](https://arxiv.org/abs/2508.07458)|**[link](https://github.com/wqian507/unlearn_uncertainty)**|
|**2025-08-10**|**Ion Coulomb crystals: an exotic form of condensed matter**|Giovanna Morigi et.al.|[2508.07374](https://arxiv.org/abs/2508.07374)|null|
|**2025-08-10**|**KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features**|Ivan Kukanov et.al.|[2508.07337](https://arxiv.org/abs/2508.07337)|null|
|**2025-08-10**|**Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)**|Adeetya Uppal et.al.|[2508.07323](https://arxiv.org/abs/2508.07323)|null|
|**2025-08-10**|**A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks**|Yanzhao Yu et.al.|[2508.07319](https://arxiv.org/abs/2508.07319)|null|
|**2025-08-10**|**Multimodal Spiking Neural Network for Space Robotic Manipulation**|Liwen Zhang et.al.|[2508.07287](https://arxiv.org/abs/2508.07287)|null|
|**2025-08-10**|**Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization**|Songlin Li et.al.|[2508.07216](https://arxiv.org/abs/2508.07216)|null|
|**2025-08-10**|**Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI**|Ahmed M. Abuzuraiq et.al.|[2508.07183](https://arxiv.org/abs/2508.07183)|null|
|**2025-08-10**|**CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion**|Xiaotong Lin et.al.|[2508.07162](https://arxiv.org/abs/2508.07162)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|
|**2025-08-10**|**Canvas3D: Empowering Precise Spatial Control for Image Generation with Constraints from a 3D Virtual Canvas**|Runlin Duan et.al.|[2508.07135](https://arxiv.org/abs/2508.07135)|null|
|**2025-08-09**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Aiden Swann et.al.|[2508.07118](https://arxiv.org/abs/2508.07118)|**[link](https://github.com/dex-fruit/dex-fruit.github.io)**|
|**2025-08-09**|**Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications**|Ayane Lebeta Goshu et.al.|[2508.07098](https://arxiv.org/abs/2508.07098)|null|
|**2025-08-09**|**Joint Beamforming Optimization for Pinching-Antenna Systems (PASS)-assisted Symbiotic Radio**|Ze Wang et.al.|[2508.07002](https://arxiv.org/abs/2508.07002)|null|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-09**|**Manipulator for people with limited abilities**|Bingkun Huang et.al.|[2508.06969](https://arxiv.org/abs/2508.06969)|null|
|**2025-08-09**|**Millimeter-Wave Position Sensing Using Reconfigurable Intelligent Surfaces: Positioning Error Bound and Phase Shift Configuration**|Xin Cheng et.al.|[2508.06958](https://arxiv.org/abs/2508.06958)|null|
|**2025-08-09**|**Coulombic control of charge transfer in luminescent radicals with long-lived quartet states**|Lujo Matasovic et.al.|[2508.06945](https://arxiv.org/abs/2508.06945)|null|
|**2025-08-09**|**Optically Tunable Spin Transport in Bilayer Altermagnetic Mott Insulators**|Niklas Sicheler et.al.|[2508.06938](https://arxiv.org/abs/2508.06938)|null|
|**2025-08-09**|**Observation and Control of Chiral Spin Frustration in BiYIG Thin Films**|Jinlong Wang et.al.|[2508.06858](https://arxiv.org/abs/2508.06858)|null|
|**2025-08-09**|**Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation**|Nizamudheen V et.al.|[2508.06780](https://arxiv.org/abs/2508.06780)|null|
|**2025-08-09**|**Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual Integrity Perspective**|Sarah Tran et.al.|[2508.06760](https://arxiv.org/abs/2508.06760)|null|
|**2025-08-08**|**Learning Causal Structure Distributions for Robust Planning**|Alejandro Murillo-Gonzalez et.al.|[2508.06742](https://arxiv.org/abs/2508.06742)|null|
|**2025-08-08**|**In-Context Reinforcement Learning via Communicative World Models**|Fernando Martinez-Lopez et.al.|[2508.06659](https://arxiv.org/abs/2508.06659)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-08**|**When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation**|Dario Pasquini et.al.|[2508.06394](https://arxiv.org/abs/2508.06394)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-08**|**Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators**|Amir Hossein Barjini et.al.|[2508.06313](https://arxiv.org/abs/2508.06313)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-08-08**|**A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions**|Gerhard Kirsten et.al.|[2508.06303](https://arxiv.org/abs/2508.06303)|**[link](https://github.com/CYandYue/Auto-Get-Papers-pro)**|
|**2025-08-08**|**Real-Time 3D Vision-Language Embedding Mapping**|Christian Rauch et.al.|[2508.06291](https://arxiv.org/abs/2508.06291)|null|
|**2025-08-08**|**EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators**|Juan Heredia et.al.|[2508.06276](https://arxiv.org/abs/2508.06276)|null|

## Vision Language Action Model

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-08-11**|**Reinforcement Learning in Vision: A Survey**|Weijia Wu et.al.|[2508.08189](https://arxiv.org/abs/2508.08189)|null|
|**2025-08-11**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Jason Lee et.al.|[2508.07917](https://arxiv.org/abs/2508.07917)|null|
|**2025-08-11**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Helong Huang et.al.|[2508.07650](https://arxiv.org/abs/2508.07650)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-06**|**Static and Plugged: Make Embodied Evaluation Simple**|Jiahao Xiao et.al.|[2508.06553](https://arxiv.org/abs/2508.06553)|null|
|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Heran Wu et.al.|[2508.06547](https://arxiv.org/abs/2508.06547)|null|
|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Shunlei Li et.al.|[2508.05342](https://arxiv.org/abs/2508.05342)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|**[link](https://github.com/XiaoWei-i/Awesome-VLA-RL)**|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Zhigen Zhao et.al.|[2508.00097](https://arxiv.org/abs/2508.00097)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Xiaoyu Chen et.al.|[2507.23682](https://arxiv.org/abs/2507.23682)|**[link](https://huggingface.co/models/microsoft/villa-x)**|
|**2025-07-30**|**Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance**|Songsheng Wang et.al.|[2507.22424](https://arxiv.org/abs/2507.22424)|**[link](https://github.com/hemingkx/SpeculativeDecodingPapers)**|
|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Thomas P Zollo et.al.|[2507.17383](https://arxiv.org/abs/2507.17383)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al.|[2507.17294](https://arxiv.org/abs/2507.17294)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Hao Luo et.al.|[2507.15597](https://arxiv.org/abs/2507.15597)|**[link](https://huggingface.co/models/BeingBeyond/Being-H0)**|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Paweł Budzianowski et.al.|[2507.14049](https://arxiv.org/abs/2507.14049)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Ruihan Yang et.al.|[2507.12440](https://arxiv.org/abs/2507.12440)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Muhayy Ud Din et.al.|[2507.10672](https://arxiv.org/abs/2507.10672)|null|
|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Jialei Huang et.al.|[2507.09160](https://arxiv.org/abs/2507.09160)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Fan-Yun Sun et.al.|[2507.06484](https://arxiv.org/abs/2507.06484)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Qucheng Peng et.al.|[2507.05227](https://arxiv.org/abs/2507.05227)|null|
|**2025-07-17**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Wenyao Zhang et.al.|[2507.04447](https://arxiv.org/abs/2507.04447)|**[link](https://huggingface.co/models/WenyaoZhang/DreamVLA)**|
|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yifan Zhong et.al.|[2507.01925](https://arxiv.org/abs/2507.01925)|**[link](https://github.com/Psi-Robot/Awesome-VLA-Papers)**|
|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Dmytro Kuzmenko et.al.|[2507.01843](https://arxiv.org/abs/2507.01843)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Zhenyang Liu et.al.|[2507.01424](https://arxiv.org/abs/2507.01424)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|
|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Yating Wang et.al.|[2507.01016](https://arxiv.org/abs/2507.01016)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Tao Lin et.al.|[2507.00416](https://arxiv.org/abs/2507.00416)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Sicong Jiang et.al.|[2506.24044](https://arxiv.org/abs/2506.24044)|**[link](https://github.com/52CV/CV-Surveys)**|
|**2025-06-24**|**Unified Vision-Language-Action Model**|Yuqi Wang et.al.|[2506.19850](https://arxiv.org/abs/2506.19850)|**[link](https://huggingface.co/models/Yuqi1997/UniVLA)**|
|**2025-07-07**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Jacky Kwok et.al.|[2506.17811](https://arxiv.org/abs/2506.17811)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Yuxuan Chen et.al.|[2506.17639](https://arxiv.org/abs/2506.17639)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Chongkai Gao et.al.|[2506.17561](https://arxiv.org/abs/2506.17561)|**[link](https://huggingface.co/models/Linslab/VLA-OS)**|
|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Puhao Li et.al.|[2506.16211](https://arxiv.org/abs/2506.16211)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Zeyuan Chen et.al.|[2506.14317](https://arxiv.org/abs/2506.14317)|**[link](https://github.com/YanjieZe/3D-Diffusion-Policy)**|
|**2025-06-16**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Zewei Zhou et.al.|[2506.13757](https://arxiv.org/abs/2506.13757)|null|
|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Wenxuan Song et.al.|[2506.13725](https://arxiv.org/abs/2506.13725)|**[link](https://huggingface.co/models/chenpyyy/openvla-ac)**|
|**2025-06-16**|**Block-wise Adaptive Caching for Accelerating Diffusion Policy**|Kangye Ji et.al.|[2506.13456](https://arxiv.org/abs/2506.13456)|null|
|**2025-06-19**|**A Comprehensive Survey on Continual Learning in Generative Models**|Haiyang Guo et.al.|[2506.13045](https://arxiv.org/abs/2506.13045)|null|
|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Wenxuan Song et.al.|[2506.10826](https://arxiv.org/abs/2506.10826)|null|
|**2025-06-11**|**EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models**|Yantai Yang et.al.|[2506.10100](https://arxiv.org/abs/2506.10100)|null|
|**2025-06-11**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Qiao Gu et.al.|[2506.09937](https://arxiv.org/abs/2506.09937)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Irving Fang et.al.|[2506.09930](https://arxiv.org/abs/2506.09930)|**[link](https://huggingface.co/models/IPEC-COMMUNITY/spatialvla-4b-224-sft-bridge)**|
|**2025-06-17**|**An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Pranav Guruprasad et.al.|[2506.09172](https://arxiv.org/abs/2506.09172)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-06-11**|**TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization**|Zengjue Chen et.al.|[2506.08440](https://arxiv.org/abs/2506.08440)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Hongyu Wang et.al.|[2506.07530](https://arxiv.org/abs/2506.07530)|**[link](https://huggingface.co/models/hongyuw/bitvla-bitsiglipL-224px-bf16)**|
|**2025-06-09**|**Real-Time Execution of Action Chunking Flow Policies**|Kevin Black et.al.|[2506.07339](https://arxiv.org/abs/2506.07339)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-20**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Vineet Bhat et.al.|[2506.06535](https://arxiv.org/abs/2506.06535)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Meng Li et.al.|[2506.03574](https://arxiv.org/abs/2506.03574)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-03**|**Adversarial Attacks on Robotic Vision Language Action Models**|Eliot Krzysztof Jones et.al.|[2506.03350](https://arxiv.org/abs/2506.03350)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|

## Imitation Learning

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-08-11**|**ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction**|Chaojun Ni et.al.|[2508.08170](https://arxiv.org/abs/2508.08170)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-11**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|null|
|**2025-08-09**|**From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving**|Antonio Guillen-Perez et.al.|[2508.07029](https://arxiv.org/abs/2508.07029)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-07**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Anqing Jiang et.al.|[2508.06571](https://arxiv.org/abs/2508.06571)|null|
|**2025-08-08**|**Towards Balanced Behavior Cloning from Imbalanced Datasets**|Sagar Parekh et.al.|[2508.06319](https://arxiv.org/abs/2508.06319)|null|
|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Daechul Ahn et.al.|[2508.06042](https://arxiv.org/abs/2508.06042)|**[link](https://github.com/tangwen-qian/DailyArXiv)**|
|**2025-08-08**|**Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning**|Haohui Chen et.al.|[2508.05960](https://arxiv.org/abs/2508.05960)|**[link](https://github.com/CoderBak/DailyArXiv)**|
|**2025-08-08**|**Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution**|Zhanyi Sun et.al.|[2508.05941](https://arxiv.org/abs/2508.05941)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-08-07**|**ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning**|Jelle Luijkx et.al.|[2508.05310](https://arxiv.org/abs/2508.05310)|null|
|**2025-08-07**|**Cognitive Duality for Adaptive Web Agents**|Jiarun Liu et.al.|[2508.05081](https://arxiv.org/abs/2508.05081)|null|
|**2025-08-07**|**Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning**|Luai Abuelsamen et.al.|[2508.05077](https://arxiv.org/abs/2508.05077)|null|
|**2025-08-05**|**Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection**|Le Qiu et.al.|[2508.03129](https://arxiv.org/abs/2508.03129)|**[link](https://github.com/dingyue772/DailyArxiv)**|
|**2025-08-05**|**Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control**|Yi-Hsuan Hsiao et.al.|[2508.03043](https://arxiv.org/abs/2508.03043)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-04**|**Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach**|Peng Wei et.al.|[2508.02617](https://arxiv.org/abs/2508.02617)|null|
|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|**[link](https://github.com/XiaoWei-i/Awesome-VLA-RL)**|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|null|
|**2025-08-02**|**Physically-based Lighting Augmentation for Robotic Manipulation**|Shutong Jin et.al.|[2508.01442](https://arxiv.org/abs/2508.01442)|null|
|**2025-08-02**|**T2S: Tokenized Skill Scaling for Lifelong Imitation Learning**|Hongquan Zhang et.al.|[2508.01167](https://arxiv.org/abs/2508.01167)|null|
|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|null|
|**2025-08-01**|**Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation**|Ibrahim Althamary et.al.|[2508.01060](https://arxiv.org/abs/2508.01060)|null|
|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|null|
|**2025-08-01**|**On-Device Diffusion Transformer Policy for Efficient Robot Manipulation**|Yiming Wu et.al.|[2508.00697](https://arxiv.org/abs/2508.00697)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|
|**2025-08-01**|**HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning**|Carlo Alessi et.al.|[2508.00491](https://arxiv.org/abs/2508.00491)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-08-01**|**Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning**|Saichao Liu et.al.|[2508.00261](https://arxiv.org/abs/2508.00261)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-30**|**Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations**|Yifei Chen et.al.|[2507.22380](https://arxiv.org/abs/2507.22380)|null|
|**2025-07-29**|**RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation**|Dongyub Jude Lee et.al.|[2507.22219](https://arxiv.org/abs/2507.22219)|null|
|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Yufei Jia et.al.|[2507.21981](https://arxiv.org/abs/2507.21981)|null|
|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Yuying Zhang et.al.|[2507.21796](https://arxiv.org/abs/2507.21796)|null|
|**2025-07-29**|**Model Predictive Adversarial Imitation Learning for Planning from Observation**|Tyler Han et.al.|[2507.21533](https://arxiv.org/abs/2507.21533)|null|
|**2025-07-29**|**Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training**|Sodtavilan Odonchimed et.al.|[2507.21452](https://arxiv.org/abs/2507.21452)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-07-28**|**FMimic: Foundation Models are Fine-grained Action Learners from Human Videos**|Guangyan Chen et.al.|[2507.20622](https://arxiv.org/abs/2507.20622)|**[link](https://github.com/GuanchengWan/awesome-ai-ml-papers-auto)**|
|**2025-07-26**|**Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models**|Anjali R. Menon et.al.|[2507.19854](https://arxiv.org/abs/2507.19854)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-26**|**Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation**|Ziyin Xiong et.al.|[2507.19817](https://arxiv.org/abs/2507.19817)|null|
|**2025-07-25**|**GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning**|Amin Banayeeanzade et.al.|[2507.19647](https://arxiv.org/abs/2507.19647)|null|
|**2025-07-25**|**MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service**|Ming Gong et.al.|[2507.18884](https://arxiv.org/abs/2507.18884)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-24**|**Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning**|David Blanco-Mulero et.al.|[2507.18436](https://arxiv.org/abs/2507.18436)|**[link](https://github.com/GuanchengWan/awesome-ai-ml-papers-auto)**|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Chang Nie et.al.|[2507.17462](https://arxiv.org/abs/2507.17462)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-23**|**Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning**|Joobin Jin et.al.|[2507.17418](https://arxiv.org/abs/2507.17418)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-07-23**|**Confounded Causal Imitation Learning with Instrumental Variables**|Yan Zeng et.al.|[2507.17309](https://arxiv.org/abs/2507.17309)|null|
|**2025-07-22**|**Pragmatic Policy Development via Interpretable Behavior Cloning**|Anton Matsson et.al.|[2507.17056](https://arxiv.org/abs/2507.17056)|null|
|**2025-07-19**|**Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning**|Yinan Meng et.al.|[2507.16842](https://arxiv.org/abs/2507.16842)|null|
|**2025-07-22**|**GR-3 Technical Report**|Chilam Cheang et.al.|[2507.15493](https://arxiv.org/abs/2507.15493)|null|
|**2025-07-20**|**Reinforcement Learning for Flow-Matching Policies**|Samuel Pfrommer et.al.|[2507.15073](https://arxiv.org/abs/2507.15073)|null|
|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|Chengwei Lou et.al.|[2507.14995](https://arxiv.org/abs/2507.14995)|null|
|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Shivakanth Sujit et.al.|[2507.13602](https://arxiv.org/abs/2507.13602)|null|
|**2025-07-17**|**Latent Policy Steering with Embodiment-Agnostic Pretrained World Models**|Yiqi Wang et.al.|[2507.13340](https://arxiv.org/abs/2507.13340)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|
|**2025-07-17**|**The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner**|Zhouqi Hua et.al.|[2507.13332](https://arxiv.org/abs/2507.13332)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|
|**2025-07-17**|**ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning**|Rahel Rickenbach et.al.|[2507.13088](https://arxiv.org/abs/2507.13088)|**[link](https://github.com/GuanchengWan/awesome-ai-ml-papers-auto)**|

## Robotic Navigation

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2025-08-11**|**BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion**|Takara E. Truong et.al.|[2508.08241](https://arxiv.org/abs/2508.08241)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|
|**2025-08-11**|**Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy**|Haiyue Chen et.al.|[2508.08226](https://arxiv.org/abs/2508.08226)|null|
|**2025-08-11**|**Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning**|Zihe Liu et.al.|[2508.08221](https://arxiv.org/abs/2508.08221)|null|
|**2025-08-11**|**Tunable edge and depth sensing via phase-change nonlocal metasurfaces**|Kenan Guo et.al.|[2508.08202](https://arxiv.org/abs/2508.08202)|null|
|**2025-08-11**|**Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration**|Vladimir Zhurov et.al.|[2508.08128](https://arxiv.org/abs/2508.08128)|null|
|**2025-08-11**|**Vision-Based Localization and LLM-based Navigation for Indoor Environments**|Keyan Rahimi et.al.|[2508.08120](https://arxiv.org/abs/2508.08120)|null|
|**2025-08-11**|**Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain**|Wei Zhang et.al.|[2508.08108](https://arxiv.org/abs/2508.08108)|null|
|**2025-08-11**|**Grid2Guide: A* Enabled Small Language Model for Indoor Navigation**|Md. Wasiul Haque et.al.|[2508.08100](https://arxiv.org/abs/2508.08100)|null|
|**2025-08-11**|**How Quantum Agents Can Change Which Strategies Are More Complex**|Spiros Kechrimparis et.al.|[2508.08092](https://arxiv.org/abs/2508.08092)|null|
|**2025-08-11**|**Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning**|Shoaib Ahmmad et.al.|[2508.07885](https://arxiv.org/abs/2508.07885)|null|
|**2025-08-11**|**SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing**|Malaika Zafar et.al.|[2508.07814](https://arxiv.org/abs/2508.07814)|null|
|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Tianyi Ma et.al.|[2508.07642](https://arxiv.org/abs/2508.07642)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-11**|**End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy**|Zifan Wang et.al.|[2508.07611](https://arxiv.org/abs/2508.07611)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|
|**2025-08-10**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiaobei Zhao et.al.|[2508.07406](https://arxiv.org/abs/2508.07406)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-10**|**MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control**|Basant Sharma et.al.|[2508.07387](https://arxiv.org/abs/2508.07387)|null|
|**2025-08-10**|**In-person, Online and Back Again -- A Tale of Three Hybrid Hackathons**|Abasi-amefon Obot Affia-Jomants et.al.|[2508.07301](https://arxiv.org/abs/2508.07301)|null|
|**2025-08-10**|**Time-dependent Zermelo navigation with tacking**|Steen Markvorsen et.al.|[2508.07274](https://arxiv.org/abs/2508.07274)|**[link](https://github.com/FrederikMR/zermelo_tacking)**|
|**2025-08-10**|**Navigation and Exploration with Active Inference: from Biology to Industry**|Daria de Tinguy et.al.|[2508.07269](https://arxiv.org/abs/2508.07269)|null|
|**2025-08-10**|**Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics**|Daria de Tinguy et.al.|[2508.07267](https://arxiv.org/abs/2508.07267)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-10**|**Hybrid-Locked Kerr Microcombs for Flexible On-Chip Optical Clock Division**|Andrei Diakonov et.al.|[2508.07258](https://arxiv.org/abs/2508.07258)|null|
|**2025-08-10**|**Understanding Dynamic Scenes in Ego Centric 4D Point Clouds**|Junsheng Huang et.al.|[2508.07251](https://arxiv.org/abs/2508.07251)|null|
|**2025-08-09**|**Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction**|Mohamed Parvez Aslam et.al.|[2508.07079](https://arxiv.org/abs/2508.07079)|null|
|**2025-08-09**|**Beyond Problem Solving: Framing and Problem-Solution Co-Evolution in Data Visualization Design**|Paul C. Parsons et.al.|[2508.07058](https://arxiv.org/abs/2508.07058)|null|
|**2025-08-09**|**From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline**|Dennis Benders et.al.|[2508.07045](https://arxiv.org/abs/2508.07045)|null|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-09**|**AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance**|Lixuan He et.al.|[2508.06944](https://arxiv.org/abs/2508.06944)|**[link](https://github.com/TSYJ-He/AMFT)**|
|**2025-08-09**|**Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network**|Bing Li et.al.|[2508.06864](https://arxiv.org/abs/2508.06864)|null|
|**2025-08-09**|**Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation**|Xuan Zhao et.al.|[2508.06823](https://arxiv.org/abs/2508.06823)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Minku Kim et.al.|[2508.06779](https://arxiv.org/abs/2508.06779)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-08**|**Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC**|Justin London et.al.|[2508.06722](https://arxiv.org/abs/2508.06722)|null|
|**2025-08-08**|**Zero-Shot Cellular Trajectory Map Matching**|Weijie Shi et.al.|[2508.06674](https://arxiv.org/abs/2508.06674)|null|
|**2025-08-08**|**GPU-accelerated Direct Geolocation of GNSS Interference**|Jacob S. Clements et.al.|[2508.06672](https://arxiv.org/abs/2508.06672)|null|
|**2025-08-08**|**A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis**|Xinglin Zhao et.al.|[2508.06589](https://arxiv.org/abs/2508.06589)|null|
|**2025-08-08**|**Characterization and automated optimization of laser-driven proton beams from converging liquid sheet jet targets**|G. D. Glenn et.al.|[2508.06462](https://arxiv.org/abs/2508.06462)|null|
|**2025-08-08**|**V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles**|Abdullah Zareh Andaryan et.al.|[2508.06404](https://arxiv.org/abs/2508.06404)|null|
|**2025-08-08**|**REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance**|Zihao Xu et.al.|[2508.06229](https://arxiv.org/abs/2508.06229)|**[link](https://github.com/Ed1sonChen/DailyArxiv)**|
|**2025-08-08**|**Depth Jitter: Seeing through the Depth**|Md Sazidur Rahman et.al.|[2508.06227](https://arxiv.org/abs/2508.06227)|**[link](https://github.com/mim-team/Depth-Jitter)**|
|**2025-08-08**|**Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor**|Dominik Brämer et.al.|[2508.06177](https://arxiv.org/abs/2508.06177)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-08-08**|**GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning**|Xing Lei et.al.|[2508.06108](https://arxiv.org/abs/2508.06108)|**[link](https://github.com/CoderBak/DailyArXiv)**|
|**2025-08-08**|**ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation**|Daniel Lee et.al.|[2508.06065](https://arxiv.org/abs/2508.06065)|null|
|**2025-08-08**|**Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles**|Shaoting Liu et.al.|[2508.05972](https://arxiv.org/abs/2508.05972)|null|
|**2025-08-08**|**It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design**|Kathy Cheng et.al.|[2508.05940](https://arxiv.org/abs/2508.05940)|null|
|**2025-08-07**|**Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures**|Martin Deron et.al.|[2508.05860](https://arxiv.org/abs/2508.05860)|null|
|**2025-08-07**|**Safety of Embodied Navigation: A Survey**|Zixia Wang et.al.|[2508.05855](https://arxiv.org/abs/2508.05855)|null|
|**2025-08-07**|**Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction**|Ahmad Farooq et.al.|[2508.05838](https://arxiv.org/abs/2508.05838)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|
|**2025-08-07**|**Progress and new challenges in image-based profiling**|Erik Serrano et.al.|[2508.05800](https://arxiv.org/abs/2508.05800)|null|
|**2025-08-07**|**AI-Guided Exploration of Large-Scale Codebases**|Yoseph Berhanu Alebachew et.al.|[2508.05799](https://arxiv.org/abs/2508.05799)|null|
|**2025-08-07**|**GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems**|Keyvan Majd et.al.|[2508.05773](https://arxiv.org/abs/2508.05773)|null|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|null|
|**2025-08-07**|**TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution**|Zhikai Zhao et.al.|[2508.05616](https://arxiv.org/abs/2508.05616)|null|

