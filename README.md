## Updated on 2025.08.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#robot-&-agent>Robot & Agent</a></li>
    <li><a href=#robotic-manipulation>Robotic Manipulation</a></li>
    <li><a href=#vision-language-action-model>Vision Language Action Model</a></li>
    <li><a href=#imitation-learning>Imitation Learning</a></li>
    <li><a href=#robotic-navigation>Robotic Navigation</a></li>
  </ol>
</details>

## Robot & Agent

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-14**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Andrea Rosasco et.al.|[2508.10511](https://arxiv.org/abs/2508.10511)|null|
|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Marion Lepert et.al.|[2508.09976](https://arxiv.org/abs/2508.09976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion**|Seungeun Rho et.al.|[2508.08982](https://arxiv.org/abs/2508.08982)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-09**|**$\mathcal{P}^3$ : Toward Versatile Embodied Agents**|Shengli Zhou et.al.|[2508.07033](https://arxiv.org/abs/2508.07033)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-09**|**Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model**|Aswin Paul et.al.|[2508.06980](https://arxiv.org/abs/2508.06980)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Minku Kim et.al.|[2508.06779](https://arxiv.org/abs/2508.06779)|null|
|**2025-08-08**|**Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation**|Youguang Xing et.al.|[2508.06426](https://arxiv.org/abs/2508.06426)|null|
|**2025-08-04**|**A "good regulator theorem" for embodied agents**|Nathaniel Virgo et.al.|[2508.06326](https://arxiv.org/abs/2508.06326)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|null|
|**2025-08-07**|**OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks**|Zixuan Wang et.al.|[2508.05614](https://arxiv.org/abs/2508.05614)|**[link](https://huggingface.co/datasets/wangzx1210/OmniEAR)**|
|**2025-08-07**|**CleanUpBench: Embodied Sweeping and Grasping Benchmark**|Wenbo Li et.al.|[2508.05543](https://arxiv.org/abs/2508.05543)|null|
|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-05**|**DiWA: Diffusion Policy Adaptation with World Models**|Akshay L Chandra et.al.|[2508.03645](https://arxiv.org/abs/2508.03645)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|Sirui Chen et.al.|[2508.03068](https://arxiv.org/abs/2508.03068)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|
|**2025-08-04**|**Learning User Interaction Forces using Vision for a Soft Finger Exosuit**|Mohamed Irfan Refai et.al.|[2508.02870](https://arxiv.org/abs/2508.02870)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-06**|**HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents**|Yibin Liu et.al.|[2508.02629](https://arxiv.org/abs/2508.02629)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-04**|**Talking Surveys: How Photorealistic Embodied Conversational Agents Shape Response Quality, Engagement, and Satisfaction**|Matus Krajcovic et.al.|[2508.02376](https://arxiv.org/abs/2508.02376)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-04**|**ScrewSplat: An End-to-End Method for Articulated Object Recognition**|Seungyeon Kim et.al.|[2508.02146](https://arxiv.org/abs/2508.02146)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-03**|**Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by Recurrent Action-Confidence Chunking with Transformer**|Yu Tian et.al.|[2508.01808](https://arxiv.org/abs/2508.01808)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-05**|**VPN: Visual Prompt Navigation**|Shuo Feng et.al.|[2508.01766](https://arxiv.org/abs/2508.01766)|null|
|**2025-08-03**|**OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping**|Danyang Li et.al.|[2508.01723](https://arxiv.org/abs/2508.01723)|null|
|**2025-08-03**|**DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding**|Hanqing Wang et.al.|[2508.01651](https://arxiv.org/abs/2508.01651)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-08-01**|**Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking**|Haoyu Wang et.al.|[2508.00500](https://arxiv.org/abs/2508.00500)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-08-01**|**Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents**|Janika Deborah Gajo et.al.|[2508.00400](https://arxiv.org/abs/2508.00400)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-01**|**Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging**|Tianshuang Qiu et.al.|[2508.00354](https://arxiv.org/abs/2508.00354)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|
|**2025-07-31**|**SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting**|Di Li et.al.|[2507.23772](https://arxiv.org/abs/2507.23772)|**[link](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|null|
|**2025-07-31**|**Policy Learning from Large Vision-Language Model Feedback without Reward Modeling**|Tung M. Luu et.al.|[2507.23391](https://arxiv.org/abs/2507.23391)|null|
|**2025-07-29**|**From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning**|Honglin He et.al.|[2507.22028](https://arxiv.org/abs/2507.22028)|null|
|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Yufei Jia et.al.|[2507.21981](https://arxiv.org/abs/2507.21981)|null|
|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Yuying Zhang et.al.|[2507.21796](https://arxiv.org/abs/2507.21796)|null|
|**2025-08-03**|**Learning Physical Interaction Skills from Human Demonstrations**|Tianyu Li et.al.|[2507.20445](https://arxiv.org/abs/2507.20445)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-26**|**Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models**|Anjali R. Menon et.al.|[2507.19854](https://arxiv.org/abs/2507.19854)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-26**|**Moving Out: Physically-grounded Human-AI Collaboration**|Xuhui Kang et.al.|[2507.18623](https://arxiv.org/abs/2507.18623)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-24**|**EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs**|Yuping He et.al.|[2507.18342](https://arxiv.org/abs/2507.18342)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Chang Nie et.al.|[2507.17462](https://arxiv.org/abs/2507.17462)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al.|[2507.17294](https://arxiv.org/abs/2507.17294)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-25**|**Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning**|Po-Yen Wu et.al.|[2507.17275](https://arxiv.org/abs/2507.17275)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-23**|**Towards Human-level Intelligence via Human-like Whole-Body Manipulation**|Guang Gao et.al.|[2507.17141](https://arxiv.org/abs/2507.17141)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-22**|**Benchmarking LLM Privacy Recognition for Social Robot Decision Making**|Dakota Sullivan et.al.|[2507.16124](https://arxiv.org/abs/2507.16124)|null|
|**2025-07-21**|**Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers**|Ian Chuang et.al.|[2507.15833](https://arxiv.org/abs/2507.15833)|null|
|**2025-07-22**|**GR-3 Technical Report**|Chilam Cheang et.al.|[2507.15493](https://arxiv.org/abs/2507.15493)|null|
|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Jiaao Li et.al.|[2507.15428](https://arxiv.org/abs/2507.15428)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-20**|**Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions**|Majid Roshanfar et.al.|[2507.15155](https://arxiv.org/abs/2507.15155)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-20**|**TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP**|Fan Li et.al.|[2507.14904](https://arxiv.org/abs/2507.14904)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-17**|**Latent Policy Steering with Embodiment-Agnostic Pretrained World Models**|Yiqi Wang et.al.|[2507.13340](https://arxiv.org/abs/2507.13340)|**[link](https://github.com/LMD0311/Awesome-World-Model)**|
|**2025-07-17**|**Learning to Predict Mobile Robot Stability in Off-Road Environments**|Nathaniel Rose et.al.|[2507.12731](https://arxiv.org/abs/2507.12731)|null|

<p align=right>(<a href=#updated-on-20250815>back to top</a>)</p>

## Robotic Manipulation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-14**|**Learning Task Execution Hierarchies for Redundant Robots**|Alessandro Adami et.al.|[2508.10780](https://arxiv.org/abs/2508.10780)|**[link](https://github.com/GuanchengWan/awesome-ai-ml-papers-auto)**|
|**2025-08-14**|**From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models**|Tiancheng Han et.al.|[2508.10770](https://arxiv.org/abs/2508.10770)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-14**|**Multi-Functional Polarization-Based Coverage Control through Static Passive EMSs**|Giacomo Oliveri et.al.|[2508.10730](https://arxiv.org/abs/2508.10730)|null|
|**2025-08-14**|**MirGuard: Towards a Robust Provenance-based Intrusion Detection System Against Graph Manipulation Attacks**|Anyuan Sang et.al.|[2508.10639](https://arxiv.org/abs/2508.10639)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-14**|**MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models**|Xinyan Jiang et.al.|[2508.10599](https://arxiv.org/abs/2508.10599)|null|
|**2025-08-14**|**Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions**|Birgit Nierula et.al.|[2508.10586](https://arxiv.org/abs/2508.10586)|null|
|**2025-08-14**|**MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm**|Xin Liu et.al.|[2508.10538](https://arxiv.org/abs/2508.10538)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-14**|**Projected Coupled Diffusion for Test-Time Constrained Joint Generation**|Hao Luan et.al.|[2508.10531](https://arxiv.org/abs/2508.10531)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-14**|**Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures**|Jonas Ulmen et.al.|[2508.10489](https://arxiv.org/abs/2508.10489)|**[link](https://github.com/Tavish9/awesome-daily-AI-arxiv)**|
|**2025-08-14**|**Edgetronics in 2D Altermagnet via Real-Space-Spin Coupling**|Shibo Fang et.al.|[2508.10451](https://arxiv.org/abs/2508.10451)|null|
|**2025-08-14**|**Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation**|Huizhen Shu et.al.|[2508.10404](https://arxiv.org/abs/2508.10404)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|null|
|**2025-08-14**|**A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons**|Yu Chen et.al.|[2508.10378](https://arxiv.org/abs/2508.10378)|null|
|**2025-08-14**|**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**|Wenxuan Song et.al.|[2508.10333](https://arxiv.org/abs/2508.10333)|null|
|**2025-08-13**|**Detecting Untargeted Attacks and Mitigating Unreliable Updates in Federated Learning for Underground Mining Operations**|Md Sazedur Rahman et.al.|[2508.10212](https://arxiv.org/abs/2508.10212)|null|
|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Marion Lepert et.al.|[2508.09976](https://arxiv.org/abs/2508.09976)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**LIA-X: Interpretable Latent Portrait Animator**|Yaohui Wang et.al.|[2508.09959](https://arxiv.org/abs/2508.09959)|**[link](https://huggingface.co/spaces/YaohuiW/LIA-X)**|
|**2025-08-13**|**Machine Learning for Detecting Collusion and Capacity Withholding in Wholesale Electricity Markets**|Jeremy Proz et.al.|[2508.09885](https://arxiv.org/abs/2508.09885)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Spin-chirality-dependent modulation of topological gap, Chern number, and valley-polarization in monolayer Kagome materials**|Wenzhe Zhou et.al.|[2508.09884](https://arxiv.org/abs/2508.09884)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes**|Yuekun Wu et.al.|[2508.09855](https://arxiv.org/abs/2508.09855)|**[link](https://github.com/longxiang-ai/awesome-gaussians)**|
|**2025-08-13**|**Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation**|Donghoon Baek et.al.|[2508.09846](https://arxiv.org/abs/2508.09846)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Embodied Tactile Perception of Soft Objects Properties**|Anirvan Dutta et.al.|[2508.09836](https://arxiv.org/abs/2508.09836)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification**|Linh Nguyen et.al.|[2508.09832](https://arxiv.org/abs/2508.09832)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Physical Autoregressive Model for Robotic Manipulation without Action Pretraining**|Zijian Song et.al.|[2508.09822](https://arxiv.org/abs/2508.09822)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-13**|**Provable In-Context Vector Arithmetic via Retrieving Task Concepts**|Dake Bu et.al.|[2508.09820](https://arxiv.org/abs/2508.09820)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models**|Ridwan Mahbub et.al.|[2508.09716](https://arxiv.org/abs/2508.09716)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-13**|**Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions**|Mahdi Hejrati et.al.|[2508.09700](https://arxiv.org/abs/2508.09700)|null|
|**2025-08-13**|**Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation**|Ziyang Ma et.al.|[2508.09666](https://arxiv.org/abs/2508.09666)|null|
|**2025-08-13**|**Skyrmions with customized intensity distribution and trajectory**|Yihan Tian et.al.|[2508.09657](https://arxiv.org/abs/2508.09657)|null|
|**2025-08-13**|**BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots**|Alejandro Posadas-Nava et.al.|[2508.09606](https://arxiv.org/abs/2508.09606)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-14**|**Vortex Light at the Nanoscale: Twists, Spins, and Surprises -- A Review**|Kayn A Forbes et.al.|[2508.09564](https://arxiv.org/abs/2508.09564)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges**|Changyuan Zhao et.al.|[2508.09561](https://arxiv.org/abs/2508.09561)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-13**|**CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail**|Jiahui Zuo et.al.|[2508.09558](https://arxiv.org/abs/2508.09558)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Reactive Model Predictive Contouring Control for Robot Manipulators**|Junheon Yoon et.al.|[2508.09502](https://arxiv.org/abs/2508.09502)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Handows: A Palm-Based Interactive Multi-Window Management System in Virtual Reality**|Jindu Wang et.al.|[2508.09469](https://arxiv.org/abs/2508.09469)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization**|Wen Huang et.al.|[2508.09459](https://arxiv.org/abs/2508.09459)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding**|Junxian Li et.al.|[2508.09456](https://arxiv.org/abs/2508.09456)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-13**|**The watery atmosphere of HD~209458~b revealed by joint $K$- and $L$ -band high-resolution spectroscopy**|Luke Finnerty et.al.|[2508.09448](https://arxiv.org/abs/2508.09448)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Ultrafast Optical Evidence of Split Density Waves in Bilayer Nickelate La $_3$Ni$_2$O$_7$**|Qi-Yi Wu et.al.|[2508.09436](https://arxiv.org/abs/2508.09436)|null|
|**2025-08-12**|**How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy**|Zhenjiang Mao et.al.|[2508.09346](https://arxiv.org/abs/2508.09346)|null|
|**2025-08-12**|**Collective dynamics of strategic classification**|Marta C. Couto et.al.|[2508.09340](https://arxiv.org/abs/2508.09340)|null|
|**2025-08-12**|**SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning**|Alexandre Brown et.al.|[2508.09325](https://arxiv.org/abs/2508.09325)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Demonstration of a photonic time-frequency Fourier transform and temporal double slit using atomic quantum memory**|Ankit Papneja et.al.|[2508.09316](https://arxiv.org/abs/2508.09316)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**TFZ: Topology-Preserving Compression of 2D Symmetric and Asymmetric Second-Order Tensor Fields**|Nathaniel Gorski et.al.|[2508.09235](https://arxiv.org/abs/2508.09235)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer**|Zixin Yin et.al.|[2508.09131](https://arxiv.org/abs/2508.09131)|**[link](https://github.com/wangkai930418/awesome-diffusion-categorized)**|
|**2025-08-12**|**Deep Learning Models for Robust Facial Liveness Detection**|Oleksandr Kuznetsov et.al.|[2508.09094](https://arxiv.org/abs/2508.09094)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Lin Sun et.al.|[2508.09071](https://arxiv.org/abs/2508.09071)|**[link](https://github.com/AoqunJin/Awesome-VLA-Post-Training)**|
|**2025-08-12**|**Large Scale Robotic Material Handling: Learning, Planning, and Control**|Filippo A. Spinelli et.al.|[2508.09003](https://arxiv.org/abs/2508.09003)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Nanoscale lattice heterostructure in high Tc superconductors**|Annette Bussmann-Holder et.al.|[2508.08994](https://arxiv.org/abs/2508.08994)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Rational Inverse Reasoning**|Ben Zandonati et.al.|[2508.08983](https://arxiv.org/abs/2508.08983)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Addressing the Heterogeneity of Visualization in an Introductory PhD Course in the Swedish Context**|Kostiantyn Kucher et.al.|[2508.08958](https://arxiv.org/abs/2508.08958)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Ferroelectric Control of Interlayer Excitons in 3R-MoS $_{2}$ / MoSe$_{2}$ Heterostructures**|Johannes Schwandt-Krause et.al.|[2508.08911](https://arxiv.org/abs/2508.08911)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors**|Haoyu Zhao et.al.|[2508.08896](https://arxiv.org/abs/2508.08896)|null|
|**2025-08-12**|**Towards all-optical spin manipulation in single molecules: a refined region for locating a dark resonance**|Robert Smit et.al.|[2508.08835](https://arxiv.org/abs/2508.08835)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT**|Muhammad A. Muttaqien et.al.|[2508.08748](https://arxiv.org/abs/2508.08748)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Topological Control of Chirality and Spin with Structured Light**|Light Mkhumbuza et.al.|[2508.08733](https://arxiv.org/abs/2508.08733)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Haoran Ding et.al.|[2508.08707](https://arxiv.org/abs/2508.08707)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Zhengxue Cheng et.al.|[2508.08706](https://arxiv.org/abs/2508.08706)|**[link](https://github.com/linchangyi1/Awesome-Touch)**|
|**2025-08-12**|**Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation**|Xin Wang et.al.|[2508.08660](https://arxiv.org/abs/2508.08660)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Byzantine-Resilient Decentralized Online Resource Allocation**|Runhua Wang et.al.|[2508.08658](https://arxiv.org/abs/2508.08658)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Autonomous Mobile Plant Watering Robot : A Kinematic Approach**|Justin London et.al.|[2508.08607](https://arxiv.org/abs/2508.08607)|null|
|**2025-08-12**|**Analytical modeling of the gravitational potential of irregularly shaped celestial bodies considering three distinct internal structures: application to (21) Lutetia**|Marcelo L. Mota et.al.|[2508.08538](https://arxiv.org/abs/2508.08538)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models**|Mansi Phute et.al.|[2508.08521](https://arxiv.org/abs/2508.08521)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-11**|**A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search**|Joan Salvà Soler et.al.|[2508.08477](https://arxiv.org/abs/2508.08477)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Multistable polar textures in geometrically frustrated nematic liquid crystals**|Ufuoma I. Kara et.al.|[2508.08432](https://arxiv.org/abs/2508.08432)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**XDMA: A Distributed, Extensible DMA Architecture for Layout-Flexible Data Movements in Heterogeneous Multi-Accelerator SoCs**|Fanchen Kong et.al.|[2508.08396](https://arxiv.org/abs/2508.08396)|null|
|**2025-08-11**|**CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation**|Shuzhou Yuan et.al.|[2508.08386](https://arxiv.org/abs/2508.08386)|null|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Kaijun Wang et.al.|[2508.08240](https://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling**|Zhuohao Yu et.al.|[2508.08211](https://arxiv.org/abs/2508.08211)|null|
|**2025-08-11**|**Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization**|Nicholas Klein et.al.|[2508.08141](https://arxiv.org/abs/2508.08141)|null|
|**2025-08-11**|**AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies**|Yinpei Dai et.al.|[2508.08113](https://arxiv.org/abs/2508.08113)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability**|Yancheng Jiang et.al.|[2508.08043](https://arxiv.org/abs/2508.08043)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-11**|**Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks**|Thusitha Dayaratne et.al.|[2508.08029](https://arxiv.org/abs/2508.08029)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-11**|**Expert Preference-based Evaluation of Automated Related Work Generation**|Furkan Şahinuç et.al.|[2508.07955](https://arxiv.org/abs/2508.07955)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|En Yen Puang et.al.|[2508.07945](https://arxiv.org/abs/2508.07945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Gate tunable spin-charge interconversion in a graphene/ReS $_{2}$ heterostructure up to room temperature**|Eoin Dolan et.al.|[2508.07888](https://arxiv.org/abs/2508.07888)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Selective Contrastive Learning for Weakly Supervised Affordance Grounding**|WonJun Moon et.al.|[2508.07877](https://arxiv.org/abs/2508.07877)|**[link](https://github.com/hq-King/Awesome-Affordance-Learning)**|
|**2025-08-11**|**KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations**|Mubaris Nadeem et.al.|[2508.07834](https://arxiv.org/abs/2508.07834)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-11**|**Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation**|Antonio Rosales et.al.|[2508.07758](https://arxiv.org/abs/2508.07758)|null|
|**2025-08-11**|**Observation and Modulation of the Quantum Mpemba Effect on a Superconducting Quantum Processor**|Yueshan Xu et.al.|[2508.07707](https://arxiv.org/abs/2508.07707)|null|
|**2025-08-11**|**Improving Continuous Grasp Force Decoding from EEG with Time-Frequency Regressors and Premotor-Parietal Network Integration**|Parth G. Dangi et.al.|[2508.07677](https://arxiv.org/abs/2508.07677)|null|
|**2025-08-11**|**Ethics2vec: aligning automatic agents and human preferences**|Gianluca Bontempi et.al.|[2508.07673](https://arxiv.org/abs/2508.07673)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Helong Huang et.al.|[2508.07650](https://arxiv.org/abs/2508.07650)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-11**|**Grasp-HGN: Grasping the Unexpected**|Mehrshad Zandigohar et.al.|[2508.07648](https://arxiv.org/abs/2508.07648)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Dejie Yang et.al.|[2508.07626](https://arxiv.org/abs/2508.07626)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Instantaneous optical selection rule for independent control of valley currents**|Wanzhu He et.al.|[2508.07612](https://arxiv.org/abs/2508.07612)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users**|Shahroz Tariq et.al.|[2508.07596](https://arxiv.org/abs/2508.07596)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning**|Stephan Rabanser et.al.|[2508.07556](https://arxiv.org/abs/2508.07556)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-10**|**Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten**|Wei Qian et.al.|[2508.07458](https://arxiv.org/abs/2508.07458)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-10**|**Ion Coulomb crystals: an exotic form of condensed matter**|Giovanna Morigi et.al.|[2508.07374](https://arxiv.org/abs/2508.07374)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features**|Ivan Kukanov et.al.|[2508.07337](https://arxiv.org/abs/2508.07337)|null|
|**2025-08-10**|**Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)**|Adeetya Uppal et.al.|[2508.07323](https://arxiv.org/abs/2508.07323)|null|
|**2025-08-10**|**A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks**|Yanzhao Yu et.al.|[2508.07319](https://arxiv.org/abs/2508.07319)|null|
|**2025-08-10**|**Multimodal Spiking Neural Network for Space Robotic Manipulation**|Liwen Zhang et.al.|[2508.07287](https://arxiv.org/abs/2508.07287)|null|
|**2025-08-10**|**Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization**|Songlin Li et.al.|[2508.07216](https://arxiv.org/abs/2508.07216)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI**|Ahmed M. Abuzuraiq et.al.|[2508.07183](https://arxiv.org/abs/2508.07183)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion**|Xiaotong Lin et.al.|[2508.07162](https://arxiv.org/abs/2508.07162)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|
|**2025-08-10**|**Canvas3D: Empowering Precise Spatial Control for Image Generation with Constraints from a 3D Virtual Canvas**|Runlin Duan et.al.|[2508.07135](https://arxiv.org/abs/2508.07135)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Aiden Swann et.al.|[2508.07118](https://arxiv.org/abs/2508.07118)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications**|Ayane Lebeta Goshu et.al.|[2508.07098](https://arxiv.org/abs/2508.07098)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Joint Beamforming Optimization for Pinching-Antenna Systems (PASS)-assisted Symbiotic Radio**|Ze Wang et.al.|[2508.07002](https://arxiv.org/abs/2508.07002)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-09**|**Manipulator for people with limited abilities**|Bingkun Huang et.al.|[2508.06969](https://arxiv.org/abs/2508.06969)|null|
|**2025-08-09**|**Millimeter-Wave Position Sensing Using Reconfigurable Intelligent Surfaces: Positioning Error Bound and Phase Shift Configuration**|Xin Cheng et.al.|[2508.06958](https://arxiv.org/abs/2508.06958)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Coulombic control of charge transfer in luminescent radicals with long-lived quartet states**|Lujo Matasovic et.al.|[2508.06945](https://arxiv.org/abs/2508.06945)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Optically Tunable Spin Transport in Bilayer Altermagnetic Mott Insulators**|Niklas Sicheler et.al.|[2508.06938](https://arxiv.org/abs/2508.06938)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Observation and Control of Chiral Spin Frustration in BiYIG Thin Films**|Jinlong Wang et.al.|[2508.06858](https://arxiv.org/abs/2508.06858)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation**|Nizamudheen V et.al.|[2508.06780](https://arxiv.org/abs/2508.06780)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual Integrity Perspective**|Sarah Tran et.al.|[2508.06760](https://arxiv.org/abs/2508.06760)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Learning Causal Structure Distributions for Robust Planning**|Alejandro Murillo-Gonzalez et.al.|[2508.06742](https://arxiv.org/abs/2508.06742)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**In-Context Reinforcement Learning via Communicative World Models**|Fernando Martinez-Lopez et.al.|[2508.06659](https://arxiv.org/abs/2508.06659)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-08**|**When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation**|Dario Pasquini et.al.|[2508.06394](https://arxiv.org/abs/2508.06394)|null|
|**2025-08-08**|**Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators**|Amir Hossein Barjini et.al.|[2508.06313](https://arxiv.org/abs/2508.06313)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions**|Gerhard Kirsten et.al.|[2508.06303](https://arxiv.org/abs/2508.06303)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Real-Time 3D Vision-Language Embedding Mapping**|Christian Rauch et.al.|[2508.06291](https://arxiv.org/abs/2508.06291)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators**|Juan Heredia et.al.|[2508.06276](https://arxiv.org/abs/2508.06276)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|

<p align=right>(<a href=#updated-on-20250815>back to top</a>)</p>

## Vision Language Action Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-14**|**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**|Wenxuan Song et.al.|[2508.10333](https://arxiv.org/abs/2508.10333)|**[link](https://github.com/Chowzy069/ReconVLA)**|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Lin Sun et.al.|[2508.09071](https://arxiv.org/abs/2508.09071)|null|
|**2025-08-12**|**Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding**|Maxim A. Patratskiy et.al.|[2508.09032](https://arxiv.org/abs/2508.09032)|null|
|**2025-08-14**|**Reinforcement Learning in Vision: A Survey**|Weijia Wu et.al.|[2508.08189](https://arxiv.org/abs/2508.08189)|null|
|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Jason Lee et.al.|[2508.07917](https://arxiv.org/abs/2508.07917)|**[link](https://huggingface.co/models/allenai/MolmoAct-7B-D-0812)**|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Helong Huang et.al.|[2508.07650](https://arxiv.org/abs/2508.07650)|null|
|**2025-08-06**|**Static and Plugged: Make Embodied Evaluation Simple**|Jiahao Xiao et.al.|[2508.06553](https://arxiv.org/abs/2508.06553)|**[link](https://huggingface.co/datasets/xiaojiahao/StaticEmbodiedBench)**|
|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Heran Wu et.al.|[2508.06547](https://arxiv.org/abs/2508.06547)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Shunlei Li et.al.|[2508.05342](https://arxiv.org/abs/2508.05342)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Sahar Salimpour et.al.|[2508.05294](https://arxiv.org/abs/2508.05294)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|**[link](https://github.com/XiaoWei-i/Awesome-VLA-RL)**|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Zhigen Zhao et.al.|[2508.00097](https://arxiv.org/abs/2508.00097)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Xiaoyu Chen et.al.|[2507.23682](https://arxiv.org/abs/2507.23682)|**[link](https://huggingface.co/models/microsoft/villa-x)**|
|**2025-07-30**|**Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance**|Songsheng Wang et.al.|[2507.22424](https://arxiv.org/abs/2507.22424)|**[link](https://github.com/hemingkx/SpeculativeDecodingPapers)**|
|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Thomas P Zollo et.al.|[2507.17383](https://arxiv.org/abs/2507.17383)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al.|[2507.17294](https://arxiv.org/abs/2507.17294)|null|
|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Hao Luo et.al.|[2507.15597](https://arxiv.org/abs/2507.15597)|**[link](https://huggingface.co/models/BeingBeyond/Being-H0)**|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Paweł Budzianowski et.al.|[2507.14049](https://arxiv.org/abs/2507.14049)|null|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Ruihan Yang et.al.|[2507.12440](https://arxiv.org/abs/2507.12440)|null|
|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Muhayy Ud Din et.al.|[2507.10672](https://arxiv.org/abs/2507.10672)|null|
|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Jialei Huang et.al.|[2507.09160](https://arxiv.org/abs/2507.09160)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Fan-Yun Sun et.al.|[2507.06484](https://arxiv.org/abs/2507.06484)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Qucheng Peng et.al.|[2507.05227](https://arxiv.org/abs/2507.05227)|**[link](https://github.com/runjtu/awesome-and-novel-works-in-slam)**|
|**2025-07-17**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Wenyao Zhang et.al.|[2507.04447](https://arxiv.org/abs/2507.04447)|**[link](https://huggingface.co/models/WenyaoZhang/DreamVLA)**|
|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yifan Zhong et.al.|[2507.01925](https://arxiv.org/abs/2507.01925)|**[link](https://github.com/TianxingChen/Embodied-AI-Guide)**|
|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Dmytro Kuzmenko et.al.|[2507.01843](https://arxiv.org/abs/2507.01843)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Zhenyang Liu et.al.|[2507.01424](https://arxiv.org/abs/2507.01424)|**[link](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)**|
|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Yating Wang et.al.|[2507.01016](https://arxiv.org/abs/2507.01016)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Tao Lin et.al.|[2507.00416](https://arxiv.org/abs/2507.00416)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Sicong Jiang et.al.|[2506.24044](https://arxiv.org/abs/2506.24044)|null|
|**2025-06-24**|**Unified Vision-Language-Action Model**|Yuqi Wang et.al.|[2506.19850](https://arxiv.org/abs/2506.19850)|**[link](https://huggingface.co/models/Yuqi1997/UniVLA)**|
|**2025-07-07**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Jacky Kwok et.al.|[2506.17811](https://arxiv.org/abs/2506.17811)|null|
|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Yuxuan Chen et.al.|[2506.17639](https://arxiv.org/abs/2506.17639)|null|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Chongkai Gao et.al.|[2506.17561](https://arxiv.org/abs/2506.17561)|**[link](https://huggingface.co/models/Linslab/VLA-OS)**|
|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Puhao Li et.al.|[2506.16211](https://arxiv.org/abs/2506.16211)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Zeyuan Chen et.al.|[2506.14317](https://arxiv.org/abs/2506.14317)|**[link](https://github.com/YanjieZe/3D-Diffusion-Policy)**|
|**2025-06-16**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Zewei Zhou et.al.|[2506.13757](https://arxiv.org/abs/2506.13757)|**[link](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)**|
|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Wenxuan Song et.al.|[2506.13725](https://arxiv.org/abs/2506.13725)|**[link](https://huggingface.co/models/chenpyyy/openvla-ac)**|
|**2025-06-16**|**Block-wise Adaptive Caching for Accelerating Diffusion Policy**|Kangye Ji et.al.|[2506.13456](https://arxiv.org/abs/2506.13456)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-06-19**|**A Comprehensive Survey on Continual Learning in Generative Models**|Haiyang Guo et.al.|[2506.13045](https://arxiv.org/abs/2506.13045)|**[link](https://github.com/52CV/CV-Surveys)**|
|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Wenxuan Song et.al.|[2506.10826](https://arxiv.org/abs/2506.10826)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-11**|**EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models**|Yantai Yang et.al.|[2506.10100](https://arxiv.org/abs/2506.10100)|**[link](https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling)**|
|**2025-06-11**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Qiao Gu et.al.|[2506.09937](https://arxiv.org/abs/2506.09937)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Irving Fang et.al.|[2506.09930](https://arxiv.org/abs/2506.09930)|**[link](https://huggingface.co/models/IPEC-COMMUNITY/spatialvla-4b-224-sft-bridge)**|
|**2025-06-17**|**An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Pranav Guruprasad et.al.|[2506.09172](https://arxiv.org/abs/2506.09172)|null|
|**2025-06-11**|**TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization**|Zengjue Chen et.al.|[2506.08440](https://arxiv.org/abs/2506.08440)|null|
|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Hongyu Wang et.al.|[2506.07530](https://arxiv.org/abs/2506.07530)|**[link](https://huggingface.co/models/hongyuw/bitvla-bitsiglipL-224px-bf16)**|
|**2025-06-09**|**Real-Time Execution of Action Chunking Flow Policies**|Kevin Black et.al.|[2506.07339](https://arxiv.org/abs/2506.07339)|null|
|**2025-07-20**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Vineet Bhat et.al.|[2506.06535](https://arxiv.org/abs/2506.06535)|null|
|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Meng Li et.al.|[2506.03574](https://arxiv.org/abs/2506.03574)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-06-03**|**Adversarial Attacks on Robotic Vision Language Action Models**|Eliot Krzysztof Jones et.al.|[2506.03350](https://arxiv.org/abs/2506.03350)|null|

<p align=right>(<a href=#updated-on-20250815>back to top</a>)</p>

## Imitation Learning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-14**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Andrea Rosasco et.al.|[2508.10511](https://arxiv.org/abs/2508.10511)|null|
|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Wenlong Liang et.al.|[2508.10399](https://arxiv.org/abs/2508.10399)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-14**|**Leveraging OS-Level Primitives for Robotic Action Management**|Wenxin Zheng et.al.|[2508.10259](https://arxiv.org/abs/2508.10259)|**[link](https://github.com/Ponkux/DailyArXiv-cp)**|
|**2025-08-13**|**GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation**|Yifei Yao et.al.|[2508.09960](https://arxiv.org/abs/2508.09960)|**[link](https://github.com/jonyzhang2023/awesome-humanoid-learning)**|
|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Haoxiang Shi et.al.|[2508.09444](https://arxiv.org/abs/2508.09444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation**|Dayu Wang et.al.|[2508.08882](https://arxiv.org/abs/2508.08882)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT**|Muhammad A. Muttaqien et.al.|[2508.08748](https://arxiv.org/abs/2508.08748)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Haoran Ding et.al.|[2508.08707](https://arxiv.org/abs/2508.08707)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction**|Chaojun Ni et.al.|[2508.08170](https://arxiv.org/abs/2508.08170)|null|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Yizheng Zhang et.al.|[2508.07770](https://arxiv.org/abs/2508.07770)|null|
|**2025-08-09**|**From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving**|Antonio Guillen-Perez et.al.|[2508.07029](https://arxiv.org/abs/2508.07029)|null|
|**2025-08-12**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Anqing Jiang et.al.|[2508.06571](https://arxiv.org/abs/2508.06571)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-08**|**Towards Balanced Behavior Cloning from Imbalanced Datasets**|Sagar Parekh et.al.|[2508.06319](https://arxiv.org/abs/2508.06319)|null|
|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Daechul Ahn et.al.|[2508.06042](https://arxiv.org/abs/2508.06042)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning**|Haohui Chen et.al.|[2508.05960](https://arxiv.org/abs/2508.05960)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution**|Zhanyi Sun et.al.|[2508.05941](https://arxiv.org/abs/2508.05941)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning**|Jelle Luijkx et.al.|[2508.05310](https://arxiv.org/abs/2508.05310)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**Cognitive Duality for Adaptive Web Agents**|Jiarun Liu et.al.|[2508.05081](https://arxiv.org/abs/2508.05081)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning**|Luai Abuelsamen et.al.|[2508.05077](https://arxiv.org/abs/2508.05077)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-05**|**Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection**|Le Qiu et.al.|[2508.03129](https://arxiv.org/abs/2508.03129)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-05**|**Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control**|Yi-Hsuan Hsiao et.al.|[2508.03043](https://arxiv.org/abs/2508.03043)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-04**|**Vision-based Navigation of Unmanned Aerial Vehicles in Orchards: An Imitation Learning Approach**|Peng Wei et.al.|[2508.02617](https://arxiv.org/abs/2508.02617)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Dongchi Huang et.al.|[2508.02219](https://arxiv.org/abs/2508.02219)|null|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Kaustubh Sridhar et.al.|[2508.02062](https://arxiv.org/abs/2508.02062)|null|
|**2025-08-03**|**CLASS: Contrastive Learning via Action Sequence Supervision for Robot Manipulation**|Sung-Wook Lee et.al.|[2508.01600](https://arxiv.org/abs/2508.01600)|null|
|**2025-08-02**|**Physically-based Lighting Augmentation for Robotic Manipulation**|Shutong Jin et.al.|[2508.01442](https://arxiv.org/abs/2508.01442)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-02**|**T2S: Tokenized Skill Scaling for Lifelong Imitation Learning**|Hongquan Zhang et.al.|[2508.01167](https://arxiv.org/abs/2508.01167)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-02**|**COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning**|Sateesh Kumar et.al.|[2508.01131](https://arxiv.org/abs/2508.01131)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-01**|**Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation**|Ibrahim Althamary et.al.|[2508.01060](https://arxiv.org/abs/2508.01060)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-01**|**Video Generators are Robot Policies**|Junbang Liang et.al.|[2508.00795](https://arxiv.org/abs/2508.00795)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-08-01**|**On-Device Diffusion Transformer Policy for Efficient Robot Manipulation**|Yiming Wu et.al.|[2508.00697](https://arxiv.org/abs/2508.00697)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|
|**2025-08-01**|**HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning**|Carlo Alessi et.al.|[2508.00491](https://arxiv.org/abs/2508.00491)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-01**|**Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning**|Saichao Liu et.al.|[2508.00261](https://arxiv.org/abs/2508.00261)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Hongzhe Bi et.al.|[2507.23523](https://arxiv.org/abs/2507.23523)|**[link](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)**|
|**2025-07-30**|**Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations**|Yifei Chen et.al.|[2507.22380](https://arxiv.org/abs/2507.22380)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-29**|**RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation**|Dongyub Jude Lee et.al.|[2507.22219](https://arxiv.org/abs/2507.22219)|null|
|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Yufei Jia et.al.|[2507.21981](https://arxiv.org/abs/2507.21981)|null|
|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Yuying Zhang et.al.|[2507.21796](https://arxiv.org/abs/2507.21796)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-29**|**Model Predictive Adversarial Imitation Learning for Planning from Observation**|Tyler Han et.al.|[2507.21533](https://arxiv.org/abs/2507.21533)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-29**|**Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training**|Sodtavilan Odonchimed et.al.|[2507.21452](https://arxiv.org/abs/2507.21452)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-28**|**FMimic: Foundation Models are Fine-grained Action Learners from Human Videos**|Guangyan Chen et.al.|[2507.20622](https://arxiv.org/abs/2507.20622)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-26**|**Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models**|Anjali R. Menon et.al.|[2507.19854](https://arxiv.org/abs/2507.19854)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-26**|**Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation**|Ziyin Xiong et.al.|[2507.19817](https://arxiv.org/abs/2507.19817)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-25**|**GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning**|Amin Banayeeanzade et.al.|[2507.19647](https://arxiv.org/abs/2507.19647)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-25**|**MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service**|Ming Gong et.al.|[2507.18884](https://arxiv.org/abs/2507.18884)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-24**|**Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning**|David Blanco-Mulero et.al.|[2507.18436](https://arxiv.org/abs/2507.18436)|null|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Chang Nie et.al.|[2507.17462](https://arxiv.org/abs/2507.17462)|**[link](https://github.com/Xuchen-Li/llm-arxiv-daily)**|
|**2025-07-23**|**Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning**|Joobin Jin et.al.|[2507.17418](https://arxiv.org/abs/2507.17418)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-07-23**|**Confounded Causal Imitation Learning with Instrumental Variables**|Yan Zeng et.al.|[2507.17309](https://arxiv.org/abs/2507.17309)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-22**|**Pragmatic Policy Development via Interpretable Behavior Cloning**|Anton Matsson et.al.|[2507.17056](https://arxiv.org/abs/2507.17056)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-19**|**Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning**|Yinan Meng et.al.|[2507.16842](https://arxiv.org/abs/2507.16842)|**[link](https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation)**|
|**2025-07-22**|**GR-3 Technical Report**|Chilam Cheang et.al.|[2507.15493](https://arxiv.org/abs/2507.15493)|null|
|**2025-07-20**|**Reinforcement Learning for Flow-Matching Policies**|Samuel Pfrommer et.al.|[2507.15073](https://arxiv.org/abs/2507.15073)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|Chengwei Lou et.al.|[2507.14995](https://arxiv.org/abs/2507.14995)|**[link](https://github.com/tmgthb/Autonomous-Agents)**|
|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Shivakanth Sujit et.al.|[2507.13602](https://arxiv.org/abs/2507.13602)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-07-17**|**Latent Policy Steering with Embodiment-Agnostic Pretrained World Models**|Yiqi Wang et.al.|[2507.13340](https://arxiv.org/abs/2507.13340)|null|
|**2025-07-17**|**The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner**|Zhouqi Hua et.al.|[2507.13332](https://arxiv.org/abs/2507.13332)|null|
|**2025-07-17**|**ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning**|Rahel Rickenbach et.al.|[2507.13088](https://arxiv.org/abs/2507.13088)|null|

<p align=right>(<a href=#updated-on-20250815>back to top</a>)</p>

## Robotic Navigation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-14**|**UI-Venus Technical Report: Building High-performance UI Agents with RFT**|Zhangxuan Gu et.al.|[2508.10833](https://arxiv.org/abs/2508.10833)|**[link](https://github.com/codefuse-ai/Awesome-Code-LLM)**|
|**2025-08-14**|**Advances in Speech Separation: Techniques, Challenges, and Future Trends**|Kai Li et.al.|[2508.10830](https://arxiv.org/abs/2508.10830)|**[link](https://github.com/GuanchengWan/awesome-ai-ml-papers-auto)**|
|**2025-08-14**|**Towards Hybrid Lunar PNT: Error Models, Lower Bounds and Algorithms**|Robert Pöhlmann et.al.|[2508.10699](https://arxiv.org/abs/2508.10699)|null|
|**2025-08-14**|**AR Surgical Navigation With Surface Tracing: Comparing In-SitVisualization with Tool-Tracking Guidance for Neurosurgical Applications**|Marc J. Fischer et.al.|[2508.10554](https://arxiv.org/abs/2508.10554)|null|
|**2025-08-14**|**Onboard Dual Quaternion Guidance for Rocket Landing**|Abhinav G. Kamath et.al.|[2508.10439](https://arxiv.org/abs/2508.10439)|null|
|**2025-08-14**|**CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model**|Zhuoyuan Yu et.al.|[2508.10416](https://arxiv.org/abs/2508.10416)|null|
|**2025-08-14**|**LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval**|Yaoze Zhang et.al.|[2508.10391](https://arxiv.org/abs/2508.10391)|null|
|**2025-08-14**|**BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots**|Donipolo Ghimire et.al.|[2508.10363](https://arxiv.org/abs/2508.10363)|**[link](https://github.com/Active-SLAM/Active-SLAM-Paper-List)**|
|**2025-08-14**|**Meta-Metrics and Best Practices for System-Level Inference Performance Benchmarking**|Shweta Salaria et.al.|[2508.10251](https://arxiv.org/abs/2508.10251)|null|
|**2025-08-13**|**Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices**|Jay L. Cunningham et.al.|[2508.10071](https://arxiv.org/abs/2508.10071)|null|
|**2025-08-13**|**LIA-X: Interpretable Latent Portrait Animator**|Yaohui Wang et.al.|[2508.09959](https://arxiv.org/abs/2508.09959)|**[link](https://huggingface.co/spaces/YaohuiW/LIA-X)**|
|**2025-08-13**|**FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning**|Dongcheng Cao et.al.|[2508.09797](https://arxiv.org/abs/2508.09797)|**[link](https://github.com/wonderNefelibata/Awesome-LRM-Safety)**|
|**2025-08-13**|**Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System**|Romeo Valentin et.al.|[2508.09732](https://arxiv.org/abs/2508.09732)|**[link](https://github.com/wonderNefelibata/Awesome-LRM-Safety)**|
|**2025-08-13**|**Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization**|Qiaolei Gu et.al.|[2508.09730](https://arxiv.org/abs/2508.09730)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Decoding Neuronal Ensembles from Spatially-Referenced Calcium Traces: A Bayesian Semiparametric Approach**|Laura D'Angelo et.al.|[2508.09576](https://arxiv.org/abs/2508.09576)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**GoViG: Goal-Conditioned Visual Navigation Instruction Generation**|Fengyi Wu et.al.|[2508.09547](https://arxiv.org/abs/2508.09547)|null|
|**2025-08-13**|**COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection**|Peiran Peng et.al.|[2508.09533](https://arxiv.org/abs/2508.09533)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents**|Reema Raval et.al.|[2508.09508](https://arxiv.org/abs/2508.09508)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Haoxiang Shi et.al.|[2508.09444](https://arxiv.org/abs/2508.09444)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation**|Badi Li et.al.|[2508.09423](https://arxiv.org/abs/2508.09423)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Bridging Clarity and Accuracy: A Simple Spectral Longwave Radiation Scheme for Idealized Climate Modeling**|Andrew I. L. Williams et.al.|[2508.09353](https://arxiv.org/abs/2508.09353)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Harnessing Input-Adaptive Inference for Efficient VLN**|Dongwoo Kang et.al.|[2508.09262](https://arxiv.org/abs/2508.09262)|**[link](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)**|
|**2025-08-12**|**PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research**|Nick Oh et.al.|[2508.09232](https://arxiv.org/abs/2508.09232)|null|
|**2025-08-12**|**Nonlinear Symmetry Breaking to Enhance the Sagnac Effect in a Microresonator Gyroscope**|Thariq Shanavas et.al.|[2508.09132](https://arxiv.org/abs/2508.09132)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams**|Zane Witherspoon et.al.|[2508.09036](https://arxiv.org/abs/2508.09036)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions**|Miruna-Alexandra Gafencu et.al.|[2508.08923](https://arxiv.org/abs/2508.08923)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI**|Bo-Hsun Chen et.al.|[2508.08831](https://arxiv.org/abs/2508.08831)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Caption: Generating Informative Content Labels for Image Buttons Using Next-Screen Context**|Mingyuan Zhong et.al.|[2508.08731](https://arxiv.org/abs/2508.08731)|null|
|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Haoran Ding et.al.|[2508.08707](https://arxiv.org/abs/2508.08707)|null|
|**2025-08-12**|**ROD: RGB-Only Fast and Efficient Off-road Freespace Detection**|Tong Sun et.al.|[2508.08697](https://arxiv.org/abs/2508.08697)|null|
|**2025-08-12**|**Explore, Listen, Inspect: Supporting Multimodal Interaction with 3D Surface and Point Data Visualizations**|Sanchita S. Kamath et.al.|[2508.08554](https://arxiv.org/abs/2508.08554)|null|
|**2025-08-11**|**StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI**|Jon E. Froehlich et.al.|[2508.08524](https://arxiv.org/abs/2508.08524)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**A Bayesian Benchmarking of GBEES Applied to Outer Planet Orbiter Estimation**|Benjamin L. Hanson et.al.|[2508.08453](https://arxiv.org/abs/2508.08453)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Between Fear and Desire, the Monster Artificial Intelligence (AI): Analysis through the Lenses of Monster Theory**|Ahmed Tlili et.al.|[2508.08318](https://arxiv.org/abs/2508.08318)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion**|Qiayuan Liao et.al.|[2508.08241](https://arxiv.org/abs/2508.08241)|**[link](https://github.com/YanjieZe/awesome-humanoid-robot-learning)**|
|**2025-08-11**|**Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy**|Haiyue Chen et.al.|[2508.08226](https://arxiv.org/abs/2508.08226)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning**|Zihe Liu et.al.|[2508.08221](https://arxiv.org/abs/2508.08221)|**[link](https://github.com/hijkzzz/Awesome-LLM-Strawberry)**|
|**2025-08-11**|**Tunable edge and depth sensing via phase-change nonlocal metasurfaces**|Kenan Guo et.al.|[2508.08202](https://arxiv.org/abs/2508.08202)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-13**|**Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration**|Vladimir Zhurov et.al.|[2508.08128](https://arxiv.org/abs/2508.08128)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Vision-Based Localization and LLM-based Navigation for Indoor Environments**|Keyan Rahimi et.al.|[2508.08120](https://arxiv.org/abs/2508.08120)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-11**|**Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain**|Wei Zhang et.al.|[2508.08108](https://arxiv.org/abs/2508.08108)|null|
|**2025-08-11**|**Grid2Guide: A* Enabled Small Language Model for Indoor Navigation**|Md. Wasiul Haque et.al.|[2508.08100](https://arxiv.org/abs/2508.08100)|null|
|**2025-08-11**|**How Quantum Agents Can Change Which Strategies Are More Complex**|Spiros Kechrimparis et.al.|[2508.08092](https://arxiv.org/abs/2508.08092)|null|
|**2025-08-11**|**Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning**|Shoaib Ahmmad et.al.|[2508.07885](https://arxiv.org/abs/2508.07885)|null|
|**2025-08-11**|**SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing**|Malaika Zafar et.al.|[2508.07814](https://arxiv.org/abs/2508.07814)|null|
|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Tianyi Ma et.al.|[2508.07642](https://arxiv.org/abs/2508.07642)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-11**|**End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy**|Zifan Wang et.al.|[2508.07611](https://arxiv.org/abs/2508.07611)|**[link](https://github.com/Foruck/Awesome-Human-Motion)**|
|**2025-08-10**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiaobei Zhao et.al.|[2508.07406](https://arxiv.org/abs/2508.07406)|**[link](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv)**|
|**2025-08-10**|**MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control**|Basant Sharma et.al.|[2508.07387](https://arxiv.org/abs/2508.07387)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**In-person, Online and Back Again -- A Tale of Three Hybrid Hackathons**|Abasi-amefon Obot Affia-Jomants et.al.|[2508.07301](https://arxiv.org/abs/2508.07301)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**Time-dependent Zermelo navigation with tacking**|Steen Markvorsen et.al.|[2508.07274](https://arxiv.org/abs/2508.07274)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**Navigation and Exploration with Active Inference: from Biology to Industry**|Daria de Tinguy et.al.|[2508.07269](https://arxiv.org/abs/2508.07269)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics**|Daria de Tinguy et.al.|[2508.07267](https://arxiv.org/abs/2508.07267)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-10**|**Hybrid-Locked Kerr Microcombs for Flexible On-Chip Optical Clock Division**|Andrei Diakonov et.al.|[2508.07258](https://arxiv.org/abs/2508.07258)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-12**|**Understanding Dynamic Scenes in Ego Centric 4D Point Clouds**|Junsheng Huang et.al.|[2508.07251](https://arxiv.org/abs/2508.07251)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction**|Mohamed Parvez Aslam et.al.|[2508.07079](https://arxiv.org/abs/2508.07079)|null|
|**2025-08-09**|**Beyond Problem Solving: Framing and Problem-Solution Co-Evolution in Data Visualization Design**|Paul C. Parsons et.al.|[2508.07058](https://arxiv.org/abs/2508.07058)|null|
|**2025-08-09**|**From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline**|Dennis Benders et.al.|[2508.07045](https://arxiv.org/abs/2508.07045)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-09**|**Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation**|Yue Hu et.al.|[2508.06990](https://arxiv.org/abs/2508.06990)|**[link](https://github.com/leofan90/Awesome-World-Models)**|
|**2025-08-12**|**AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance**|Lixuan He et.al.|[2508.06944](https://arxiv.org/abs/2508.06944)|**[link](https://github.com/gabrielchua/daily-ai-papers)**|
|**2025-08-09**|**Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network**|Bing Li et.al.|[2508.06864](https://arxiv.org/abs/2508.06864)|null|
|**2025-08-09**|**Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation**|Xuan Zhao et.al.|[2508.06823](https://arxiv.org/abs/2508.06823)|null|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Minku Kim et.al.|[2508.06779](https://arxiv.org/abs/2508.06779)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC**|Justin London et.al.|[2508.06722](https://arxiv.org/abs/2508.06722)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Zero-Shot Cellular Trajectory Map Matching**|Weijie Shi et.al.|[2508.06674](https://arxiv.org/abs/2508.06674)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-08-08**|**GPU-accelerated Direct Geolocation of GNSS Interference**|Jacob S. Clements et.al.|[2508.06672](https://arxiv.org/abs/2508.06672)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis**|Xinglin Zhao et.al.|[2508.06589](https://arxiv.org/abs/2508.06589)|null|
|**2025-08-08**|**Characterization and automated optimization of laser-driven proton beams from converging liquid sheet jet targets**|G. D. Glenn et.al.|[2508.06462](https://arxiv.org/abs/2508.06462)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles**|Abdullah Zareh Andaryan et.al.|[2508.06404](https://arxiv.org/abs/2508.06404)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance**|Zihao Xu et.al.|[2508.06229](https://arxiv.org/abs/2508.06229)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Depth Jitter: Seeing through the Depth**|Md Sazidur Rahman et.al.|[2508.06227](https://arxiv.org/abs/2508.06227)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-08**|**Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor**|Dominik Brämer et.al.|[2508.06177](https://arxiv.org/abs/2508.06177)|null|
|**2025-08-08**|**GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning**|Xing Lei et.al.|[2508.06108](https://arxiv.org/abs/2508.06108)|null|
|**2025-08-08**|**ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation**|Daniel Lee et.al.|[2508.06065](https://arxiv.org/abs/2508.06065)|null|
|**2025-08-08**|**Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles**|Shaoting Liu et.al.|[2508.05972](https://arxiv.org/abs/2508.05972)|**[link](https://github.com/zezhishao/DailyArXiv)**|
|**2025-08-08**|**It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design**|Kathy Cheng et.al.|[2508.05940](https://arxiv.org/abs/2508.05940)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures**|Martin Deron et.al.|[2508.05860](https://arxiv.org/abs/2508.05860)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**Safety of Embodied Navigation: A Survey**|Zixia Wang et.al.|[2508.05855](https://arxiv.org/abs/2508.05855)|**[link](https://github.com/Trustworthy-AI-Group/Adversarial_Examples_Papers)**|
|**2025-08-07**|**Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction**|Ahmad Farooq et.al.|[2508.05838](https://arxiv.org/abs/2508.05838)|**[link](https://github.com/liliu-avril/Awesome-Segment-Anything)**|
|**2025-08-07**|**Progress and new challenges in image-based profiling**|Erik Serrano et.al.|[2508.05800](https://arxiv.org/abs/2508.05800)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**AI-Guided Exploration of Large-Scale Codebases**|Yoseph Berhanu Alebachew et.al.|[2508.05799](https://arxiv.org/abs/2508.05799)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems**|Keyvan Majd et.al.|[2508.05773](https://arxiv.org/abs/2508.05773)|**[link](https://github.com/BaiShuanghao/my_arXiv_daily)**|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jianpeng Yao et.al.|[2508.05634](https://arxiv.org/abs/2508.05634)|null|
|**2025-08-07**|**TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution**|Zhikai Zhao et.al.|[2508.05616](https://arxiv.org/abs/2508.05616)|null|

<p align=right>(<a href=#updated-on-20250815>back to top</a>)</p>

